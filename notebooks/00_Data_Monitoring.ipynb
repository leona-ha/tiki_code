{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb48f09-be5d-4ef4-aa3e-38c38cd62e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755b4ae3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date, datetime\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "\n",
    "# If your current working directory is the notebooks directory, use this:\n",
    "notebook_dir = os.getcwd()  # current working directory\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from server_config import datapath, proj_sheet, credential_path\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "scopes = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "          'https://www.googleapis.com/auth/drive']\n",
    "credentials = Credentials.from_service_account_file(credential_path, scopes=scopes)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "today = date.today() \n",
    "week_ago = today - dt.timedelta(days=7)\n",
    "today = today.strftime(\"%d%m%Y\")\n",
    "week_ago = week_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# passive + ema_data\n",
    "filepath = datapath + f\"export_{today}.csv\"\n",
    "datapath1 = datapath + f\"/raw/export_tiki_{today}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d386d",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310925d",
   "metadata": {},
   "source": [
    "### 1.1 Import epoch level passive + GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e997b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(datapath1, \"epoch_part*.csv\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6129acfe-a5d6-415c-834f-64d0fce1d2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sc-projects/sc-proj-cc15-preact/SP6/tiki_data/raw/export_tiki_03032025/epoch_part*.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c21b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the file list to ensure it's in the correct order, if necessary\n",
    "df_complete = pd.concat((pd.read_csv(f, encoding=\"latin-1\", low_memory=False) for f in file_list), ignore_index=True)\n",
    "df_complete[\"customer\"] = df_complete.customer.str.split(\"@\").str.get(0)\n",
    "df_complete[\"customer\"] = df_complete[\"customer\"].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028ae944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete[\"startTimestamp\"] = pd.to_datetime(df_complete[\"startTimestamp\"],unit='ms')\n",
    "df_complete[\"createdAt\"] = pd.to_datetime(df_complete[\"createdAt\"],unit='ms')\n",
    "\n",
    "df_complete[\"startTimestamp_day\"] = df_complete.startTimestamp.dt.strftime('%Y/%m/%d')\n",
    "df_complete[\"createdAt_day\"] = df_complete.startTimestamp.dt.strftime('%Y/%m/%d')\n",
    "\n",
    "df_complete[\"startTimestamp_hour\"] = df_complete.startTimestamp.dt.hour\n",
    "df_complete[\"createdAt_hour\"] = df_complete.startTimestamp.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054db53",
   "metadata": {},
   "source": [
    "### 1.2 Import passive data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f53acf",
   "metadata": {},
   "source": [
    "### Check location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2665c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location data\n",
    "df_loc_complete = df_complete[df_complete.type.isin([\"Latitude\", \"Longitude\"])] \n",
    "df_loc_complete = df_loc_complete[[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\", \n",
    "                           \"timezoneOffset\"]]\n",
    "df_loc_complete[\"startTimestamp\"] = (pd.to_datetime(df_loc_complete[\"startTimestamp\"],unit='ms'))\n",
    "\n",
    "df_loc_complete = df_loc_complete.groupby(\"customer\")[[\"startTimestamp\"]].max().rename_axis(None, axis=1).reset_index()\n",
    "df_loc_complete.rename(columns={\"startTimestamp\":\"last_day_GPS\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bb03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passive data\n",
    "df_pd_complete = df_complete[df_complete.type.isin([\"HeartRate\", \"AtrialFibrillationDetection\", \"RawECGVoltage\", \n",
    "                                                   \"ActiveBurnedCalories\", 'SleepAwakeBinary','SleepBinary'])]\n",
    "                                                    \n",
    "df_pd_complete = df_pd_complete[[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\", \"timezoneOffset\"]]\n",
    "df_pd_complete[\"startTimestamp\"] = (pd.to_datetime(df_pd_complete[\"startTimestamp\"],unit='ms'))\n",
    "\n",
    "df_pd_complete = df_pd_complete.groupby(\"customer\")[[\"startTimestamp\"]].max().rename_axis(None, axis=1).reset_index()\n",
    "df_pd_complete.rename(columns={\"startTimestamp\":\"last_day_passive\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e96be",
   "metadata": {},
   "source": [
    "### 1.3 Import montoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186f5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project management data\n",
    "df_sheet = pd.read_csv(f\"https://docs.google.com/spreadsheets/d/{proj_sheet}/export?format=csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbc79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring = df_sheet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f941d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring = df_monitoring[['FOR_ID', 'EMA_ID', 'Pseudonym', 'Studienversion', 'Status',\n",
    "       'Besonderes', 'Start EMA Baseline', 'Ende EMA Baseline',\n",
    "       'Terminpräferenz', 'Termin 1. Gespräch',  'Telefonat stattgefunden?', 'Baseline T20 Update verschickt?', 'Freischaltung/ Start EMA T20',\n",
    "       'Ende EMA T20', 'Freischaltung/ Start EMA Post','Ende EMA Post','Post T20 Update verschickt?',\n",
    "       'Studienende/ Dropout Mail verschickt?', 'T20=Post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2eb4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring.rename(columns = {\"Pseudonym\": \"customer\", \"EMA_ID\": \"ema_id\", \"Status\": \"status\",\n",
    "                                \"Studienversion\":\"study_version\", \"FOR_ID\":\"for_id\", \n",
    "                           \"Start EMA Baseline\": \"ema_base_start\", \"Ende EMA Baseline\": \"ema_base_end\", \n",
    "                           \"Freischaltung/ Start EMA T20\": \"ema_t20_start\",\"Ende EMA T20\":\"ema_t20_end\", \n",
    "                               \"Termin 1. Gespräch\": \"first_call_date\", \"Freischaltung/ Start EMA Post\":\"ema_post_start\",\n",
    "                               \"Ende EMA Post\":\"ema_post_end\", \"T20=Post\":\"t20_post\" }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d704c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring[\"customer\"] = df_monitoring[\"customer\"].str[:4]\n",
    "df_active = df_monitoring.copy()\n",
    "df_active = df_active[[\"customer\", \"ema_id\", \"ema_base_end\", \"ema_base_start\", \"study_version\", \"for_id\", \"status\"]]\n",
    "df_active[\"for_id\"] = df_active.for_id.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c156e",
   "metadata": {},
   "source": [
    "### 1.5 Import EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30bfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "session = pd.read_csv(datapath1 + \"questionnaireSession.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f426b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session data\n",
    "session[\"user\"] = session[\"user\"].str[:4]\n",
    "session.rename(columns = {\"user\":\"customer\",\"completedAt\": \"quest_complete\", \"createdAt\": \"quest_create\", \"expirationTimestamp\": \"quest_expir\"}, inplace=True)\n",
    "session[\"quest_create\"] = (pd.to_datetime(session[\"quest_create\"],unit='ms'))\n",
    "session[\"quest_complete\"] = (pd.to_datetime(session[\"quest_complete\"],unit='ms'))\n",
    "df_sess = session[[\"customer\", \"sessionRun\", \"quest_create\", \"quest_complete\", \"study\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f670143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of completed EMA beeps in first phase\n",
    "df_sess1 = df_sess.loc[df_sess.study.isin([24,25])]\n",
    "sess_count1 = df_sess1.dropna(subset=[\"quest_complete\"]).groupby(\"customer\")[\"quest_create\"].size()\\\n",
    ".reset_index()\n",
    "sess_count1 = sess_count1.rename(columns = {\"quest_create\":\"nquest_EMA1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fb3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of completed EMA beeps in second phase\n",
    "df_sess2 = df_sess.loc[df_sess.study.isin([33,34])]\n",
    "sess_count2 = df_sess2.dropna(subset=[\"quest_create\"]).groupby(\"customer\")[\"quest_create\"].size()\\\n",
    ".reset_index()\n",
    "sess_count2 = sess_count2.rename(columns = {\"quest_create\":\"nquest_EMA2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c810190-13ee-4200-959c-8217f6f5d21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count number of completed EMA beeps in third phase\n",
    "df_sess3 = df_sess.loc[df_sess.study.isin([38,39])]\n",
    "sess_count3 = df_sess3.dropna(subset=[\"quest_create\"]).groupby(\"customer\")[\"quest_create\"].size()\\\n",
    ".reset_index()\n",
    "sess_count3 = sess_count3.rename(columns = {\"quest_create\":\"nquest_EMA3\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622eb18",
   "metadata": {},
   "source": [
    "## 2. Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fef120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monitoring and passive\n",
    "df_merged = pd.merge(df_pd_complete, df_active, on=\"customer\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2516c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monitoring and EMA\n",
    "df_merged = pd.merge(df_merged, sess_count1, on=\"customer\", how=\"outer\")\n",
    "df_merged = pd.merge(df_merged, sess_count2, on=\"customer\", how=\"outer\")\n",
    "df_merged = pd.merge(df_merged, sess_count3, on=\"customer\", how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a4cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_merged, df_loc_complete, on=\"customer\", how=\"outer\")\n",
    "\n",
    "df_merged.to_csv(f\"data_compliance_{today}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6daa16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[df_merged['status'].isin(['Erhebung_1_aktiv', 'Post_Erhebung_1', 'Post_Erhebung_2','Erhebung_2_aktiv', 'Erhebung_3_aktiv'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b902c27b-60ea-449a-b65d-7fe701342464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.customer.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429c7e9",
   "metadata": {},
   "source": [
    "## 3. Check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa935458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get structure of the google spreadsheet\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE/export?format=csv&gid=1512138040\")\n",
    "df = df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c9d4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_remove = [\"FOR13016\", \"FOR11022\", \"FOR14062\", \"FOR11012\"]\n",
    "remove_scanwatch = [\"FOR14029\", \"FOR14055\", \"FOR14080\", \"FOR12027\", \"FOR14002\", \"FOR14003\", \"FOR11001\"]\n",
    "remove_gps = [\"FOR13013\", \"FOR14014\", \"FOR13019\", \"FOR13010\", \"13082\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a907530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[~df_merged['for_id'].isin(users_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "319aaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no pd since 7 days \n",
    "\n",
    "list_no_pd = df_merged.loc[(df_merged.last_day_GPS > week_ago) & (df_merged.last_day_passive < week_ago)][\"for_id\"].tolist()\n",
    "list_no_pd = [string for string in list_no_pd if string not in remove_scanwatch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5adefa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps for > 7 days \n",
    "list_no_gps = df_merged.loc[(df_merged.last_day_GPS < week_ago)& (df_merged.last_day_passive > week_ago)][\"for_id\"].tolist()\n",
    "list_no_gps = [string for string in list_no_gps if string not in remove_gps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "963b30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps and no pd for > 7 days\n",
    "\n",
    "list_no_gpspd = df_merged.loc[(df_merged.last_day_GPS < week_ago) & (df_merged.last_day_passive < week_ago)][\"for_id\"].tolist()\n",
    "list_no_gpspd = [string for string in list_no_gpspd if string not in users_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c66972ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps at all \n",
    "\n",
    "list_no_gps_at_all = df_merged.loc[df_merged.last_day_GPS.isna()].for_id.tolist()\n",
    "list_no_gps_at_all = [string for string in list_no_gps_at_all if string not in remove_gps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4be2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append each list to the DataFrame\n",
    "date_today = datetime.today().date()\n",
    "for column_name, entries in zip(['no_pd', 'no_gps', 'no_gpspd', 'no_gps_at_all'], \n",
    "                                [list_no_pd, list_no_gps, list_no_gpspd, list_no_gps_at_all]):\n",
    "    # Create a new DataFrame for the current list\n",
    "    temp_df = pd.DataFrame(entries, columns=[column_name])\n",
    "    \n",
    "    # Add the \"Datum\" column with today's date\n",
    "    temp_df['Datum'] = date_today\n",
    "    \n",
    "    # Since we're appending column-wise, we align other columns by setting them to NaN\n",
    "    # This step ensures the DataFrame has all the necessary columns\n",
    "    for col in df.columns:\n",
    "        if col not in temp_df.columns:\n",
    "            temp_df[col] = \"\"\n",
    "    \n",
    "    # Concatenate the new DataFrame to the original DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Reorder df columns to match the original order, if necessary\n",
    "df = df[['Datum', 'no_pd', 'no_gps', 'no_gpspd', 'data_deleted', \n",
    "         'no_gps_at_all', 'Status', 'Smartphone', 'Grund', \n",
    "         'Grund (frei)', 'Unnamed: 10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6304b",
   "metadata": {},
   "source": [
    "## 4. Create Monitoring Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10b9494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_str):\n",
    "    if isinstance(date_str, str):\n",
    "        # Remove the day of the week by splitting on the comma and taking the second part\n",
    "        date_part = date_str.split(\", \")[1]\n",
    "        return date_part\n",
    "    else:\n",
    "        return date_str  # Return the value as is if it's not a string\n",
    "\n",
    "# Apply the conversion function to preprocess the dates\n",
    "df_monitoring['first_call_date'] = df_monitoring['first_call_date'].apply(convert_date)\n",
    "\n",
    "# Convert the preprocessed date strings to datetime objects\n",
    "df_monitoring['first_call_date'] = pd.to_datetime(df_monitoring['first_call_date'], format=\"%d.%m.%Y\")\n",
    "\n",
    "date_columns = [\"ema_base_end\", \"ema_base_start\", \"ema_t20_start\", \"ema_t20_end\", \"first_call_date\", \"ema_post_start\", \"ema_post_end\"]\n",
    "df_monitoring = df_monitoring.copy()\n",
    "\n",
    "# Convert multiple columns to datetime'\n",
    "for col in date_columns:\n",
    "    df_monitoring[col] = pd.to_datetime(df_monitoring[col], errors='coerce', dayfirst=True).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcf9ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamp for today\n",
    "today = pd.Timestamp(\"today\")\n",
    "\n",
    "# Calculate the day of the week for today, where Monday is 0 and Sunday is 6\n",
    "today_day_of_week = today.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b79acf42-87d5-41a6-9c06-db3a6b320144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday 03.03:  T20 Start (Status ändern): ['FOR11100']; Kurzversion end today, send mail: ['FOR14167']; TPost Start (Status ändern): ['FOR13026']\n",
      "Tuesday 04.03:  T20 Ende (Status ändern): ['FOR11070', 'FOR11103']; Kurzversion Ende, change status: ['FOR14167']\n",
      "Wednesday 05.03:  Kurzversion end today, send mail: ['FOR11141']\n",
      "Thursday 06.03:  Onboarding Call: ['FOR11141']; Kurzversion Ende, change status: ['FOR11141']; TPost Start (Status ändern): ['FOR14080']\n",
      "Friday 07.03:  Onboarding Call: ['FOR13099']; Baseline Ende Lang (Status ändern): ['FOR13099']; TPost Start (Status ändern): ['FOR14049']\n",
      "Saturday 08.03: No actions needed\n",
      "Sunday 09.03: No actions needed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use today's date, but focus only on the date part\n",
    "today = pd.Timestamp(\"today\").date()\n",
    "\n",
    "# Calculate the most recent Monday as the start of the week\n",
    "week_start_date = today - pd.Timedelta(days=today.weekday())\n",
    "\n",
    "# Initialize an empty dictionary to store tasks for each day\n",
    "weekly_tasks = {day: [] for day in range(7)}  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Loop through each day of the current week from Monday to Sunday\n",
    "for day in range(7):  # Monday to Sunday\n",
    "    target_date = week_start_date + pd.Timedelta(days=day)\n",
    "\n",
    "    # Format the date to include the weekday name and day.month\n",
    "    formatted_date = target_date.strftime(\"%A %d.%m\")  # e.g., \"Monday 12.02\"\n",
    "\n",
    "    # Initialize message list for the specific day\n",
    "    messages = []\n",
    "\n",
    "    # Assuming the filtering logic is already correctly implemented\n",
    "    onboarding_ids = df_monitoring[df_monitoring['first_call_date'] == target_date]['for_id'].tolist()\n",
    "    baseline_ended_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date - pd.Timedelta(days=1)) &\n",
    "                                       (df_monitoring['study_version'].isin(['Lang', 'Lang(Wechsel)']))]['for_id'].tolist()\n",
    "    study_short_finished_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date) &\n",
    "                                             (df_monitoring['study_version'].isin(['Kurz', 'Kurz (Wechsel/Abbruch)']))]['for_id'].tolist()\n",
    "    study_finished_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date - pd.Timedelta(days=1)) &\n",
    "                                        (df_monitoring['study_version'].isin(['Kurz', 'Kurz (Wechsel/Abbruch)']))]['for_id'].tolist()\n",
    "    t20_ended_ids = df_monitoring[df_monitoring['ema_t20_end'] == (target_date - pd.Timedelta(days=1))]['for_id'].tolist()\n",
    "    t20_start_ids = df_monitoring[df_monitoring['ema_t20_start'] == target_date]['for_id'].tolist()\n",
    "    t20_post_ids = df_monitoring[(df_monitoring['ema_t20_end'] == (target_date - pd.Timedelta(days=1))) & \n",
    "                                 (df_monitoring['t20_post'].str.contains('ja'))]['for_id'].tolist()\n",
    "    post_ended_ids = df_monitoring[df_monitoring['ema_post_end'] == (target_date - pd.Timedelta(days=1))]['for_id'].tolist()\n",
    "    post_start_ids = df_monitoring[df_monitoring['ema_post_start'] == target_date]['for_id'].tolist()\n",
    "\n",
    "    if onboarding_ids:\n",
    "        messages.append(f\"Onboarding Call: {onboarding_ids}\")\n",
    "    if baseline_ended_ids:\n",
    "        messages.append(f\"Baseline Ende Lang (Status ändern): {baseline_ended_ids}\")\n",
    "    if t20_start_ids:\n",
    "        messages.append(f\"T20 Start (Status ändern): {t20_start_ids}\")\n",
    "    if t20_ended_ids:\n",
    "        messages.append(f\"T20 Ende (Status ändern): {t20_ended_ids}\")\n",
    "    if study_short_finished_ids:\n",
    "        messages.append(f\"Kurzversion end today, send mail: {study_short_finished_ids}\")\n",
    "    if study_finished_ids:\n",
    "        messages.append(f\"Kurzversion Ende, change status: {study_finished_ids}\")\n",
    "    if t20_post_ids:\n",
    "        messages.append(f\"Person has finished Langversion, send reward, Redcap eCRF auf Complete setzen: {t20_post_ids}\")\n",
    "    if post_start_ids:\n",
    "        messages.append(f\"TPost Start (Status ändern): {post_start_ids}\")\n",
    "    if post_ended_ids:\n",
    "        messages.append(f\"TPost Ende change status, send reward, finish Redcap): {post_ended_ids}\")\n",
    "\n",
    "    # Store messages for the day\n",
    "    if messages:\n",
    "        weekly_tasks[day].extend(messages)\n",
    "\n",
    "# Add weekend tasks to Monday\n",
    "if weekly_tasks[5]:  # Saturday\n",
    "    weekly_tasks[0].insert(0, f\"Tasks from Saturday: {'; '.join(weekly_tasks[5])}\")\n",
    "if weekly_tasks[6]:  # Sunday\n",
    "    weekly_tasks[0].insert(0, f\"Tasks from Sunday: {'; '.join(weekly_tasks[6])}\")\n",
    "\n",
    "# Print the tasks for each day in order\n",
    "for day in range(7):  # Monday to Sunday\n",
    "    target_date = week_start_date + pd.Timedelta(days=day)\n",
    "    formatted_date = target_date.strftime(\"%A %d.%m\")\n",
    "\n",
    "    if weekly_tasks[day]:\n",
    "        print(f\"{formatted_date}: \", \"; \".join(weekly_tasks[day]))\n",
    "    else:\n",
    "        print(f\"{formatted_date}: No actions needed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3da0e4-3fb5-48eb-b7ac-10cdb97487ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74f8b93a",
   "metadata": {},
   "source": [
    "## 5. Export missing data to google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd9ca8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.apply(lambda col: col.map(str)).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2dba8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a google sheet\n",
    "gs = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE\")\n",
    "# select a work sheet from its name\n",
    "worksheet1 = gs.worksheet('Datenqualität')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc3809d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE',\n",
       " 'updatedRange': \"'Datenqualität'!A2792:K2839\",\n",
       " 'updatedRows': 48,\n",
       " 'updatedColumns': 11,\n",
       " 'updatedCells': 528}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "next_row = len(worksheet1.col_values(1)) + 1  # Assuming column A has index 1\n",
    "\n",
    "# Construct the range string where you want to start appending data\n",
    "# For example, if starting from column A and the next available row is 10, the range would be 'A10'\n",
    "start_range = f'A{next_row}'\n",
    "\n",
    "# Use the update method to append data starting from the specified cell\n",
    "worksheet1.update(values=missing_data, range_name=start_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5b8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tiki]",
   "language": "python",
   "name": "conda-env-.conda-tiki-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
