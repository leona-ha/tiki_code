{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ac61a",
   "metadata": {},
   "source": [
    "# DGPS 2024: Situation Assessment in PREACT\n",
    "\n",
    "This notebook shows the analysis of situational context using EMA and passive sensing data\n",
    "\n",
    "1. **Load Data**: Load necessary data from pickle files.\n",
    "2. **Preprocess EMA**:\n",
    "- Keep only first assessment phase \n",
    "- Remove all entries that have no complete EMA assessment \n",
    "- Remove all participants with too few data \n",
    "- Create blocks of assessment \n",
    "3. **Perform Item Analysis according to Siepe et al. (2022)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import regex as re\n",
    "# If your current working directory is the notebooks directory, use this:\n",
    "notebook_dir = os.getcwd()  # current working directory\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "import glob\n",
    "import pickle\n",
    "from IPython.display import Markdown\n",
    "from server_config import datapath, preprocessed_path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"axes.labelsize\": 14, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': True})\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ada525-80a7-4b82-bc10-1b06b1381a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "# Original colors for situation categories mapped to the simplified names\n",
    "situation_colors = {\n",
    "    'other': '#1f77b4',\n",
    "    'care work': '#ff7f0e',\n",
    "    'travelling': '#2ca02c',\n",
    "    'chores': '#d62728',\n",
    "    'eating - drinking - selfcare': '#9467bd',  # Updated name to match the new mapping\n",
    "    'active leisure': '#8c564b',\n",
    "    'smartphone - social media': '#e377c2',  # Updated name to match the new mapping\n",
    "    'passive leisure': '#7f7f7f',\n",
    "    'work or study': '#bcbd22'\n",
    "}\n",
    "\n",
    "\n",
    "# Paired colors for diagnosis categories\n",
    "diagnosis_colors = {\n",
    "    'Depressive Disorder': '#a6cee3',   # Light Blue\n",
    "    'Social Anxiety Disorder': '#1f78b4',  # Dark Blue\n",
    "    'Obsessive-Compulsive Disorder': '#b2df8a',  # Light Green\n",
    "    'Generalized Anxiety Disorder': '#33a02c',  # Dark Green\n",
    "    'Agoraphobia and/or Panic Disorder': '#fb9a99',  # Light Pink\n",
    "    'Post-Traumatic Stress Disorder': '#e31a1c',  # Red\n",
    "    'Specific Phobia': '#fdbf6f'}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a36ca6-093e-4a65-979d-312aa51673b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "# Function to get color for situation category\n",
    "def get_situation_color(category):\n",
    "    return situation_colors.get(category, '#000000')  # Default to black if category not found\n",
    "\n",
    "# Function to get color for diagnosis category\n",
    "def get_diagnosis_color(category):\n",
    "    return diagnosis_colors.get(category, '#000000')  # Default to black if category not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696265f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup_path = preprocessed_path + \"backup_data_passive.feather\"\n",
    "#df_backup = pd.read_feather(backup_path)\n",
    "\n",
    "with open(preprocessed_path + '/ema_data.pkl', 'rb') as file:\n",
    "    df_ema_framework = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path + '/ema_content.pkl', 'rb') as file:\n",
    "    df_ema_content = pickle.load(file)  \n",
    "\n",
    "with open(preprocessed_path + '/monitoring_data.pkl', 'rb') as file:\n",
    "    df_monitoring = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path + '/redcap_data.pkl', 'rb') as file:\n",
    "    df_redcap = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path + '/map_ema_passive.pkl', 'rb') as file:\n",
    "    df_ema_passive = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031fc950-73df-4bab-a520-681db981096a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>createdAt_day</th>\n",
       "      <th>unique_day_id</th>\n",
       "      <th>assess</th>\n",
       "      <th>sensor_block_end</th>\n",
       "      <th>sensor_block_start</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_GPS</th>\n",
       "      <th>total_distance_km</th>\n",
       "      <th>transition</th>\n",
       "      <th>transition_minutes</th>\n",
       "      <th>at_home_minute</th>\n",
       "      <th>at_home_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>20230919_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-19 07:31:20.352</td>\n",
       "      <td>2023-09-19 05:31:20.352</td>\n",
       "      <td>295</td>\n",
       "      <td>115</td>\n",
       "      <td>0.445619</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>20230919_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-19 17:14:33.463</td>\n",
       "      <td>2023-09-19 15:14:33.463</td>\n",
       "      <td>11126</td>\n",
       "      <td>286</td>\n",
       "      <td>16.757672</td>\n",
       "      <td>1</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>20230928_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-28 18:29:55.737</td>\n",
       "      <td>2023-09-28 16:29:55.737</td>\n",
       "      <td>12097</td>\n",
       "      <td>2</td>\n",
       "      <td>19.321239</td>\n",
       "      <td>1</td>\n",
       "      <td>35.283333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>20230925_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-25 17:08:34.592</td>\n",
       "      <td>2023-09-25 15:08:34.592</td>\n",
       "      <td>13281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>20230922_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-22 17:06:14.166</td>\n",
       "      <td>2023-09-22 15:06:14.166</td>\n",
       "      <td>6328</td>\n",
       "      <td>85</td>\n",
       "      <td>6.815990</td>\n",
       "      <td>1</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760451</th>\n",
       "      <td>xwB7</td>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>20230721_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-21 11:40:30.657</td>\n",
       "      <td>2023-07-21 09:40:30.657</td>\n",
       "      <td>4374</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760480</th>\n",
       "      <td>xwB7</td>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>20230720_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-20 13:46:15.775</td>\n",
       "      <td>2023-07-20 11:46:15.775</td>\n",
       "      <td>6063</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760510</th>\n",
       "      <td>xwB7</td>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>20230720_7</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-20 16:58:19.651</td>\n",
       "      <td>2023-07-20 14:58:19.651</td>\n",
       "      <td>4497</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760544</th>\n",
       "      <td>tpJ1</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>20240903_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-03 10:17:33.582</td>\n",
       "      <td>2024-09-03 08:17:33.582</td>\n",
       "      <td>3190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760635</th>\n",
       "      <td>OzwS</td>\n",
       "      <td>2024-03-26</td>\n",
       "      <td>20240326_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-26 14:23:56.059</td>\n",
       "      <td>2024-03-26 12:23:56.059</td>\n",
       "      <td>11016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17202 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer createdAt_day unique_day_id  assess        sensor_block_end  \\\n",
       "0          MYAi    2023-09-19    20230919_1       0 2023-09-19 07:31:20.352   \n",
       "32         MYAi    2023-09-19    20230919_6       0 2023-09-19 17:14:33.463   \n",
       "33         MYAi    2023-09-28    20230928_6       0 2023-09-28 18:29:55.737   \n",
       "35         MYAi    2023-09-25    20230925_6       0 2023-09-25 17:08:34.592   \n",
       "39         MYAi    2023-09-22    20230922_6       0 2023-09-22 17:06:14.166   \n",
       "...         ...           ...           ...     ...                     ...   \n",
       "760451     xwB7    2023-07-21    20230721_4       0 2023-07-21 11:40:30.657   \n",
       "760480     xwB7    2023-07-20    20230720_5       0 2023-07-20 13:46:15.775   \n",
       "760510     xwB7    2023-07-20    20230720_7       0 2023-07-20 16:58:19.651   \n",
       "760544     tpJ1    2024-09-03    20240903_2       0 2024-09-03 10:17:33.582   \n",
       "760635     OzwS    2024-03-26    20240326_5       0 2024-03-26 14:23:56.059   \n",
       "\n",
       "            sensor_block_start  n_steps  n_GPS  total_distance_km  transition  \\\n",
       "0      2023-09-19 05:31:20.352      295    115           0.445619           0   \n",
       "32     2023-09-19 15:14:33.463    11126    286          16.757672           1   \n",
       "33     2023-09-28 16:29:55.737    12097      2          19.321239           1   \n",
       "35     2023-09-25 15:08:34.592    13281      0           0.000000          -1   \n",
       "39     2023-09-22 15:06:14.166     6328     85           6.815990           1   \n",
       "...                        ...      ...    ...                ...         ...   \n",
       "760451 2023-07-21 09:40:30.657     4374      0           0.000000          -1   \n",
       "760480 2023-07-20 11:46:15.775     6063      0           0.000000          -1   \n",
       "760510 2023-07-20 14:58:19.651     4497      0           0.000000          -1   \n",
       "760544 2024-09-03 08:17:33.582     3190      0           0.000000          -1   \n",
       "760635 2024-03-26 12:23:56.059    11016      0           0.000000          -1   \n",
       "\n",
       "        transition_minutes  at_home_minute  at_home_binary  \n",
       "0                 0.000000           118.0               1  \n",
       "32               18.750000             0.0               0  \n",
       "33               35.283333             0.0               0  \n",
       "35                0.000000             0.0              -1  \n",
       "39               12.200000             0.0               0  \n",
       "...                    ...             ...             ...  \n",
       "760451            0.000000             0.0              -1  \n",
       "760480            0.000000             0.0              -1  \n",
       "760510            0.000000             0.0              -1  \n",
       "760544            0.000000             0.0              -1  \n",
       "760635            0.000000             0.0              -1  \n",
       "\n",
       "[17202 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ema_passive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20265259",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c4bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA\n",
    "assessment_phase = [0] #1,2\n",
    "min_num_daily = 4\n",
    "min_days_data = 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94cfda",
   "metadata": {},
   "source": [
    "### 1. Include only patients with finished assessments and enough quests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b95336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first assessment phase finished\n",
    "df_ema = df_ema_content.loc[df_ema_content.status.isin([\"Abgeschlossen\", \"Post_Erhebung_1\",\n",
    "                                                             \"Erhebung_2_aktiv\",\"Post_Erhebung_2\", \"Erhebung_3_aktiv\", \"Dropout\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c9d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema1 = df_ema.loc[df_ema.study.isin([24,25])] # first assessment phase\n",
    "df_ema2 = df_ema.loc[df_ema.study.isin([33,34])] # second assessment phase\n",
    "df_ema3 = df_ema.loc[df_ema.study.isin([33,34])] # third assessment phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7472ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema1 = df_ema1.loc[df_ema1[\"n_quest\"] >= min_num_daily]\n",
    "df_ema1[\"n_days_min\"] = df_ema1.groupby(\"customer\")['quest_complete_day'].transform(\"nunique\")\n",
    "df_ema1 = df_ema1.loc[df_ema1.n_days_min >= min_days_data]\n",
    "df_ema1_customers = df_ema1.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6e9f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema2 = df_ema2.loc[df_ema2[\"n_quest\"] >= min_num_daily]\n",
    "df_ema2[\"n_days_min\"] = df_ema2.groupby(\"customer\")['quest_complete_day'].transform(\"nunique\")\n",
    "df_ema2 = df_ema2.loc[df_ema2.n_days_min >= min_days_data]\n",
    "df_ema2_customers = df_ema2.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bad65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema3 = df_ema3.loc[df_ema3[\"n_quest\"] >= min_num_daily]\n",
    "df_ema3[\"n_days_min\"] = df_ema3.groupby(\"customer\")['quest_complete_day'].transform(\"nunique\")\n",
    "df_ema3 = df_ema3.loc[df_ema3.n_days_min >= min_days_data]\n",
    "df_ema3_customers = df_ema3.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062a98a7",
   "metadata": {},
   "source": [
    "### 2. Pivot table to get assessments merged together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3ce875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_social = df_ema[df_ema.quest_title == \"event_social2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26b73ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sit = df_ema[df_ema.quest_title ==\"situation1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0034413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nosit = df_ema[(df_ema['quest_title'] != 'event_social2') & (df_ema['quest_title'] != 'situation1')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf50996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table as specified\n",
    "df_sit = df_sit.pivot_table(\n",
    "    index=[\"customer\", \"unique_day_id\", \"quest_create\", \"choice_id\"],\n",
    "    columns=\"quest_title\",\n",
    "    values=\"choice_text\",\n",
    "    aggfunc='first'  # Using 'first' since each entry should theoretically be unique per group\n",
    ")\n",
    "\n",
    "# The columns are now a single level Index with just the quest_title values since 'values' is not a list anymore\n",
    "df_sit.columns = [col for col in df_sit.columns.values]\n",
    "\n",
    "# Reset the index to turn the MultiIndex into columns\n",
    "df_sit = df_sit.reset_index()\n",
    "\n",
    "df_sit = df_sit.drop_duplicates(subset=['customer', 'unique_day_id', 'choice_id'])\n",
    "\n",
    "\n",
    "df_sit['situation_count'] = df_sit.groupby([\"customer\",\"unique_day_id\"])[\"choice_id\"].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7b06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table as specified\n",
    "df_social = df_social.pivot_table(\n",
    "    index=[\"customer\", \"unique_day_id\", \"choice_id\"],\n",
    "    columns=\"quest_title\",\n",
    "    values=\"choice_text\",\n",
    "    aggfunc='first'  # Using 'first' since each entry should theoretically be unique per group\n",
    ")\n",
    "\n",
    "# The columns are now a single level Index with just the quest_title values since 'values' is not a list anymore\n",
    "df_social.columns = [col for col in df_social.columns.values]\n",
    "\n",
    "# Reset the index to turn the MultiIndex into columns\n",
    "df_social = df_social.reset_index()\n",
    "df_sit = df_sit.drop_duplicates(subset=['customer', 'unique_day_id', 'choice_id'])\n",
    "\n",
    "df_social['social_contact_count'] = df_social.groupby([\"customer\",\"unique_day_id\"])[\"choice_id\"].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e405a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_social = df_social.drop(columns=['choice_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "576f47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table as specified\n",
    "df_piv = df_nosit.pivot_table(\n",
    "    index=[\"customer\", \"unique_day_id\", \"assess\", \"quest_complete_day\", \"absolute_day_index\", \"relative_day_index\", \"weekend\", \"quest_nr\", \"weekday\"],\n",
    "    columns=\"quest_title\",\n",
    "    values=\"choice_text\",\n",
    "    aggfunc='first'  # Using 'first' since each entry should theoretically be unique per group\n",
    ")\n",
    "\n",
    "# The columns are now a single level Index with just the quest_title values since 'values' is not a list anymore\n",
    "df_piv.columns = [col for col in df_piv.columns.values]\n",
    "\n",
    "# Reset the index to turn the MultiIndex into columns\n",
    "df_piv = df_piv.reset_index()\n",
    "df_piv = df_piv.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35289c92-0670-4fba-bd04-cf7b4c12da64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pa_scale = ['panas_attentiveness', 'panas_joviality1', 'panas_joviality2', \n",
    "            'panas_selfassurance', 'panas_serenity1', 'panas_serenity2']\n",
    "na_scale = ['panas_fear1', 'panas_fear2', 'panas_guilt1', \n",
    "            'panas_guilt2', 'panas_hostility1', 'panas_hostility2', \n",
    "             'panas_sadness1', 'panas_sadness2', 'panas_loneliness']\n",
    "\n",
    "# Step 1: Ensure the columns in pa_scale and na_scale are numeric\n",
    "df_piv[pa_scale + na_scale] = df_piv[pa_scale + na_scale].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Step 2: Calculate the mean for PA and NA scales per unique_day_id\n",
    "df_piv['mean_pa'] = df_piv.groupby(['customer', 'unique_day_id'])[pa_scale].transform('mean').mean(axis=1)\n",
    "df_piv['mean_na'] = df_piv.groupby(['customer', 'unique_day_id'])[na_scale].transform('mean').mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c2edb91-5b5f-44f8-a870-35902b292481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panas_fear1         1.401390\n",
      "panas_fear2         1.630749\n",
      "panas_guilt1        1.276730\n",
      "panas_guilt2        1.784037\n",
      "panas_hostility1    1.629005\n",
      "panas_hostility2    1.346876\n",
      "panas_sadness1      1.711182\n",
      "panas_sadness2      1.599512\n",
      "panas_loneliness    1.572446\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the variance of each NA subscale per individual\n",
    "individual_variance = df_piv.groupby('customer')[na_scale].var()\n",
    "# Aggregate variance across individuals (mean variance for each subscale)\n",
    "average_variance_per_subscale = individual_variance.mean()\n",
    "\n",
    "# Display the average variance per subscale\n",
    "print(average_variance_per_subscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd237713-707b-46c7-b76f-7a7ae82cf87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9107c8-76b7-47cf-ba9d-b3959507adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting the distribution of mean PA scores across participants\n",
    "sns.histplot(df_piv['mean_pa'], kde=True)\n",
    "plt.title('Distribution of Positive Affect (PA) Scores Across Participants')\n",
    "plt.xlabel('Mean PA Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the distribution of mean NA scores across participants\n",
    "sns.histplot(df_piv['mean_na'], kde=True)\n",
    "plt.title('Distribution of Negative Affect (NA) Scores Across Participants')\n",
    "plt.xlabel('Mean NA Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c20657-27ad-412f-b431-492301ca9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate PA and NA means at the participant level\n",
    "participant_means = df_piv.groupby('customer')[['mean_pa', 'mean_na']].mean()\n",
    "\n",
    "# Plotting the distribution of mean PA scores across participants\n",
    "sns.histplot(participant_means['mean_pa'], kde=True)\n",
    "plt.title('Distribution of Positive Affect (PA) Scores Across Participants')\n",
    "plt.xlabel('Mean PA Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the distribution of mean NA scores across participants\n",
    "sns.histplot(participant_means['mean_na'], kde=True)\n",
    "plt.title('Distribution of Negative Affect (NA) Scores Across Participants')\n",
    "plt.xlabel('Mean NA Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2a8c6-e5ee-47e5-8908-20d593c4c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "na_scale = ['panas_fear1', 'panas_fear2', 'panas_guilt1', \n",
    "            'panas_guilt2', 'panas_hostility1', 'panas_hostility2', \n",
    "            'panas_sadness1', 'panas_sadness2', 'panas_loneliness']\n",
    "\n",
    "\n",
    "# NA subscale plots\n",
    "for subscale in na_scale:\n",
    "    sns.histplot(df_piv[subscale], kde=True)\n",
    "    plt.title(f'Distribution of {subscale} (NA Subscale)')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09174934-c527-4556-a204-5f3a90b22c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the NA subscales\n",
    "na_scale = ['panas_fear1', 'panas_fear2', 'panas_guilt1', \n",
    "            'panas_guilt2', 'panas_hostility1', 'panas_hostility2', \n",
    "            'panas_sadness1', 'panas_sadness2']\n",
    "\n",
    "# Calculate the correlation matrix for NA subscales\n",
    "correlation_matrix = df_piv[na_scale].corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix for Negative Affect (NA) Subscales\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b8250-8f74-442c-96f8-f0d0492aafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variability (e.g., standard deviation) for each subject\n",
    "subject_variability = df_piv.groupby('customer')[na_scale].std()\n",
    "\n",
    "# Plot a boxplot of variability across subjects\n",
    "subject_variability.boxplot(figsize=(10, 6))\n",
    "plt.title('Variability of NA Subscales Across Subjects')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, use a histogram for distribution of overall variability\n",
    "subject_variability.mean(axis=1).hist(bins=20)\n",
    "plt.title('Distribution of Average Variability Across Subjects')\n",
    "plt.xlabel('Average Variability (SD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddca47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only customers with complete assessment\n",
    "df_piv_merged = df_piv.merge(df_sit, on=[\"customer\", \"unique_day_id\"], how=\"right\")\n",
    "\n",
    "# Keep only customers with complete assessment\n",
    "df_piv_merged = df_piv_merged.merge(df_social, on=[\"customer\", \"unique_day_id\"], how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a6c67-d81d-4a44-a1f4-8ae0beb699e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the situation mapping\n",
    "situation_mapping = {\n",
    "    'Etwas Anderes': 'other',  \n",
    "    'Kümmern um Kinder / Angehörige': 'care work',\n",
    "    'Unterwegs (z.B. in der U-Bahn)': 'travelling',\n",
    "    'Hausarbeit oder Erledigungen': 'chores',\n",
    "    'Essen/ Trinken/ Körperpflege': 'eating - drinking - selfcare',  # Changed commas to hyphens\n",
    "    'Freizeitaktivität, eher aktiv (z.B. Sport, Unternehmungen)': 'active leisure',\n",
    "    'Smartphone/ Soziale Medien': 'smartphone - social media',  # Changed commas to hyphens\n",
    "    'Freizeitaktivität, eher passiv (z.B. Film schauen, Lesen)': 'passive leisure',\n",
    "    'Arbeit oder Studium': 'work or study'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'situation1' column\n",
    "df_piv_merged['situation1_simplified'] = df_piv_merged['situation1'].map(situation_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b754d5-9c5d-4dee-b540-7d78b90bac78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep only first assessment phase\n",
    "df_piv_merged = df_piv_merged.loc[df_piv_merged.assess.isin(assessment_phase)]\n",
    "\n",
    "# keep inly customers with engough data in first assessment phase\n",
    "df_piv_merged = df_piv_merged.loc[df_piv_merged.customer.isin(df_ema1_customers)]\n",
    "df_piv_merged = df_piv_merged.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f69dd4",
   "metadata": {},
   "source": [
    "### 3. Create binary negative affect score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71817bda-85dc-4820-abe0-c44f70d96bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Calculate the mode of 'mean_pa' and 'mean_na' for each customer\n",
    "def calculate_customer_modes(df):\n",
    "    # Group by customer and apply mode calculation\n",
    "    modes = df.groupby('customer').agg({\n",
    "        'mean_pa': lambda x: x.mode()[0] if not x.mode().empty else None,  # Mode for mean_pa\n",
    "        'mean_na': lambda x: x.mode()[0] if not x.mode().empty else None   # Mode for mean_na\n",
    "    })\n",
    "    return modes\n",
    "\n",
    "# Step 2: Add the mode values as new columns to the original dataframe\n",
    "modes = calculate_customer_modes(df_piv_merged)\n",
    "\n",
    "# Merge the mode values back to the original dataframe\n",
    "df_piv_merged = df_piv_merged.merge(modes, on='customer', suffixes=('', '_mode'))\n",
    "\n",
    "# Step 3: Create new columns for the binary classification based on mode comparison\n",
    "def label_rows(df):\n",
    "    # Label 'mean_pa' as 1 if above mode, otherwise 0\n",
    "    df['mean_pa_label'] = (df['mean_pa'] < df['mean_pa_mode']).astype(int)\n",
    "    \n",
    "    # Label 'mean_na' as 1 if below mode (improvement), otherwise 0\n",
    "    df['mean_na_label'] = (df['mean_na'] > df['mean_na_mode']).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the labeling function\n",
    "df_piv_merged = label_rows(df_piv_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c91189-5a50-4d6f-9ffe-8555ceee0d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_piv_merged.groupby(\"mean_na_label\")[\"customer\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365b78c-17f4-45a7-a81f-11a3ae7cef28",
   "metadata": {},
   "source": [
    "## 5. Match with Redcap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec7e21-0e70-4755-9267-2ad83fe68b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redcap_full = pd.merge(df_redcap, df_piv_merged, on= \"customer\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33bb7a2-472e-45d2-91dd-3dca12a21ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_piv_merged.groupby(\"customer\")[\"unique_day_id\"].nunique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0205dc-0ca9-46ef-bbac-74e156696a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_piv_merged.groupby(\"customer\")[\"unique_day_id\"].nunique().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43a834-27bd-45a7-8095-5d25623e36c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_piv_merged.groupby(\"customer\")[\"unique_day_id\"].nunique().std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e090d6-0f8e-48bd-9197-b9de59a2c95a",
   "metadata": {},
   "source": [
    "#### 5.1 Situation distribution across categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91371655-f2b0-4ec8-b582-60cb7a464be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_redcap_age = df_redcap_full.loc[df_redcap_full.age >18][[\"customer\", \"age\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0bb35-37f6-433f-93b6-fcc4153e42d3",
   "metadata": {},
   "source": [
    "## 6. Match with Passive data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1d799-a99f-4e42-b7fa-cc8fa58bc7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_ema_passive.merge(df_redcap_full, on=[\"customer\", \"unique_day_id\", \"assess\"], how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768098bc-129b-4a11-836d-d783b2c91e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['quest_hour'] = df_final['sensor_block_end'].dt.hour\n",
    "def categorize_time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 14:\n",
    "        return 'noon'\n",
    "    elif 14 <= hour < 18:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'evening'\n",
    "\n",
    "df_final['time_of_day'] = df_final['quest_hour'].apply(categorize_time_of_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac1205-469d-4642-8603-514f1b78ee7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def categorize_season(date):\n",
    "    if pd.isna(date):  # Check if the value is NaT\n",
    "        return None  # Return None (or you can choose another label like 'Unknown')\n",
    "\n",
    "    day_of_year = date.timetuple().tm_yday\n",
    "\n",
    "    if 80 <= day_of_year < 172:\n",
    "        return 'spring'\n",
    "    elif 172 <= day_of_year < 264:\n",
    "        return 'summer'\n",
    "    elif 264 <= day_of_year < 355:\n",
    "        return 'autumn'\n",
    "    else:\n",
    "        return 'winter'\n",
    "\n",
    "df_final['season'] = df_final['sensor_block_end'].apply(categorize_season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a77709-35dd-4312-800e-b97bd8b84889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " df_final_red_red = df_final.loc[df_final.at_home_binary !=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9bd72-395d-4743-af71-5228220664e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregated_df = aggregated_df.loc[aggregated_df.at_home_binary != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c095f8-3ad4-4edd-8391-810fb623a226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregated_df = aggregated_df.loc[aggregated_df.at_home_binary != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ec89b-32d3-4d1e-b6e1-6312280f0324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tiki]",
   "language": "python",
   "name": "conda-env-.conda-tiki-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
