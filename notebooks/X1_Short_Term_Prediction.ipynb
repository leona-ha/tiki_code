{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ac61a",
   "metadata": {},
   "source": [
    "# Paper: Towards JITAI -\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd56bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ML_pipeline.py, line 457)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/py39-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 28\u001b[0;36m\n\u001b[0;31m    import ML_pipeline\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/tiki_code/model_pipeline/ML_pipeline.py:457\u001b[0;36m\u001b[0m\n\u001b[0;31m    try:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import regex as re\n",
    "# If your current working directory is the notebooks directory, use this:\n",
    "notebook_dir = os.getcwd()  # current working directory\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "model_path = os.path.abspath(os.path.join(notebook_dir, '..', 'model_pipeline'))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append(src_path)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "from IPython.display import Markdown\n",
    "from server_config import datapath, preprocessed_path, preprocessed_path_freezed, redcap_path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "import ML_config\n",
    "import ML_pipeline\n",
    "import run_ML_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"axes.labelsize\": 14, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': True})\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696265f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup_path = preprocessed_path + \"backup_data_passive.feather\"\n",
    "#df_backup = pd.read_feather(backup_path)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_data.pkl', 'rb') as file:\n",
    "    df_ema_framework = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_content.pkl', 'rb') as file:\n",
    "    df_ema_content = pickle.load(file)  \n",
    "\n",
    "with open(preprocessed_path_freezed + '/monitoring_data.pkl', 'rb') as file:\n",
    "    df_monitoring = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/redcap_data.pkl', 'rb') as file:\n",
    "    df_redcap = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/map_ema_passive.pkl', 'rb') as file:\n",
    "    df_ema_passive = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20265259",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA\n",
    "assessment_phase = [0] #1,2\n",
    "min_num_daily = 4\n",
    "min_days_data = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2ab72-1836-4f36-9a4c-1597a1ac791c",
   "metadata": {},
   "source": [
    "### 3. Compare Included vs. not Included Participantants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c79e12-d8c9-486e-ae01-6050fe0bcbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_content_cust = df_ema_content.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e91bd-3963-4903-8e29-d85017ce6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redcap_original = df_redcap.dropna(subset = [\"age\", \"customer\"] )\n",
    "df_redcap_original = df_redcap_original[df_redcap_original.customer.isin(df_ema_content_cust)]\n",
    "df_redcap_original = df_redcap_original.drop_duplicates(subset=\"customer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72958cfb-6939-442b-a79d-4b88ffbff98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of included customer IDs\n",
    "included_customers = set(df_ema_passive['customer'])\n",
    "\n",
    "# Add a new column to df_redcap_original indicating inclusion\n",
    "df_redcap_original['Included'] = df_redcap_original['customer'].isin(included_customers)\n",
    "\n",
    "# Define the two groups\n",
    "df_redcap_original['Group'] = df_redcap_original['Included'].map({True: 'Included', False: 'Not Included'})\n",
    "\n",
    "# Verify the counts\n",
    "print(f\"Subjects included in the analysis (n={df_redcap_original['Group'].value_counts().get('Included', 0)})\")\n",
    "print(f\"Subjects not included in the analysis (n={df_redcap_original['Group'].value_counts().get('Not Included', 0)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbec043-e744-47f8-940d-2c6c2f550474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import TableOne\n",
    "# Define your variables\n",
    "# Replace the variable names with those present in your DataFrame\n",
    "\n",
    "# Demographic variables\n",
    "age = 'age'  # Continuous\n",
    "employable = 'employability_description_simple'  # Categorical\n",
    "smartphone_type = 'ema_smartphone_description'  # Categorical\n",
    "psychotropic_med = 'psychotropic_description'\n",
    "diagnosis = 'scid_cv_description'\n",
    "previous_treatment = 'prior_treatment_description_simple'\n",
    "somatic = 'somatic_description'\n",
    "\n",
    "\n",
    "\n",
    "# List of all variables to include in the table\n",
    "columns = [age, employable, smartphone_type, previous_treatment, psychotropic_med, diagnosis, somatic]\n",
    "\n",
    "# Define categorical variables\n",
    "categorical = [employable, smartphone_type, previous_treatment, psychotropic_med, diagnosis, somatic]\n",
    "\n",
    "# Define grouping variable\n",
    "group_var = 'Included'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061bfd5b-330d-4f03-bff3-2f281c517c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TableOne object\n",
    "table1 = TableOne(\n",
    "    df_redcap_original,\n",
    "    columns=columns,\n",
    "    categorical=categorical,\n",
    "    groupby=group_var,\n",
    "    pval=True,\n",
    "    nonnormal=[],  # Add variables that are non-normally distributed if any\n",
    "    missing=False  # Whether to include missing data\n",
    ")\n",
    "\n",
    "# Print the table\n",
    "print(table1.tabulate(tablefmt=\"fancy_grid\"))\n",
    "table1.to_csv('sample_overview.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb4927-cb7c-4226-a0c0-9652a615ebaa",
   "metadata": {},
   "source": [
    "## Manual Missing data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03a77b-ff3a-419a-ac90-0829f79b5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also impute activity features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f0b59-51dc-440e-97d0-232deb24e482",
   "metadata": {},
   "source": [
    "#### GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9b1b1-0583-45bb-baa2-c2d23247fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps<=625'\n",
    "mask = df_ema_passive['missing_GPS'] == 'Steps<=625'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['n_GPS', 'total_distance_km', 'time_in_transition_minutes']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0\n",
    "\n",
    "# For these rows, set the selected columns to 120\n",
    "cols_set_120 = ['time_stationary_minutes']\n",
    "for col in cols_set_120:\n",
    "    df_ema_passive.loc[mask, col] = 120\n",
    "\n",
    "mask = df_ema_passive['missing_GPS_home'] == 'Steps<=625'\n",
    "\n",
    "# For these rows, set the selected columns to 120\n",
    "cols_set_120 = ['at_home_minute']\n",
    "for col in cols_set_120:\n",
    "    df_ema_passive.loc[mask, col] = 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa95db-4e1a-439b-a047-a4be3dfa5ca1",
   "metadata": {},
   "source": [
    "#### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b5799-48bc-4157-89d9-65c9a3032ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps>625'\n",
    "mask = df_ema_passive['missing_steps'] == 'step_zero'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['n_steps']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f1199-6b99-421e-bb37-c80a2db3bd91",
   "metadata": {},
   "source": [
    "#### Physical Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57a0f2-b326-4e02-a9cd-5eed2d8be3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps>625'\n",
    "mask = df_ema_passive['missing_pa'] == 'pa_zero'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['activity_102_minutes', 'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes', 'activity_106_minutes', \n",
    "                 'activity_107_minutes']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404eb5a-7127-4662-8e68-f7a5cc6ac987",
   "metadata": {},
   "source": [
    "### Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f7e30-e5fd-4101-858c-4a969b999ad9",
   "metadata": {},
   "source": [
    "- prior treatment: ordinal encoding\n",
    "- age: min-max scaling\n",
    "- somatic, employability, psychotropic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef055ac-b39b-45d2-9b97-cc09c98fbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are which\n",
    "binary_features = ['somatic_description', 'psychotropic_description', 'employability_description_simple', 'smartphone_type', 'weekend']\n",
    "categorical_features = ['weekday', 'prior_treatment_description_simple', 'quest_create_hour', 'season', 'time_of_day']\n",
    "numeric_features = ['age','hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hr_zone_resting', 'hr_zone_moderate','hr_zone_vigorous', 'n_steps', \n",
    "       'n_GPS', 'total_distance_km', 'at_home_minute',\n",
    "       'time_in_transition_minutes', 'time_stationary_minutes', 'activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes',\n",
    "       'apparent_temperature_mean', 'sunshine_duration', 'precipitation_hours'] \n",
    "\n",
    "person_static_features = ['customer', 'age', 'somatic_description', 'psychotropic_description', 'employability_description_simple', 'smartphone_type', 'weekend']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9dd96-a71f-4771-a06f-957bc1046a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_passive[numeric_features] = df_ema_passive[numeric_features].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7ffc1-a4e8-4e16-adc7-a993ccf09eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewtest,normaltest\n",
    "\n",
    "skewed_features = []\n",
    "for col in numeric_features:\n",
    "    valid_data = df_ema_passive[col].dropna()\n",
    "\n",
    "    # skewtest requires sample size > 7 for reliable results\n",
    "    stat, p_val = skewtest(valid_data)\n",
    "    if p_val < 0.05:\n",
    "        skewed_features.append(col)  # append this feature as skewed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415b57e-f966-47a4-a2dc-63a60f4d6317",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484e1ec-bb6e-48c0-bf9b-88bbad964977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_pipeline = df_ema_passive[['customer', 'unique_day_id', \n",
    "       'quest_create_hour', 'weekday', 'weekend', 'season', 'time_of_day',\n",
    "       'n_quest', 'mean_na', 'sensor_block_end', 'age', \n",
    "       'ema_smartphone', 'psychotropic', 'somatic_problems','employability_description_simple',\n",
    "       'prior_treatment_description_simple',\n",
    "       'hr_mean', 'hr_min', 'hr_max', 'hr_std', \n",
    "       'hr_zone_resting', 'hr_zone_moderate',\n",
    "       'hr_zone_vigorous', 'n_steps',  'n_GPS', 'total_distance_km', 'at_home_minute',\n",
    "       'time_in_transition_minutes', 'time_stationary_minutes',\n",
    "       'activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes',\n",
    "       'apparent_temperature_mean', 'sunshine_duration', 'precipitation_hours',\n",
    "      ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f4680-1946-4965-acb4-69258df0d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_features:\n",
    "    series = df_ema_pipeline[col]\n",
    "    n_nan = series.isna().sum()\n",
    "    col_min = series.min()\n",
    "    col_max = series.max()\n",
    "    col_mean = series.mean()\n",
    "    col_std = series.std()\n",
    "    print(f\"{col}: NaNs={n_nan}, min={col_min}, max={col_max}, mean={col_mean}, std={col_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f599b7-50f3-4da8-8776-ded831dc3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_pipeline import MLpipeline\n",
    "from ML_config import Config\n",
    "\n",
    "my_config = Config()\n",
    "pipeline = MLpipeline(my_config)\n",
    "\n",
    "pipeline.set_data(df_ema_pipeline)\n",
    "pipeline.outer_user_split()\n",
    "pipeline.inner_time_split()\n",
    "\n",
    "# (1) Time-based runs\n",
    "results_timebased = pipeline.run(my_config.ANALYSIS[\"neg_affect_regression\"][\"MODEL_PIPEGRIDS\"])\n",
    "\n",
    "# Inspect or store results_timebased\n",
    "print(\"Time-based results:\")\n",
    "for r in results_timebased:\n",
    "    print(r)\n",
    "\n",
    "# (2) User-based holdout evaluation\n",
    "#results_holdout = pipeline.evaluate_holdout_all(results_timebased)\n",
    "\n",
    "#print(\"Holdout results:\")\n",
    "#for r in results_holdout:\n",
    "#    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277e11c-38d9-4d78-a28b-df2a3794af4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39-env)",
   "language": "python",
   "name": "py39-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
