{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ac61a",
   "metadata": {},
   "source": [
    "# Paper: Towards JITAI -\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import regex as re\n",
    "# If your current working directory is the notebooks directory, use this:\n",
    "notebook_dir = os.getcwd()  # current working directory\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "model_path = os.path.abspath(os.path.join(notebook_dir, '..', 'model_pipeline'))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append(src_path)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "from IPython.display import Markdown\n",
    "from server_config import datapath, preprocessed_path, preprocessed_path_freezed, redcap_path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "import ML_config\n",
    "import ML_pipeline\n",
    "import run_ML_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"axes.labelsize\": 14, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': True})\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696265f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup_path = preprocessed_path + \"backup_data_passive.feather\"\n",
    "#df_backup = pd.read_feather(backup_path)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_data.pkl', 'rb') as file:\n",
    "    df_ema_framework = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_content.pkl', 'rb') as file:\n",
    "    df_ema_content = pickle.load(file)  \n",
    "\n",
    "with open(preprocessed_path_freezed + '/monitoring_data.pkl', 'rb') as file:\n",
    "    df_monitoring = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/redcap_data.pkl', 'rb') as file:\n",
    "    df_redcap = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/map_ema_passive.pkl', 'rb') as file:\n",
    "    df_ema_passive = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20265259",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c4bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA\n",
    "assessment_phase = [0] #1,2\n",
    "min_num_daily = 4\n",
    "min_days_data = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2ab72-1836-4f36-9a4c-1597a1ac791c",
   "metadata": {},
   "source": [
    "### 3. Compare Included vs. not Included Participantants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c79e12-d8c9-486e-ae01-6050fe0bcbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_content_cust = df_ema_content.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0e91bd-3963-4903-8e29-d85017ce6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redcap_original = df_redcap.dropna(subset = [\"age\", \"customer\"] )\n",
    "df_redcap_original = df_redcap_original[df_redcap_original.customer.isin(df_ema_content_cust)]\n",
    "df_redcap_original = df_redcap_original.drop_duplicates(subset=\"customer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72958cfb-6939-442b-a79d-4b88ffbff98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects included in the analysis (n=176)\n",
      "Subjects not included in the analysis (n=125)\n"
     ]
    }
   ],
   "source": [
    "# Create a set of included customer IDs\n",
    "included_customers = set(df_ema_passive['customer'])\n",
    "\n",
    "# Add a new column to df_redcap_original indicating inclusion\n",
    "df_redcap_original['Included'] = df_redcap_original['customer'].isin(included_customers)\n",
    "\n",
    "# Define the two groups\n",
    "df_redcap_original['Group'] = df_redcap_original['Included'].map({True: 'Included', False: 'Not Included'})\n",
    "\n",
    "# Verify the counts\n",
    "print(f\"Subjects included in the analysis (n={df_redcap_original['Group'].value_counts().get('Included', 0)})\")\n",
    "print(f\"Subjects not included in the analysis (n={df_redcap_original['Group'].value_counts().get('Not Included', 0)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbec043-e744-47f8-940d-2c6c2f550474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import TableOne\n",
    "# Define your variables\n",
    "# Replace the variable names with those present in your DataFrame\n",
    "\n",
    "# Demographic variables\n",
    "age = 'age'  # Continuous\n",
    "employable = 'employability_description_simple'  # Categorical\n",
    "smartphone_type = 'ema_smartphone_description'  # Categorical\n",
    "psychotropic_med = 'psychotropic_description'\n",
    "diagnosis = 'scid_cv_description'\n",
    "previous_treatment = 'prior_treatment_description_simple'\n",
    "somatic = 'somatic_description'\n",
    "\n",
    "\n",
    "\n",
    "# List of all variables to include in the table\n",
    "columns = [age, employable, smartphone_type, previous_treatment, psychotropic_med, diagnosis, somatic]\n",
    "\n",
    "# Define categorical variables\n",
    "categorical = [employable, smartphone_type, previous_treatment, psychotropic_med, diagnosis, somatic]\n",
    "\n",
    "# Define grouping variable\n",
    "group_var = 'Included'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061bfd5b-330d-4f03-bff3-2f281c517c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════════════════════════════╤═══════════════════════════════════╤═════════════╤═════════════╤═════════════╤═══════════╕\n",
      "│                                           │                                   │ Overall     │ False       │ True        │ P-Value   │\n",
      "╞═══════════════════════════════════════════╪═══════════════════════════════════╪═════════════╪═════════════╪═════════════╪═══════════╡\n",
      "│ n                                         │                                   │ 301         │ 125         │ 176         │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ age, mean (SD)                            │                                   │ 33.1 (10.9) │ 33.3 (11.2) │ 32.9 (10.6) │ 0.798     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ employability_description_simple, n (%)   │ no                                │ 59 (19.6)   │ 29 (23.2)   │ 30 (17.0)   │ 0.239     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ yes                               │ 242 (80.4)  │ 96 (76.8)   │ 146 (83.0)  │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ ema_smartphone_description, n (%)         │ Android                           │ 130 (43.2)  │ 50 (40.0)   │ 80 (45.5)   │ 0.410     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ iPhone                            │ 171 (56.8)  │ 75 (60.0)   │ 96 (54.5)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ prior_treatment_description_simple, n (%) │ no prior treatment                │ 109 (36.2)  │ 45 (36.0)   │ 64 (36.4)   │ 0.579     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ prior inpatient                   │ 78 (25.9)   │ 36 (28.8)   │ 42 (23.9)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ prior psychotherapy               │ 114 (37.9)  │ 44 (35.2)   │ 70 (39.8)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ psychotropic_description, n (%)           │ no                                │ 195 (64.8)  │ 80 (64.0)   │ 115 (65.3)  │ 0.906     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ yes                               │ 106 (35.2)  │ 45 (36.0)   │ 61 (34.7)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ scid_cv_description, n (%)                │ Agoraphobia and/or Panic Disorder │ 20 (6.6)    │ 10 (8.0)    │ 10 (5.7)    │ 0.139     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Depressive Disorder               │ 134 (44.5)  │ 47 (37.6)   │ 87 (49.4)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Generalized Anxiety Disorder      │ 27 (9.0)    │ 14 (11.2)   │ 13 (7.4)    │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ None                              │ 11 (3.7)    │ 7 (5.6)     │ 4 (2.3)     │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Obsessive-Compulsive Disorder     │ 37 (12.3)   │ 20 (16.0)   │ 17 (9.7)    │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Post-Traumatic Stress Disorder    │ 12 (4.0)    │ 3 (2.4)     │ 9 (5.1)     │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Social Anxiety Disorder           │ 55 (18.3)   │ 21 (16.8)   │ 34 (19.3)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Specific Phobia                   │ 5 (1.7)     │ 3 (2.4)     │ 2 (1.1)     │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ somatic_description, n (%)                │ no                                │ 175 (58.1)  │ 75 (60.0)   │ 100 (56.8)  │ 0.665     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ yes                               │ 126 (41.9)  │ 50 (40.0)   │ 76 (43.2)   │           │\n",
      "╘═══════════════════════════════════════════╧═══════════════════════════════════╧═════════════╧═════════════╧═════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "# Create the TableOne object\n",
    "table1 = TableOne(\n",
    "    df_redcap_original,\n",
    "    columns=columns,\n",
    "    categorical=categorical,\n",
    "    groupby=group_var,\n",
    "    pval=True,\n",
    "    nonnormal=[],  # Add variables that are non-normally distributed if any\n",
    "    missing=False  # Whether to include missing data\n",
    ")\n",
    "\n",
    "# Print the table\n",
    "print(table1.tabulate(tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb4927-cb7c-4226-a0c0-9652a615ebaa",
   "metadata": {},
   "source": [
    "## Manual Missing data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d03a77b-ff3a-419a-ac90-0829f79b5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also impute activity features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f0b59-51dc-440e-97d0-232deb24e482",
   "metadata": {},
   "source": [
    "#### GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de9b1b1-0583-45bb-baa2-c2d23247fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps<=625'\n",
    "mask = df_ema_passive['missing_GPS'] == 'Steps<=625'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['n_GPS', 'total_distance_km', 'time_in_transition_minutes']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0\n",
    "\n",
    "# For these rows, set the selected columns to 120\n",
    "cols_set_120 = ['time_stationary_minutes']\n",
    "for col in cols_set_120:\n",
    "    df_ema_passive.loc[mask, col] = 120\n",
    "\n",
    "mask = df_ema_passive['missing_GPS_home'] == 'Steps<=625'\n",
    "\n",
    "# For these rows, set the selected columns to 120\n",
    "cols_set_120 = ['at_home_minute']\n",
    "for col in cols_set_120:\n",
    "    df_ema_passive.loc[mask, col] = 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa95db-4e1a-439b-a047-a4be3dfa5ca1",
   "metadata": {},
   "source": [
    "#### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5b5799-48bc-4157-89d9-65c9a3032ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps>625'\n",
    "mask = df_ema_passive['missing_steps'] == 'step_zero'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['n_steps']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f1199-6b99-421e-bb37-c80a2db3bd91",
   "metadata": {},
   "source": [
    "#### Physical Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db57a0f2-b326-4e02-a9cd-5eed2d8be3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps>625'\n",
    "mask = df_ema_passive['missing_pa'] == 'pa_zero'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['activity_102_minutes', 'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes', 'activity_106_minutes', \n",
    "                 'activity_107_minutes']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404eb5a-7127-4662-8e68-f7a5cc6ac987",
   "metadata": {},
   "source": [
    "### Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f7e30-e5fd-4101-858c-4a969b999ad9",
   "metadata": {},
   "source": [
    "- prior treatment: ordinal encoding\n",
    "- age: min-max scaling\n",
    "- somatic, employability, psychotropic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef055ac-b39b-45d2-9b97-cc09c98fbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are which\n",
    "binary_features = ['somatic_description', 'psychotropic_description', 'employability_description_simple', 'smartphone_type', 'weekend']\n",
    "categorical_features = ['weekday', 'prior_treatment_description_simple', 'quest_create_hour', 'season', 'time_of_day']\n",
    "numeric_features = ['age','hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hr_zone_resting', 'hr_zone_moderate','hr_zone_vigorous', 'n_steps', \n",
    "       'n_GPS', 'total_distance_km', 'at_home_minute',\n",
    "       'time_in_transition_minutes', 'time_stationary_minutes',\n",
    "       'prop_time_moving', 'prop_time_stationary', 'activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes',\n",
    "       'apparent_temperature_mean', 'sunshine_duration', 'precipitation_hours'] \n",
    "\n",
    "person_static_features = ['customer', 'age', 'somatic_description', 'psychotropic_description', 'employability_description_simple', 'smartphone_type', 'weekend']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d9dd96-a71f-4771-a06f-957bc1046a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_passive[numeric_features] = df_ema_passive[numeric_features].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d7ffc1-a4e8-4e16-adc7-a993ccf09eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: age\n",
      "  Skewtest statistic=46.061, p-value=0.000\n",
      "Feature: hr_mean\n",
      "  Skewtest statistic=33.683, p-value=0.000\n",
      "Feature: hr_min\n",
      "  Skewtest statistic=36.286, p-value=0.000\n",
      "Feature: hr_max\n",
      "  Skewtest statistic=43.285, p-value=0.000\n",
      "Feature: hr_std\n",
      "  Skewtest statistic=48.983, p-value=0.000\n",
      "Feature: hr_zone_resting\n",
      "  Skewtest statistic=73.116, p-value=0.000\n",
      "Feature: hr_zone_moderate\n",
      "  Skewtest statistic=76.633, p-value=0.000\n",
      "Feature: hr_zone_vigorous\n",
      "  Skewtest statistic=120.213, p-value=0.000\n",
      "Feature: n_steps\n",
      "  Skewtest statistic=68.289, p-value=0.000\n",
      "Feature: n_GPS\n",
      "  Skewtest statistic=99.497, p-value=0.000\n",
      "Feature: total_distance_km\n",
      "  Skewtest statistic=117.025, p-value=0.000\n",
      "Feature: at_home_minute\n",
      "  Skewtest statistic=-31.149, p-value=0.000\n",
      "Feature: time_in_transition_minutes\n",
      "  Skewtest statistic=122.659, p-value=0.000\n",
      "Feature: time_stationary_minutes\n",
      "  Skewtest statistic=155.178, p-value=0.000\n",
      "Feature: prop_time_moving\n",
      "  Skewtest statistic=93.895, p-value=0.000\n",
      "Feature: prop_time_stationary\n",
      "  Skewtest statistic=120.320, p-value=0.000\n",
      "Feature: activity_102_minutes\n",
      "  Skewtest statistic=57.300, p-value=0.000\n",
      "Feature: activity_103_minutes\n",
      "  Skewtest statistic=111.559, p-value=0.000\n",
      "Feature: activity_104_minutes\n",
      "  Skewtest statistic=140.511, p-value=0.000\n",
      "Feature: activity_105_minutes\n",
      "  Skewtest statistic=86.021, p-value=0.000\n",
      "Feature: activity_106_minutes\n",
      "  Skewtest statistic=158.455, p-value=0.000\n",
      "Feature: activity_107_minutes\n",
      "  Skewtest statistic=120.404, p-value=0.000\n",
      "Feature: apparent_temperature_mean\n",
      "  Skewtest statistic=1.049, p-value=0.294\n",
      "Feature: sunshine_duration\n",
      "  Skewtest statistic=-2.619, p-value=0.009\n",
      "Feature: precipitation_hours\n",
      "  Skewtest statistic=44.285, p-value=0.000\n",
      "Skewed features: ['age', 'hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hr_zone_resting', 'hr_zone_moderate', 'hr_zone_vigorous', 'n_steps', 'n_GPS', 'total_distance_km', 'at_home_minute', 'time_in_transition_minutes', 'time_stationary_minutes', 'prop_time_moving', 'prop_time_stationary', 'activity_102_minutes', 'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes', 'activity_106_minutes', 'activity_107_minutes', 'sunshine_duration', 'precipitation_hours']\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skewtest,normaltest\n",
    "\n",
    "skewed_features = []\n",
    "for col in numeric_features:\n",
    "    valid_data = df_ema_passive[col].dropna()\n",
    "\n",
    "    # skewtest requires sample size > 7 for reliable results\n",
    "    stat, p_val = skewtest(valid_data)\n",
    "    print(f\"Feature: {col}\")\n",
    "    print(f\"  Skewtest statistic={stat:.3f}, p-value={p_val:.3f}\")\n",
    "\n",
    "    if p_val < 0.05:\n",
    "        skewed_features.append(col)  # append this feature as skewed\n",
    "\n",
    "\n",
    "print(\"Skewed features:\", skewed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415b57e-f966-47a4-a2dc-63a60f4d6317",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c484e1ec-bb6e-48c0-bf9b-88bbad964977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_pipeline = df_ema_passive[['customer', 'unique_day_id', \n",
    "       'quest_create_hour', 'weekday', 'weekend', 'season', 'time_of_day',\n",
    "       'n_quest', 'mean_na', 'sensor_block_end', 'age', \n",
    "       'ema_smartphone', 'psychotropic', 'somatic_problems','employability_description_simple',\n",
    "       'prior_treatment_description_simple',\n",
    "       'hr_mean', 'hr_min', 'hr_max', 'hr_std', \n",
    "       'hr_zone_resting', 'hr_zone_moderate',\n",
    "       'hr_zone_vigorous', 'n_steps',  'n_GPS', 'total_distance_km', 'at_home_minute',\n",
    "       'time_in_transition_minutes', 'time_stationary_minutes',\n",
    "       'activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes',\n",
    "       'apparent_temperature_mean', 'sunshine_duration', 'precipitation_hours',\n",
    "      ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5f599b7-50f3-4da8-8776-ded831dc3f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[set_data] DataFrame with 13266 rows loaded in pipeline.\n",
      "[outer_user_split] Held out 17/176 users; holdout size: 1141 rows.\n",
      "[inner_time_split] Inner train size: 9637, test size: 2488.\n",
      "\n",
      "[run] Starting pipeline: LR_without_PS\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/utils/_indexing.py\", line 341, in _get_column_indices\n    all_columns = X.columns\nAttributeError: 'numpy.ndarray' object has no attribute 'columns'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 993, in fit_transform\n    self._validate_column_callables(X)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 552, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/utils/_indexing.py\", line 343, in _get_column_indices\n    raise ValueError(\nValueError: Specifying the columns using strings is only supported for dataframes.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m pipeline\u001b[38;5;241m.\u001b[39minner_time_split()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# (1) Time-based runs\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m results_timebased \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANALYSIS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneg_affect_regression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMODEL_PIPEGRIDS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Inspect or store results_timebased\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime-based results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tiki_code/model_pipeline/ML_pipeline.py:245\u001b[0m, in \u001b[0;36mMLpipeline.run\u001b[0;34m(self, pipeline_grid_dict, task_type, scoring)\u001b[0m\n\u001b[1;32m    235\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m    236\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mcombined_pipeline,\n\u001b[1;32m    237\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mN_JOBS\n\u001b[1;32m    242\u001b[0m )\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Fit on the time-based training data\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Best CV Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgs\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Best Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgs\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    999\u001b[0m     )\n\u001b[0;32m-> 1001\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/utils/_indexing.py\", line 341, in _get_column_indices\n    all_columns = X.columns\nAttributeError: 'numpy.ndarray' object has no attribute 'columns'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 993, in fit_transform\n    self._validate_column_callables(X)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 552, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"/home/leha18/.conda/envs/py39-env/lib/python3.9/site-packages/sklearn/utils/_indexing.py\", line 343, in _get_column_indices\n    raise ValueError(\nValueError: Specifying the columns using strings is only supported for dataframes.\n"
     ]
    }
   ],
   "source": [
    "from ML_pipeline import MLpipeline\n",
    "from ML_config import Config\n",
    "\n",
    "my_config = Config()\n",
    "pipeline = MLpipeline(my_config)\n",
    "\n",
    "pipeline.set_data(df_ema_pipeline)\n",
    "pipeline.outer_user_split()\n",
    "pipeline.inner_time_split()\n",
    "\n",
    "# (1) Time-based runs\n",
    "results_timebased = pipeline.run(my_config.ANALYSIS[\"neg_affect_regression\"][\"MODEL_PIPEGRIDS\"])\n",
    "\n",
    "# Inspect or store results_timebased\n",
    "print(\"Time-based results:\")\n",
    "for r in results_timebased:\n",
    "    print(r)\n",
    "\n",
    "# (2) User-based holdout evaluation\n",
    "#results_holdout = pipeline.evaluate_holdout_all(results_timebased)\n",
    "\n",
    "#print(\"Holdout results:\")\n",
    "#for r in results_holdout:\n",
    "#    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277e11c-38d9-4d78-a28b-df2a3794af4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py39-env]",
   "language": "python",
   "name": "conda-env-.conda-py39-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
