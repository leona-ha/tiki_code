{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ac61a",
   "metadata": {},
   "source": [
    "# Paper: Towards JITAI -\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd56bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 20:11:56.297768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738869116.316291 3935256 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738869116.321957 3935256 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-06 20:11:56.340087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import regex as re\n",
    "# If your current working directory is the notebooks directory, use this:\n",
    "notebook_dir = os.getcwd()  # current working directory\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "model_path = os.path.abspath(os.path.join(notebook_dir, '..', 'model_pipeline'))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append(src_path)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "from IPython.display import Markdown\n",
    "from server_config import datapath, preprocessed_path, preprocessed_path_freezed, redcap_path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "# Enable experimental features in scikit-learn\n",
    "from sklearn.experimental import enable_iterative_imputer  # ✅ Must be imported first\n",
    "from sklearn.impute import IterativeImputer  # ✅ Now you can import it\n",
    "\n",
    "\n",
    "import ML_config\n",
    "import ML_pipeline\n",
    "import run_ML_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"axes.labelsize\": 14, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': True})\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696265f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup_path = preprocessed_path + \"backup_data_passive.feather\"\n",
    "#df_backup = pd.read_feather(backup_path)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_data.pkl', 'rb') as file:\n",
    "    df_ema_framework = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_content.pkl', 'rb') as file:\n",
    "    df_ema_content = pickle.load(file)  \n",
    "\n",
    "with open(preprocessed_path_freezed + '/monitoring_data.pkl', 'rb') as file:\n",
    "    df_monitoring = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/redcap_data.pkl', 'rb') as file:\n",
    "    df_redcap = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/map_ema_passive.pkl', 'rb') as file:\n",
    "    df_ema_passive = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20265259",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c4bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA\n",
    "assessment_phase = [0] #1,2\n",
    "min_num_daily = 4\n",
    "min_days_data = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2ab72-1836-4f36-9a4c-1597a1ac791c",
   "metadata": {},
   "source": [
    "### 3. Compare Included vs. not Included Participantants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c79e12-d8c9-486e-ae01-6050fe0bcbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_content_cust = df_ema_content.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0e91bd-3963-4903-8e29-d85017ce6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redcap_original = df_redcap.dropna(subset = [\"age\", \"customer\"] )\n",
    "df_redcap_original = df_redcap_original[df_redcap_original.customer.isin(df_ema_content_cust)]\n",
    "df_redcap_original = df_redcap_original.drop_duplicates(subset=\"customer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72958cfb-6939-442b-a79d-4b88ffbff98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects included in the analysis (n=158)\n",
      "Subjects not included in the analysis (n=143)\n"
     ]
    }
   ],
   "source": [
    "# Create a set of included customer IDs\n",
    "included_customers = set(df_ema_passive['customer'])\n",
    "\n",
    "# Add a new column to df_redcap_original indicating inclusion\n",
    "df_redcap_original['Included'] = df_redcap_original['customer'].isin(included_customers)\n",
    "\n",
    "# Define the two groups\n",
    "df_redcap_original['Group'] = df_redcap_original['Included'].map({True: 'Included', False: 'Not Included'})\n",
    "\n",
    "# Verify the counts\n",
    "print(f\"Subjects included in the analysis (n={df_redcap_original['Group'].value_counts().get('Included', 0)})\")\n",
    "print(f\"Subjects not included in the analysis (n={df_redcap_original['Group'].value_counts().get('Not Included', 0)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbec043-e744-47f8-940d-2c6c2f550474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import TableOne\n",
    "# Define your variables\n",
    "# Replace the variable names with those present in your DataFrame\n",
    "\n",
    "# Demographic variables\n",
    "age = 'age'  # Continuous\n",
    "employable = 'employability_description_simple'  # Categorical\n",
    "smartphone_type = 'ema_smartphone_description'  # Categorical\n",
    "psychotropic_med = 'psychotropic_description'\n",
    "diagnosis = 'scid_cv_description'\n",
    "previous_treatment = 'prior_treatment_description_simple'\n",
    "somatic = 'somatic_description'\n",
    "\n",
    "\n",
    "\n",
    "# List of all variables to include in the table\n",
    "columns = [age, employable, smartphone_type, previous_treatment, psychotropic_med, diagnosis, somatic]\n",
    "\n",
    "# Define categorical variables\n",
    "categorical = [employable, smartphone_type, previous_treatment, psychotropic_med, diagnosis, somatic]\n",
    "\n",
    "# Define grouping variable\n",
    "group_var = 'Included'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061bfd5b-330d-4f03-bff3-2f281c517c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════════════════════════════╤═══════════════════════════════════╤═════════════╤═════════════╤═════════════╤═══════════╕\n",
      "│                                           │                                   │ Overall     │ False       │ True        │ P-Value   │\n",
      "╞═══════════════════════════════════════════╪═══════════════════════════════════╪═════════════╪═════════════╪═════════════╪═══════════╡\n",
      "│ n                                         │                                   │ 301         │ 143         │ 158         │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ age, mean (SD)                            │                                   │ 33.1 (10.9) │ 33.7 (11.5) │ 32.5 (10.2) │ 0.329     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ employability_description_simple, n (%)   │ no                                │ 59 (19.6)   │ 34 (23.8)   │ 25 (15.8)   │ 0.112     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ yes                               │ 242 (80.4)  │ 109 (76.2)  │ 133 (84.2)  │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ ema_smartphone_description, n (%)         │ Android                           │ 130 (43.2)  │ 58 (40.6)   │ 72 (45.6)   │ 0.447     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ iPhone                            │ 171 (56.8)  │ 85 (59.4)   │ 86 (54.4)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ prior_treatment_description_simple, n (%) │ no prior treatment                │ 109 (36.2)  │ 52 (36.4)   │ 57 (36.1)   │ 0.954     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ prior inpatient                   │ 78 (25.9)   │ 38 (26.6)   │ 40 (25.3)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ prior psychotherapy               │ 114 (37.9)  │ 53 (37.1)   │ 61 (38.6)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ psychotropic_description, n (%)           │ no                                │ 195 (64.8)  │ 94 (65.7)   │ 101 (63.9)  │ 0.836     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ yes                               │ 106 (35.2)  │ 49 (34.3)   │ 57 (36.1)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ scid_cv_description, n (%)                │ Agoraphobia and/or Panic Disorder │ 20 (6.6)    │ 10 (7.0)    │ 10 (6.3)    │ 0.430     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Depressive Disorder               │ 134 (44.5)  │ 56 (39.2)   │ 78 (49.4)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Generalized Anxiety Disorder      │ 27 (9.0)    │ 14 (9.8)    │ 13 (8.2)    │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ None                              │ 11 (3.7)    │ 8 (5.6)     │ 3 (1.9)     │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Obsessive-Compulsive Disorder     │ 37 (12.3)   │ 20 (14.0)   │ 17 (10.8)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Post-Traumatic Stress Disorder    │ 12 (4.0)    │ 4 (2.8)     │ 8 (5.1)     │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Social Anxiety Disorder           │ 55 (18.3)   │ 28 (19.6)   │ 27 (17.1)   │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ Specific Phobia                   │ 5 (1.7)     │ 3 (2.1)     │ 2 (1.3)     │           │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│ somatic_description, n (%)                │ no                                │ 175 (58.1)  │ 82 (57.3)   │ 93 (58.9)   │ 0.881     │\n",
      "├───────────────────────────────────────────┼───────────────────────────────────┼─────────────┼─────────────┼─────────────┼───────────┤\n",
      "│                                           │ yes                               │ 126 (41.9)  │ 61 (42.7)   │ 65 (41.1)   │           │\n",
      "╘═══════════════════════════════════════════╧═══════════════════════════════════╧═════════════╧═════════════╧═════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "# Create the TableOne object\n",
    "table1 = TableOne(\n",
    "    df_redcap_original,\n",
    "    columns=columns,\n",
    "    categorical=categorical,\n",
    "    groupby=group_var,\n",
    "    pval=True,\n",
    "    nonnormal=[],  # Add variables that are non-normally distributed if any\n",
    "    missing=False  # Whether to include missing data\n",
    ")\n",
    "\n",
    "# Print the table\n",
    "print(table1.tabulate(tablefmt=\"fancy_grid\"))\n",
    "table1.to_csv('sample_overview.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb4927-cb7c-4226-a0c0-9652a615ebaa",
   "metadata": {},
   "source": [
    "## Manual Missing data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d03a77b-ff3a-419a-ac90-0829f79b5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also impute activity features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f0b59-51dc-440e-97d0-232deb24e482",
   "metadata": {},
   "source": [
    "#### GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de9b1b1-0583-45bb-baa2-c2d23247fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps<=625'\n",
    "mask = df_ema_passive['missing_GPS'] == 'Steps<=625'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['n_GPS', 'total_distance_km', 'time_in_transition_minutes']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0\n",
    "\n",
    "# For these rows, set the selected columns to 120\n",
    "cols_set_120 = ['time_stationary_minutes']\n",
    "for col in cols_set_120:\n",
    "    df_ema_passive.loc[mask, col] = 120\n",
    "\n",
    "mask = df_ema_passive['missing_GPS_home'] == 'Steps<=625'\n",
    "\n",
    "# For these rows, set the selected columns to 120\n",
    "cols_set_120 = ['at_home_minute']\n",
    "for col in cols_set_120:\n",
    "    df_ema_passive.loc[mask, col] = 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa95db-4e1a-439b-a047-a4be3dfa5ca1",
   "metadata": {},
   "source": [
    "#### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5b5799-48bc-4157-89d9-65c9a3032ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps>625'\n",
    "mask = df_ema_passive['missing_steps'] == 'step_zero'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['n_steps']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f1199-6b99-421e-bb37-c80a2db3bd91",
   "metadata": {},
   "source": [
    "#### Physical Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db57a0f2-b326-4e02-a9cd-5eed2d8be3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where missing_GPS equals 'Steps>625'\n",
    "mask = df_ema_passive['missing_pa'] == 'pa_zero'\n",
    "\n",
    "# For these rows, set the selected columns to 0\n",
    "cols_set_zero = ['activity_102_minutes', 'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes', 'activity_106_minutes', \n",
    "                 'activity_107_minutes']\n",
    "for col in cols_set_zero:\n",
    "    df_ema_passive.loc[mask, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404eb5a-7127-4662-8e68-f7a5cc6ac987",
   "metadata": {},
   "source": [
    "### Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f7e30-e5fd-4101-858c-4a969b999ad9",
   "metadata": {},
   "source": [
    "- prior treatment: ordinal encoding\n",
    "- age: min-max scaling\n",
    "- somatic, employability, psychotropic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef055ac-b39b-45d2-9b97-cc09c98fbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are which\n",
    "binary_features = ['somatic_description', 'psychotropic_description', 'employability_description_simple', 'smartphone_type', 'weekend']\n",
    "categorical_features = ['weekday', 'prior_treatment_description_simple', 'quest_create_hour', 'season', 'time_of_day', 'employability_description_simple']\n",
    "numeric_features = ['age','hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hr_zone_resting', 'hr_zone_moderate','hr_zone_vigorous', 'n_steps', \n",
    "       'n_GPS', 'total_distance_km', 'at_home_minute',\n",
    "       'time_in_transition_minutes', 'time_stationary_minutes', 'activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes',\n",
    "       'apparent_temperature_mean', 'sunshine_duration', 'precipitation_hours'] \n",
    "\n",
    "person_static_features = ['customer', 'age', 'somatic_description', 'psychotropic_description', 'employability_description_simple', 'smartphone_type', 'weekend']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a9b87a6-5f6c-40a7-a751-dc07b6f8662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [sorted(df_ema_passive[feat].dropna().unique()) for feat in categorical_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a496a662-2c83-4c1d-a5ee-9e7cc5999391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Friday',\n",
       "  'Monday',\n",
       "  'Saturday',\n",
       "  'Sunday',\n",
       "  'Thursday',\n",
       "  'Tuesday',\n",
       "  'Wednesday'],\n",
       " ['no prior treatment', 'prior inpatient', 'prior psychotherapy'],\n",
       " [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
       " ['Fall', 'Spring', 'Summer', 'Winter'],\n",
       " ['Afternoon', 'Early Morning', 'Evening', 'Morning', 'Night'],\n",
       " ['no', 'yes']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d9dd96-a71f-4771-a06f-957bc1046a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_passive[numeric_features] = df_ema_passive[numeric_features].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14d7ffc1-a4e8-4e16-adc7-a993ccf09eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewtest,normaltest\n",
    "\n",
    "skewed_features = []\n",
    "for col in numeric_features:\n",
    "    valid_data = df_ema_passive[col].dropna()\n",
    "\n",
    "    # skewtest requires sample size > 7 for reliable results\n",
    "    stat, p_val = skewtest(valid_data)\n",
    "    if p_val < 0.05:\n",
    "        skewed_features.append(col)  # append this feature as skewed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415b57e-f966-47a4-a2dc-63a60f4d6317",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0559dc6-3dda-4a1c-86bd-003e48b57db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_passive[\"intercept\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c484e1ec-bb6e-48c0-bf9b-88bbad964977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_pipeline = df_ema_passive[['customer', 'unique_day_id', \n",
    "       'quest_create_hour', 'weekday', 'weekend', 'season', 'time_of_day',\n",
    "       'n_quest', 'mean_na', 'sensor_block_end', 'age', \n",
    "       'ema_smartphone', 'psychotropic', 'somatic_problems','employability_description_simple',\n",
    "       'prior_treatment_description_simple',\n",
    "       'hr_mean', 'hr_min', 'hr_max', 'hr_std', \n",
    "       'hr_zone_resting', 'hr_zone_moderate',\n",
    "       'hr_zone_vigorous', 'n_steps',  'n_GPS', 'total_distance_km', 'at_home_minute',\n",
    "       'time_in_transition_minutes', 'time_stationary_minutes',\n",
    "       'activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes',\n",
    "       'apparent_temperature_mean', 'sunshine_duration', 'precipitation_hours', 'intercept'\n",
    "      ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e88c8f-986f-4b33-84c3-33db78b9ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_passive['customer'] = df_ema_passive['customer'].astype('string')\n",
    "df_ema_passive.to_csv(\"short_term_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "982f4680-1946-4965-acb4-69258df0d0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: NaNs=0, min=18.0, max=66.0, mean=32.22805878054721, std=9.986262010627621\n",
      "hr_mean: NaNs=362, min=40.583333333333336, max=176.0, mean=76.21038364205769, std=14.42543554669274\n",
      "hr_min: NaNs=362, min=35.0, max=176.0, mean=61.30263488080301, std=11.62405021207671\n",
      "hr_max: NaNs=362, min=42.0, max=211.0, mean=96.8409870347135, std=27.542694611533477\n",
      "hr_std: NaNs=362, min=0.0, max=56.0, mean=10.792436474020727, std=7.9558771372936725\n",
      "hr_zone_resting: NaNs=362, min=0.0, max=32.400000000000006, mean=1.3624361661787256, std=2.2104999178041633\n",
      "hr_zone_moderate: NaNs=362, min=0.0, max=114.00951666666391, mean=5.550823878433013, std=3.4077147994985237\n",
      "hr_zone_vigorous: NaNs=362, min=0.0, max=78.6040666666656, mean=1.0310447901854172, std=3.6420108564005598\n",
      "n_steps: NaNs=198, min=0.0, max=10078.0, mean=842.1961382952388, std=1105.3486861640363\n",
      "n_GPS: NaNs=880, min=0.0, max=1897.0, mean=45.22707003584856, std=113.742096612119\n",
      "total_distance_km: NaNs=880, min=0.0, max=180.0840241629681, mean=2.4437960453651026, std=8.806879758998774\n",
      "at_home_minute: NaNs=880, min=0.0, max=120.0, mean=73.63221234735215, std=49.39772714275031\n",
      "time_in_transition_minutes: NaNs=880, min=0.0, max=119.96583333333334, mean=19.87278301565096, std=31.81578423472624\n",
      "time_stationary_minutes: NaNs=880, min=0.0, max=120.0, mean=77.9195078502521, std=43.21775689190996\n",
      "activity_102_minutes: NaNs=198, min=0.0, max=240.0, mean=23.41615622163545, std=43.57023573614579\n",
      "activity_103_minutes: NaNs=242, min=0.0, max=53.0, mean=0.8093938164251208, std=3.794309336983758\n",
      "activity_104_minutes: NaNs=198, min=0.0, max=120.0, mean=0.34712654922023267, std=3.9193200307391014\n",
      "activity_105_minutes: NaNs=198, min=0.0, max=120.0, mean=3.9812869144868936, std=10.127576311389433\n",
      "activity_106_minutes: NaNs=198, min=0.0, max=56.483333333333334, mean=0.07065372693016476, std=1.4611851783812304\n",
      "activity_107_minutes: NaNs=242, min=0.0, max=120.0, mean=1.0445797915804003, std=6.163612350523643\n",
      "apparent_temperature_mean: NaNs=0, min=-9.589198112487793, max=28.35951805114746, mean=9.605118751525879, std=8.881246566772461\n",
      "sunshine_duration: NaNs=0, min=0.0, max=15.22237777709961, mean=7.318305015563965, std=4.85858678817749\n",
      "precipitation_hours: NaNs=0, min=0.0, max=22.0, mean=4.470000743865967, std=5.333427429199219\n"
     ]
    }
   ],
   "source": [
    "for col in numeric_features:\n",
    "    series = df_ema_pipeline[col]\n",
    "    n_nan = series.isna().sum()\n",
    "    col_min = series.min()\n",
    "    col_max = series.max()\n",
    "    col_mean = series.mean()\n",
    "    col_std = series.std()\n",
    "    print(f\"{col}: NaNs={n_nan}, min={col_min}, max={col_max}, mean={col_mean}, std={col_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee6c4a7a-c437-4a79-a242-7b5efbfe83ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3935256/728832176.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ema_pipeline[\"n_quest_sum\"] = (df_ema_pipeline.groupby('customer')['unique_day_id'].transform('nunique')\n"
     ]
    }
   ],
   "source": [
    "df_ema_pipeline[\"n_quest_sum\"] = (df_ema_pipeline.groupby('customer')['unique_day_id'].transform('nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "879962cc-9a9b-4ef5-b1ab-c036d7bd9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_strat = df_ema_pipeline[[\"customer\", \"n_quest_sum\"]].drop_duplicates()\n",
    "df_ema_strat['n_quest_stratify'] = pd.qcut(df_ema_strat[\"n_quest_sum\"], q=4, labels=False, duplicates=\"drop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b238ac28-13ef-4de8-8477-16369c8ab310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_pipeline= pd.merge(df_ema_pipeline,df_ema_strat, on=[\"customer\", \"n_quest_sum\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f599b7-50f3-4da8-8776-ded831dc3f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [ML_pipeline.py:202] [ML_Pipeline] Configuration Loaded:\n",
      "INFO     [ML_pipeline.py:203]   Impute Strategy: knn\n",
      "INFO     [ML_pipeline.py:204]   Scaler Strategy: minmax\n",
      "INFO     [ML_pipeline.py:205]   Holdout Ratio: 0.1\n",
      "INFO     [ML_pipeline.py:206]   Time Ratio: 0.8\n",
      "INFO     [ML_pipeline.py:207]   Number of Jobs: 1\n",
      "INFO     [ML_pipeline.py:208]   Number of Folds (Inner CV): 5\n",
      "INFO     [ML_pipeline.py:209]   CV Method: forwardchaining (expected 'forwardchaining' here)\n",
      "INFO     [ML_pipeline.py:217] [set_data] DataFrame with 12317 rows loaded in pipeline.\n",
      "INFO     [ML_pipeline.py:288] [outer_user_split] Holdout Users: 15/158 | Holdout Strategy: first_20 | Holdout Size: 224 rows.\n",
      "INFO     [ML_pipeline.py:314] [inner_time_split] Inner train size: 8880, test size: 2290.\n",
      "INFO     [ML_pipeline.py:524] [run] Starting the ML pipeline run method.\n",
      "INFO     [ML_pipeline.py:548] \n",
      "[run] Starting pipeline: Global_Intercept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['hr_max', 'hr_std', 'apparent_temperature_mean', 'at_home_minute', 'activity_104_minutes', 'time_stationary_minutes', 'weekend', 'sunshine_duration', 'season', 'time_of_day', 'hr_mean', 'weekday', 'precipitation_hours', 'hr_zone_moderate', 'activity_106_minutes', 'n_GPS', 'activity_105_minutes', 'activity_107_minutes', 'total_distance_km', 'n_steps', 'activity_102_minutes', 'activity_103_minutes', 'hr_zone_resting', 'hr_zone_vigorous', 'hr_min', 'quest_create_hour', 'time_in_transition_minutes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [ML_pipeline.py:574] [Global_Intercept] Fitting GridSearchCV.\n",
      "INFO     [ML_pipeline.py:118] [PerUserForwardChainingCV] Unique users found: 143\n",
      "INFO     [ML_pipeline.py:576] [Global_Intercept] GridSearchCV completed.\n",
      "INFO     [ML_pipeline.py:577] [Global_Intercept] Best Parameters: {}\n",
      "INFO     [ML_pipeline.py:578] [Global_Intercept] Best CV Score (mae): 0.883\n",
      "INFO     [ML_pipeline.py:613] [Global_Intercept] Inner Test Scores: {'r2': -0.009145076570804545, 'mae': 0.9735838472205831, 'rmse': 1.1884263092171299}\n",
      "INFO     [ML_pipeline.py:548] \n",
      "[run] Starting pipeline: PerUser_Intercept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['hr_max', 'customer', 'hr_std', 'apparent_temperature_mean', 'at_home_minute', 'activity_104_minutes', 'time_stationary_minutes', 'weekend', 'sunshine_duration', 'season', 'time_of_day', 'hr_mean', 'weekday', 'precipitation_hours', 'hr_zone_moderate', 'activity_106_minutes', 'n_GPS', 'activity_105_minutes', 'activity_107_minutes', 'total_distance_km', 'n_steps', 'activity_102_minutes', 'activity_103_minutes', 'hr_zone_resting', 'hr_zone_vigorous', 'hr_min', 'quest_create_hour', 'time_in_transition_minutes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [ML_pipeline.py:574] [PerUser_Intercept] Fitting GridSearchCV.\n",
      "INFO     [ML_pipeline.py:118] [PerUserForwardChainingCV] Unique users found: 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fit completed. Detected 143 unique users.\n",
      "✅ Fit completed. Detected 143 unique users.\n",
      "✅ Fit completed. Detected 143 unique users.\n",
      "✅ Fit completed. Detected 143 unique users.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [ML_pipeline.py:576] [PerUser_Intercept] GridSearchCV completed.\n",
      "INFO     [ML_pipeline.py:577] [PerUser_Intercept] Best Parameters: {}\n",
      "INFO     [ML_pipeline.py:578] [PerUser_Intercept] Best CV Score (mae): 0.600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fit completed. Detected 143 unique users.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [ML_pipeline.py:613] [PerUser_Intercept] Inner Test Scores: {'r2': 0.5216969745545884, 'mae': 0.6124634527085445, 'rmse': 0.8181765326969993}\n",
      "INFO     [ML_pipeline.py:548] \n",
      "[run] Starting pipeline: FFNN_with_Embeddings_nonscaled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['hr_max', 'customer', 'hr_std', 'apparent_temperature_mean', 'at_home_minute', 'activity_104_minutes', 'time_stationary_minutes', 'weekend', 'sunshine_duration', 'season', 'time_of_day', 'hr_mean', 'weekday', 'precipitation_hours', 'hr_zone_moderate', 'activity_106_minutes', 'n_GPS', 'activity_105_minutes', 'activity_107_minutes', 'total_distance_km', 'n_steps', 'activity_102_minutes', 'activity_103_minutes', 'hr_zone_resting', 'hr_zone_vigorous', 'hr_min', 'quest_create_hour', 'time_in_transition_minutes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [ML_pipeline.py:574] [FFNN_with_Embeddings_nonscaled] Fitting GridSearchCV.\n",
      "INFO     [ML_pipeline.py:118] [PerUserForwardChainingCV] Unique users found: 143\n",
      "W0000 00:00:1738869135.256207 3935256 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO     [ML_pipeline.py:576] [FFNN_with_Embeddings_nonscaled] GridSearchCV completed.\n",
      "INFO     [ML_pipeline.py:577] [FFNN_with_Embeddings_nonscaled] Best Parameters: {'keras_model__embedding_dim': 64, 'keras_model__hidden_units': [128, 64]}\n",
      "INFO     [ML_pipeline.py:578] [FFNN_with_Embeddings_nonscaled] Best CV Score (mae): 0.725\n",
      "INFO     [ML_pipeline.py:613] [FFNN_with_Embeddings_nonscaled] Inner Test Scores: {'r2': 0.367950354784516, 'mae': 0.7134900108955833, 'rmse': 0.9405265304590132}\n",
      "INFO     [ML_pipeline.py:548] \n",
      "[run] Starting pipeline: FFNN_with_Embeddings_groupscaled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['hr_max', 'customer', 'hr_std', 'apparent_temperature_mean', 'at_home_minute', 'activity_104_minutes', 'time_stationary_minutes', 'weekend', 'sunshine_duration', 'season', 'time_of_day', 'hr_mean', 'weekday', 'precipitation_hours', 'hr_zone_moderate', 'activity_106_minutes', 'n_GPS', 'activity_105_minutes', 'activity_107_minutes', 'total_distance_km', 'n_steps', 'activity_102_minutes', 'activity_103_minutes', 'hr_zone_resting', 'hr_zone_vigorous', 'hr_min', 'quest_create_hour', 'time_in_transition_minutes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [ML_pipeline.py:574] [FFNN_with_Embeddings_groupscaled] Fitting GridSearchCV.\n",
      "INFO     [ML_pipeline.py:118] [PerUserForwardChainingCV] Unique users found: 143\n"
     ]
    }
   ],
   "source": [
    "from ML_pipeline import MLpipeline\n",
    "from ML_config import Config\n",
    "\n",
    "my_config = Config()\n",
    "pipeline = MLpipeline(my_config)\n",
    "\n",
    "pipeline.set_data(df_ema_pipeline)\n",
    "pipeline.outer_user_split()\n",
    "pipeline.inner_time_split()\n",
    "\n",
    "# (1) Time-based runs\n",
    "results_timebased, results_holdout = pipeline.run(my_config.ANALYSIS[\"neg_affect_regression\"][\"MODEL_PIPEGRIDS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0fafb-7c03-4c32-b6e3-fe9c9cebb8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_results_as_dataframe(results_timebased, holdout_results):\n",
    "    \"\"\"\n",
    "    Formats the results into a structured DataFrame with columns:\n",
    "    - pipeline_name\n",
    "    - best_cv_score\n",
    "    - r2, mae, rmse (inner test scores)\n",
    "    - holdout_r2, holdout_mae, holdout_rmse (holdout test scores)\n",
    "    - hyperparameters (only relevant hyperparameters per model)\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    results_timebased : list\n",
    "        List of dictionaries containing results from ML pipelines.\n",
    "    holdout_results : list\n",
    "        List of dictionaries containing holdout evaluation results.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame displaying structured results.\n",
    "    \"\"\"\n",
    "\n",
    "    formatted_results = []\n",
    "\n",
    "    # Create a mapping of pipeline_name -> holdout_scores for easy lookup\n",
    "    holdout_scores_map = {res[\"pipeline_name\"]: res[\"holdout_scores\"] for res in holdout_results}\n",
    "\n",
    "    for result in results_timebased:\n",
    "        pipeline_name = result[\"pipeline_name\"]\n",
    "        best_cv_score = result[\"best_cv_score\"]\n",
    "        \n",
    "        # Extract inner test scores\n",
    "        inner_test_scores = result[\"inner_test_scores\"]\n",
    "        r2 = inner_test_scores.get(\"r2\", None)\n",
    "        mae = inner_test_scores.get(\"mae\", None)\n",
    "        rmse = inner_test_scores.get(\"rmse\", None)\n",
    "        \n",
    "        # Extract holdout scores if available\n",
    "        holdout_scores = holdout_scores_map.get(pipeline_name, {})\n",
    "        holdout_r2 = holdout_scores.get(\"r2\", None)\n",
    "        holdout_mae = holdout_scores.get(\"mae\", None)\n",
    "        holdout_rmse = holdout_scores.get(\"rmse\", None)\n",
    "\n",
    "        # Extract relevant hyperparameters dynamically\n",
    "        best_estimator = result[\"best_estimator\"]\n",
    "        hyperparameters = {}\n",
    "\n",
    "        if hasattr(best_estimator, 'get_params'):\n",
    "            params = best_estimator.get_params()\n",
    "            \n",
    "            # Select relevant hyperparameters based on known model prefixes\n",
    "            param_keys = [\n",
    "                \"model_LR__fit_intercept\",\n",
    "                \"model_LRPS__fit_intercept\",\n",
    "                \"model_TTR__regressor__n_estimators\",\n",
    "                \"model_TTR__regressor__max_depth\",\n",
    "                \"model_TTR__regressor__min_samples_split\",\n",
    "                \"model_TTR__regressor__max_features\",\n",
    "                \"model_MERF__regressor__max_iterations\",\n",
    "                \"model_MERF__regressor__rf__n_estimators\",\n",
    "                \"model_TTR__regressor__hidden_layer_sizes\",\n",
    "                \"model_TTR__regressor__alpha\"\n",
    "            ]\n",
    "\n",
    "            # Extract only relevant hyperparameters for the current model\n",
    "            for key in param_keys:\n",
    "                if key in params:\n",
    "                    hyperparameters[key] = params[key]\n",
    "\n",
    "        formatted_results.append({\n",
    "            \"pipeline_name\": pipeline_name,\n",
    "            \"best_cv_score\": best_cv_score,\n",
    "            \"r2\": r2,\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"holdout_r2\": holdout_r2,\n",
    "            \"holdout_mae\": holdout_mae,\n",
    "            \"holdout_rmse\": holdout_rmse,\n",
    "            \"hyperparameters\": hyperparameters  # Store extracted hyperparameters\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(formatted_results)\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f9976-207d-4013-8599-d1658110f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = format_results_as_dataframe(results_timebased, results_holdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90b4ab-7ac5-44f7-8877-b431e20b7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b59c2-508f-4dbc-99ed-1094a7b4608f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39-env)",
   "language": "python",
   "name": "py39-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
