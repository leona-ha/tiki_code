{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755b4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date, datetime\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from config import proj_sheet, datapath, credential_path, drivesheet_url\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "scopes = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "          'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = Credentials.from_service_account_file(credential_path, scopes=scopes)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "today = date.today() \n",
    "week_ago = today - dt.timedelta(days=7)\n",
    "today = today.strftime(\"%d%m%Y\")\n",
    "week_ago = week_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# passive + ema_data\n",
    "filepath = datapath + f\"export_{today}.csv\"\n",
    "datapath1 = datapath + f\"export_tiki_{today}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d386d",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310925d",
   "metadata": {},
   "source": [
    "### 1.1 Import epoch level passive + GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e997b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(datapath1, \"epoch_part*.csv\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c21b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the file list to ensure it's in the correct order, if necessary\n",
    "df_complete = pd.concat((pd.read_csv(f, encoding=\"latin-1\", low_memory=False) for f in file_list), ignore_index=True)\n",
    "df_complete[\"customer\"] = df_complete.customer.str.split(\"@\").str.get(0)\n",
    "df_complete[\"customer\"] = df_complete[\"customer\"].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028ae944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete[\"startTimestamp\"] = pd.to_datetime(df_complete[\"startTimestamp\"],unit='ms')\n",
    "df_complete[\"createdAt\"] = pd.to_datetime(df_complete[\"createdAt\"],unit='ms')\n",
    "\n",
    "df_complete[\"startTimestamp_day\"] = df_complete.startTimestamp.dt.strftime('%Y/%m/%d')\n",
    "df_complete[\"createdAt_day\"] = df_complete.startTimestamp.dt.strftime('%Y/%m/%d')\n",
    "\n",
    "df_complete[\"startTimestamp_hour\"] = df_complete.startTimestamp.dt.hour\n",
    "df_complete[\"createdAt_hour\"] = df_complete.startTimestamp.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054db53",
   "metadata": {},
   "source": [
    "### 1.2 Import passive data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f53acf",
   "metadata": {},
   "source": [
    "### Check location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2665c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location data\n",
    "df_loc_complete = df_complete[df_complete.type.isin([\"Latitude\", \"Longitude\"])]\n",
    "df_loc_complete = df_loc_complete[[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\", \n",
    "                           \"timezoneOffset\"]]\n",
    "df_loc_complete[\"startTimestamp\"] = (pd.to_datetime(df_loc_complete[\"startTimestamp\"],unit='ms'))\n",
    "\n",
    "df_loc_complete = df_loc_complete.groupby(\"customer\")[[\"startTimestamp\"]].max().rename_axis(None, axis=1).reset_index()\n",
    "df_loc_complete.rename(columns={\"startTimestamp\":\"last_day_GPS\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82bb03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passive data\n",
    "df_pd_complete = df_complete[df_complete.type.isin([\"HeartRate\", \"AtrialFibrillationDetection\", \"RawECGVoltage\", \n",
    "                                                   \"ActiveBurnedCalories\", 'SleepAwakeBinary','SleepBinary'])]\n",
    "                                                    \n",
    "df_pd_complete = df_pd_complete[[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\", \"timezoneOffset\"]]\n",
    "df_pd_complete[\"startTimestamp\"] = (pd.to_datetime(df_pd_complete[\"startTimestamp\"],unit='ms'))\n",
    "\n",
    "df_pd_complete = df_pd_complete.groupby(\"customer\")[[\"startTimestamp\"]].max().rename_axis(None, axis=1).reset_index()\n",
    "df_pd_complete.rename(columns={\"startTimestamp\":\"last_day_passive\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e96be",
   "metadata": {},
   "source": [
    "### 1.3 Import montoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186f5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project management data\n",
    "df_sheet = pd.read_csv(f\"https://docs.google.com/spreadsheets/d/{proj_sheet}/export?format=csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fbc79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring = df_sheet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f941d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring = df_monitoring[['FOR_ID', 'EMA_ID', 'Pseudonym', 'Studienversion', 'Status',\n",
    "       'Besonderes', 'Start EMA Baseline', 'Ende EMA Baseline',\n",
    "       'Terminpräferenz', 'Termin 1. Gespräch',  'Telefonat stattgefunden?',\n",
    "       'Reminder-Mail Wechsel verschickt?', 'Baseline T20 Update verschickt?', 'Freischaltung/ Start EMA T20',\n",
    "       'Ende EMA T20', 'Post T20 Update verschickt?',\n",
    "       'Studienende/ Dropout Mail verschickt?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2eb4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring.rename(columns = {\"Pseudonym\": \"customer\", \"EMA_ID\": \"ema_id\", \"Status\": \"status\",\n",
    "                                \"Studienversion\":\"study_version\", \"FOR_ID\":\"for_id\", \n",
    "                           \"Start EMA Baseline\": \"ema_base_start\", \"Ende EMA Baseline\": \"ema_base_end\", \n",
    "                           \"Freischaltung/ Start EMA T20\": \"ema_t20_start\",\"Ende EMA T20\":\"ema_t20_end\", \n",
    "                               \"Termin 1. Gespräch\": \"first_call_date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d704c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring[\"customer\"] = df_monitoring[\"customer\"].str[:4]\n",
    "df_active = df_monitoring.copy()\n",
    "df_active = df_active[[\"customer\", \"ema_id\", \"ema_base_end\", \"ema_base_start\", \"study_version\", \"for_id\", \"status\"]]\n",
    "df_active[\"for_id\"] = df_active.for_id.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c156e",
   "metadata": {},
   "source": [
    "### 1.5 Import EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c30bfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "session = pd.read_csv(datapath1 + \"questionnaireSession.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f426b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session data\n",
    "session[\"user\"] = session[\"user\"].str[:4]\n",
    "session.rename(columns = {\"user\":\"customer\",\"completedAt\": \"quest_complete\", \"createdAt\": \"quest_create\", \"expirationTimestamp\": \"quest_expir\"}, inplace=True)\n",
    "session[\"quest_create\"] = (pd.to_datetime(session[\"quest_create\"],unit='ms'))\n",
    "session[\"quest_complete\"] = (pd.to_datetime(session[\"quest_complete\"],unit='ms'))\n",
    "df_sess = session[[\"customer\", \"sessionRun\", \"quest_create\", \"quest_complete\", \"study\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f670143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of completed EMA beeps in first phase\n",
    "df_sess1 = df_sess.loc[df_sess.study.isin([24,25])]\n",
    "sess_count1 = df_sess1.dropna(subset=[\"quest_complete\"]).groupby(\"customer\")[\"quest_complete\"].size()\\\n",
    ".reset_index()\n",
    "sess_count1 = sess_count1.rename(columns = {\"quest_complete\":\"nquest_EMA1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92fb3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of completed EMA beeps in second phase\n",
    "df_sess2 = df_sess.loc[df_sess.study.isin([33,34])]\n",
    "sess_count2 = df_sess2.dropna(subset=[\"quest_complete\"]).groupby(\"customer\")[\"quest_complete\"].size()\\\n",
    ".reset_index()\n",
    "sess_count2 = sess_count2.rename(columns = {\"quest_complete\":\"nquest_EMA2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622eb18",
   "metadata": {},
   "source": [
    "## 2. Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fef120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monitoring and passive\n",
    "df_merged = pd.merge(df_pd_complete, df_active, on=\"customer\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2516c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monitoring and EMA\n",
    "df_merged = pd.merge(df_merged, sess_count1, on=\"customer\", how=\"outer\")\n",
    "df_merged = pd.merge(df_merged, sess_count2, on=\"customer\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34a4cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_merged, df_loc_complete, on=\"customer\", how=\"outer\")\n",
    "df_merged.to_csv(f\"data_compliance_{today}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6daa16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[df_merged['status'].isin(['Erhebung_1_aktiv', 'Post_Erhebung_1', 'Post_Erhebung_2','Erhebung_2_aktiv'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429c7e9",
   "metadata": {},
   "source": [
    "## 3. Check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa935458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get structure of the google spreadsheet\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE/export?format=csv&gid=1512138040\")\n",
    "df = df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9d4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_remove = [\"FOR11001\", \"FOR11034\", \"FOR13023\", \"FOR14013\", \"FOR14064\"]\n",
    "remove_scanwatch = [\"FOR14029\", \"FOR14055\"]\n",
    "remove_gps = [\"FOR13013\", \"FOR14014\", \"FOR13019\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a907530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[~df_merged['for_id'].isin(users_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "319aaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no pd since 7 days \n",
    "\n",
    "list_no_pd = df_merged.loc[(df_merged.last_day_GPS > week_ago) & (df_merged.last_day_passive < week_ago)][\"for_id\"].tolist()\n",
    "list_no_pd = [string for string in list_no_pd if string not in remove_scanwatch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5adefa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps for > 7 days \n",
    "list_no_gps = df_merged.loc[(df_merged.last_day_GPS < week_ago)& (df_merged.last_day_passive > week_ago)][\"for_id\"].tolist()\n",
    "list_no_gps = [string for string in list_no_gps if string not in remove_gps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "963b30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps and no pd for > 7 days\n",
    "\n",
    "list_no_gpspd = df_merged.loc[(df_merged.last_day_GPS < week_ago) & (df_merged.last_day_passive < week_ago)][\"for_id\"].tolist()\n",
    "list_no_gpspd = [string for string in list_no_gpspd if string not in users_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c66972ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps at all \n",
    "\n",
    "list_no_gps_at_all = df_merged.loc[df_merged.last_day_GPS.isna()].for_id.tolist()\n",
    "list_no_gps_at_all = [string for string in list_no_gps_at_all if string not in remove_gps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4be2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append each list to the DataFrame\n",
    "date_today = datetime.today().date()\n",
    "for column_name, entries in zip(['no_pd', 'no_gps', 'no_gpspd', 'no_gps_at_all'], \n",
    "                                [list_no_pd, list_no_gps, list_no_gpspd, list_no_gps_at_all]):\n",
    "    # Create a new DataFrame for the current list\n",
    "    temp_df = pd.DataFrame(entries, columns=[column_name])\n",
    "    \n",
    "    # Add the \"Datum\" column with today's date\n",
    "    temp_df['Datum'] = date_today\n",
    "    \n",
    "    # Since we're appending column-wise, we align other columns by setting them to NaN\n",
    "    # This step ensures the DataFrame has all the necessary columns\n",
    "    for col in df.columns:\n",
    "        if col not in temp_df.columns:\n",
    "            temp_df[col] = \"\"\n",
    "    \n",
    "    # Concatenate the new DataFrame to the original DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Reorder df columns to match the original order, if necessary\n",
    "df = df[['Datum', 'no_pd', 'no_gps', 'no_gpspd', 'data_deleted', \n",
    "         'no_gps_at_all', 'Status', 'Smartphone', 'Grund', \n",
    "         'Grund (frei)', 'Unnamed: 10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6304b",
   "metadata": {},
   "source": [
    "## 4. Create Monitoring Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10b9494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_str):\n",
    "# Remove the day of the week by splitting on the comma and taking the second part\n",
    "    date_part = date_str.split(\", \")[1]\n",
    "    return date_part\n",
    "\n",
    "# Apply the conversion function to preprocess the dates\n",
    "df_monitoring['first_call_date'] = df_monitoring['first_call_date'].apply(convert_date)\n",
    "\n",
    "# Convert the preprocessed date strings to datetime objects\n",
    "df_monitoring['first_call_date'] = pd.to_datetime(df_monitoring['first_call_date'], format=\"%d.%m.%Y\")\n",
    "\n",
    "date_columns = [\"ema_base_end\", \"ema_base_start\", \"ema_t20_start\", \"ema_t20_end\", \"first_call_date\"]\n",
    "df_monitoring = df_monitoring.copy()\n",
    "\n",
    "# Convert multiple columns to datetime'\n",
    "for col in date_columns:\n",
    "    df_monitoring[col] = pd.to_datetime(df_monitoring[col], errors='coerce', dayfirst=True).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcf9ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamp for today\n",
    "today = pd.Timestamp(\"today\")\n",
    "\n",
    "# Calculate the day of the week for today, where Monday is 0 and Sunday is 6\n",
    "today_day_of_week = today.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14abb09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday 29.04:  Kurzversion Ende: ['FOR14106', 'FOR14107']\n",
      "Tuesday 30.04:  Onboarding Call: ['FOR11072', 'FOR13044 ', 'FOR14112']; Baseline Ende Lang (Status ändern): ['FOR11070']\n",
      "Wednesday 01.05:  Kurzversion Wechsel Reminder: ['FOR11071']\n",
      "Thursday 02.05:  Onboarding Call: ['FOR11074 ']; Kurzversion Wechsel Reminder: ['FOR14110', 'FOR14109']; Baseline Ende Lang (Status ändern): ['FOR14104', 'FOR14105']; T20 Ende (Status ändern): ['FOR12010']; Kurzversion Ende: ['FOR11071']\n",
      "Friday 03.05:  Kurzversion Ende: ['FOR14110', 'FOR14109']\n",
      "Saturday 04.05:  Baseline Ende Lang (Status ändern): ['FOR12043']\n",
      "Sunday 05.05:  Kurzversion Wechsel Reminder: ['FOR14111 ', 'FOR11072']\n"
     ]
    }
   ],
   "source": [
    "# Use today's date, but focus only on the date part\n",
    "today = pd.Timestamp(\"today\").date()\n",
    "\n",
    "\n",
    "# Calculate the most recent Monday as the start of the week\n",
    "week_start_date = today - pd.Timedelta(days=today.weekday())\n",
    "\n",
    "# Loop through each day of the week from Monday to Friday\n",
    "for day in range(7):  # Monday to Friday\n",
    "    target_date = week_start_date + pd.Timedelta(days=day)\n",
    "\n",
    "    # Format the date to include the weekday name and day.month\n",
    "    formatted_date = target_date.strftime(\"%A %d.%m\")  # e.g., \"Monday 12.02\"\n",
    "\n",
    "    # Initialize message list\n",
    "    messages = []\n",
    "\n",
    "    # Assuming the filtering logic is already correctly implemented\n",
    "\n",
    "    # Debug prints to check if conditions are met (example messages for illustration)\n",
    "    \n",
    "    onboarding_ids = df_monitoring[df_monitoring['first_call_date'] == target_date]['for_id'].tolist()      \n",
    "    \n",
    "    reminder_ids = df_monitoring[(df_monitoring['ema_base_end'] == (target_date + pd.Timedelta(days=1))) &\n",
    "                                 (df_monitoring['study_version'].isin(['Kurz', 'Kurz (Wechsel/Abbruch)']))]['for_id'].tolist()\n",
    "\n",
    "    baseline_ended_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date - pd.Timedelta(days=1)) &\n",
    "                                       (df_monitoring['study_version'].isin(['Lang', 'Lang(Wechsel)']))]['for_id'].tolist()\n",
    "    \n",
    "    study_finished_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date) &\n",
    "                                       (df_monitoring['study_version'].isin(['Kurz', 'Kurz (Wechsel/Abbruch)']))]['for_id'].tolist()\n",
    "\n",
    "    t20_ended_ids = df_monitoring[df_monitoring['ema_t20_end'] == (target_date - pd.Timedelta(days=1))]['for_id'].tolist()\n",
    "    \n",
    "    t20_start_ids = df_monitoring[df_monitoring['ema_t20_start'] == target_date]['for_id'].tolist()\n",
    "\n",
    "\n",
    "    if onboarding_ids:\n",
    "        messages.append(f\"Onboarding Call: {onboarding_ids}\")\n",
    "    if reminder_ids:\n",
    "        messages.append(f\"Kurzversion Wechsel Reminder: {reminder_ids}\")\n",
    "    if baseline_ended_ids:\n",
    "        messages.append(f\"Baseline Ende Lang (Status ändern): {baseline_ended_ids}\")\n",
    "    if t20_start_ids:\n",
    "        messages.append(f\"T20 Start (Status ändern): {t20_start_ids}\")\n",
    "    if t20_ended_ids:\n",
    "        messages.append(f\"T20 Ende (Status ändern): {t20_ended_ids}\")\n",
    "    if study_finished_ids:\n",
    "        messages.append(f\"Kurzversion Ende: {study_finished_ids}\")\n",
    "\n",
    "    # Print the formatted date along with the actions\n",
    "    if messages:\n",
    "        print(f\"{formatted_date}: \", \"; \".join(messages))\n",
    "    else:\n",
    "        print(f\"{formatted_date}: No actions needed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8b93a",
   "metadata": {},
   "source": [
    "## 5. Export missing data to google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd9ca8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.applymap(str).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2dba8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a google sheet\n",
    "gs = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE\")\n",
    "# select a work sheet from its name\n",
    "worksheet1 = gs.worksheet('Datenqualität')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc3809d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/gx19nmhj6v30dlkkh5nfp5xh0000gn/T/ipykernel_28836/4283573234.py:8: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet1.update(start_range, missing_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE',\n",
       " 'updatedRange': \"'Datenqualität'!A779:K810\",\n",
       " 'updatedRows': 32,\n",
       " 'updatedColumns': 11,\n",
       " 'updatedCells': 352}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "next_row = len(worksheet1.col_values(1)) + 1  # Assuming column A has index 1\n",
    "\n",
    "# Construct the range string where you want to start appending data\n",
    "# For example, if starting from column A and the next available row is 10, the range would be 'A10'\n",
    "start_range = f'A{next_row}'\n",
    "\n",
    "# Use the update method to append data starting from the specified cell\n",
    "worksheet1.update(start_range, missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eea0a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE/export?format=csv&gid=1512138040\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28951a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame\n",
    "df_long = df_missing.melt(id_vars=[\"Datum\"], value_vars=[\"no_pd\", \"no_gps\", \"no_gpspd\"], var_name=\"condition\", value_name=\"for_id\")\n",
    "\n",
    "# Drop rows where ID is NaN\n",
    "df_long = df_long.dropna(subset=[\"for_id\"])\n",
    "\n",
    "# Count occurrences of each ID per condition\n",
    "df_count = df_long.groupby(\"for_id\")[\"condition\"].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Optionally, rename columns back to original condition names for clarity\n",
    "df_count.columns = [\"no_pd_count\", \"no_gps_count\", \"no_gpspd_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ee80a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count[\"missing_sum\"] = df_count.no_pd_count + df_count.no_gps_count + df_count.no_gpspd_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "724f90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count[\"missing_relative\"] = df_count.missing_sum / df_long.Datum.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72a7fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pd.merge(df_active, df_count, on = \"for_id\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5b8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
