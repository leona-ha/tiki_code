{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755b4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date, datetime\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from config import proj_sheet, datapath, credential_path, drivesheet_url\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "scopes = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "          'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = Credentials.from_service_account_file(credential_path, scopes=scopes)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "today = date.today() \n",
    "week_ago = today - dt.timedelta(days=7)\n",
    "today = today.strftime(\"%d%m%Y\")\n",
    "week_ago = week_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# passive + ema_data\n",
    "filepath = datapath + f\"export_{today}.csv\"\n",
    "datapath1 = datapath + f\"export_tiki_{today}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d386d",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310925d",
   "metadata": {},
   "source": [
    "### 1.1 Import epoch level passive + GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e997b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(datapath1, \"epoch_part*.csv\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c21b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the file list to ensure it's in the correct order, if necessary\n",
    "df_complete = pd.concat((pd.read_csv(f, encoding=\"latin-1\", low_memory=False) for f in file_list), ignore_index=True)\n",
    "df_complete[\"customer\"] = df_complete.customer.str.split(\"@\").str.get(0)\n",
    "df_complete[\"customer\"] = df_complete[\"customer\"].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028ae944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete[\"startTimestamp\"] = pd.to_datetime(df_complete[\"startTimestamp\"],unit='ms')\n",
    "df_complete[\"createdAt\"] = pd.to_datetime(df_complete[\"createdAt\"],unit='ms')\n",
    "\n",
    "df_complete[\"startTimestamp_day\"] = df_complete.startTimestamp.dt.strftime('%Y/%m/%d')\n",
    "df_complete[\"createdAt_day\"] = df_complete.startTimestamp.dt.strftime('%Y/%m/%d')\n",
    "\n",
    "df_complete[\"startTimestamp_hour\"] = df_complete.startTimestamp.dt.hour\n",
    "df_complete[\"createdAt_hour\"] = df_complete.startTimestamp.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054db53",
   "metadata": {},
   "source": [
    "### 1.2 Import passive data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f53acf",
   "metadata": {},
   "source": [
    "### Check location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2665c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location data\n",
    "df_loc_complete = df_complete[df_complete.type.isin([\"Latitude\", \"Longitude\"])]\n",
    "df_loc_complete = df_loc_complete[[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\", \n",
    "                           \"timezoneOffset\"]]\n",
    "df_loc_complete[\"startTimestamp\"] = (pd.to_datetime(df_loc_complete[\"startTimestamp\"],unit='ms'))\n",
    "\n",
    "df_loc_complete = df_loc_complete.groupby(\"customer\")[[\"startTimestamp\"]].max().rename_axis(None, axis=1).reset_index()\n",
    "df_loc_complete.rename(columns={\"startTimestamp\":\"last_day_GPS\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82bb03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passive data\n",
    "df_pd_complete = df_complete[df_complete.type.isin([\"HeartRate\", \"AtrialFibrillationDetection\", \"RawECGVoltage\", \n",
    "                                                   \"ActiveBurnedCalories\", 'SleepAwakeBinary','SleepBinary'])]\n",
    "                                                    \n",
    "df_pd_complete = df_pd_complete[[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\", \"timezoneOffset\"]]\n",
    "df_pd_complete[\"startTimestamp\"] = (pd.to_datetime(df_pd_complete[\"startTimestamp\"],unit='ms'))\n",
    "\n",
    "df_pd_complete = df_pd_complete.groupby(\"customer\")[[\"startTimestamp\"]].max().rename_axis(None, axis=1).reset_index()\n",
    "df_pd_complete.rename(columns={\"startTimestamp\":\"last_day_passive\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e96be",
   "metadata": {},
   "source": [
    "### 1.3 Import montoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186f5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project management data\n",
    "df_sheet = pd.read_csv(f\"https://docs.google.com/spreadsheets/d/{proj_sheet}/export?format=csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fbc79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring = df_sheet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f941d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring = df_monitoring[['FOR_ID', 'EMA_ID', 'Pseudonym', 'Studienversion', 'Status',\n",
    "       'Besonderes', 'Start EMA Baseline', 'Ende EMA Baseline',\n",
    "       'Terminpräferenz', 'Termin 1. Gespräch',  'Telefonat stattgefunden?', 'Baseline T20 Update verschickt?', 'Freischaltung/ Start EMA T20',\n",
    "       'Ende EMA T20', 'Freischaltung/ Start EMA Post','Ende EMA Post','Post T20 Update verschickt?',\n",
    "       'Studienende/ Dropout Mail verschickt?', 'T20=Post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2eb4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring.rename(columns = {\"Pseudonym\": \"customer\", \"EMA_ID\": \"ema_id\", \"Status\": \"status\",\n",
    "                                \"Studienversion\":\"study_version\", \"FOR_ID\":\"for_id\", \n",
    "                           \"Start EMA Baseline\": \"ema_base_start\", \"Ende EMA Baseline\": \"ema_base_end\", \n",
    "                           \"Freischaltung/ Start EMA T20\": \"ema_t20_start\",\"Ende EMA T20\":\"ema_t20_end\", \n",
    "                               \"Termin 1. Gespräch\": \"first_call_date\", \"Freischaltung/ Start EMA Post\":\"ema_post_start\",\n",
    "                               \"Ende EMA Post\":\"ema_post_end\", \"T20=Post\":\"t20_post\" }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d704c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monitoring[\"customer\"] = df_monitoring[\"customer\"].str[:4]\n",
    "df_active = df_monitoring.copy()\n",
    "df_active = df_active[[\"customer\", \"ema_id\", \"ema_base_end\", \"ema_base_start\", \"study_version\", \"for_id\", \"status\"]]\n",
    "df_active[\"for_id\"] = df_active.for_id.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c156e",
   "metadata": {},
   "source": [
    "### 1.5 Import EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c30bfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "session = pd.read_csv(datapath1 + \"questionnaireSession.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f426b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session data\n",
    "session[\"user\"] = session[\"user\"].str[:4]\n",
    "session.rename(columns = {\"user\":\"customer\",\"completedAt\": \"quest_complete\", \"createdAt\": \"quest_create\", \"expirationTimestamp\": \"quest_expir\"}, inplace=True)\n",
    "session[\"quest_create\"] = (pd.to_datetime(session[\"quest_create\"],unit='ms'))\n",
    "session[\"quest_complete\"] = (pd.to_datetime(session[\"quest_complete\"],unit='ms'))\n",
    "df_sess = session[[\"customer\", \"sessionRun\", \"quest_create\", \"quest_complete\", \"study\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f670143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of completed EMA beeps in first phase\n",
    "df_sess1 = df_sess.loc[df_sess.study.isin([24,25])]\n",
    "sess_count1 = df_sess1.dropna(subset=[\"quest_complete\"]).groupby(\"customer\")[\"quest_complete\"].size()\\\n",
    ".reset_index()\n",
    "sess_count1 = sess_count1.rename(columns = {\"quest_complete\":\"nquest_EMA1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92fb3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of completed EMA beeps in second phase\n",
    "df_sess2 = df_sess.loc[df_sess.study.isin([33,34])]\n",
    "sess_count2 = df_sess2.dropna(subset=[\"quest_complete\"]).groupby(\"customer\")[\"quest_complete\"].size()\\\n",
    ".reset_index()\n",
    "sess_count2 = sess_count2.rename(columns = {\"quest_complete\":\"nquest_EMA2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622eb18",
   "metadata": {},
   "source": [
    "## 2. Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fef120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monitoring and passive\n",
    "df_merged = pd.merge(df_pd_complete, df_active, on=\"customer\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2516c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monitoring and EMA\n",
    "df_merged = pd.merge(df_merged, sess_count1, on=\"customer\", how=\"outer\")\n",
    "df_merged = pd.merge(df_merged, sess_count2, on=\"customer\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34a4cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_merged, df_loc_complete, on=\"customer\", how=\"outer\")\n",
    "df_merged.to_csv(f\"data_compliance_{today}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6daa16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[df_merged['status'].isin(['Erhebung_1_aktiv', 'Post_Erhebung_1', 'Post_Erhebung_2','Erhebung_2_aktiv'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429c7e9",
   "metadata": {},
   "source": [
    "## 3. Check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa935458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get structure of the google spreadsheet\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE/export?format=csv&gid=1512138040\")\n",
    "df = df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9d4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#users_to_remove = [\"FOR11001\", \"FOR11034\", \"FOR13023\", \"FOR14013\", \"FOR14064\"]\n",
    "users_to_remove = [\"FOR13016\", \"FOR11022\", \"FOR14062\", \"FOR11012\"]\n",
    "remove_scanwatch = [\"FOR14029\", \"FOR14055\", \"FOR14080\", \"FOR12027\", \"FOR14002\", \"FOR14003\", \"FOR11001\"]\n",
    "remove_gps = [\"FOR13013\", \"FOR14014\", \"FOR13019\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a907530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[~df_merged['for_id'].isin(users_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "319aaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no pd since 7 days \n",
    "\n",
    "list_no_pd = df_merged.loc[(df_merged.last_day_GPS > week_ago) & (df_merged.last_day_passive < week_ago)][\"for_id\"].tolist()\n",
    "list_no_pd = [string for string in list_no_pd if string not in remove_scanwatch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5adefa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps for > 7 days \n",
    "list_no_gps = df_merged.loc[(df_merged.last_day_GPS < week_ago)& (df_merged.last_day_passive > week_ago)][\"for_id\"].tolist()\n",
    "list_no_gps = [string for string in list_no_gps if string not in remove_gps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "963b30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps and no pd for > 7 days\n",
    "\n",
    "list_no_gpspd = df_merged.loc[(df_merged.last_day_GPS < week_ago) & (df_merged.last_day_passive < week_ago)][\"for_id\"].tolist()\n",
    "list_no_gpspd = [string for string in list_no_gpspd if string not in users_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c66972ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gps at all \n",
    "\n",
    "list_no_gps_at_all = df_merged.loc[df_merged.last_day_GPS.isna()].for_id.tolist()\n",
    "list_no_gps_at_all = [string for string in list_no_gps_at_all if string not in remove_gps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4be2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append each list to the DataFrame\n",
    "date_today = datetime.today().date()\n",
    "for column_name, entries in zip(['no_pd', 'no_gps', 'no_gpspd', 'no_gps_at_all'], \n",
    "                                [list_no_pd, list_no_gps, list_no_gpspd, list_no_gps_at_all]):\n",
    "    # Create a new DataFrame for the current list\n",
    "    temp_df = pd.DataFrame(entries, columns=[column_name])\n",
    "    \n",
    "    # Add the \"Datum\" column with today's date\n",
    "    temp_df['Datum'] = date_today\n",
    "    \n",
    "    # Since we're appending column-wise, we align other columns by setting them to NaN\n",
    "    # This step ensures the DataFrame has all the necessary columns\n",
    "    for col in df.columns:\n",
    "        if col not in temp_df.columns:\n",
    "            temp_df[col] = \"\"\n",
    "    \n",
    "    # Concatenate the new DataFrame to the original DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Reorder df columns to match the original order, if necessary\n",
    "df = df[['Datum', 'no_pd', 'no_gps', 'no_gpspd', 'data_deleted', \n",
    "         'no_gps_at_all', 'Status', 'Smartphone', 'Grund', \n",
    "         'Grund (frei)', 'Unnamed: 10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6304b",
   "metadata": {},
   "source": [
    "## 4. Create Monitoring Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10b9494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_str):\n",
    "    if isinstance(date_str, str):\n",
    "        # Remove the day of the week by splitting on the comma and taking the second part\n",
    "        date_part = date_str.split(\", \")[1]\n",
    "        return date_part\n",
    "    else:\n",
    "        return date_str  # Return the value as is if it's not a string\n",
    "\n",
    "# Apply the conversion function to preprocess the dates\n",
    "df_monitoring['first_call_date'] = df_monitoring['first_call_date'].apply(convert_date)\n",
    "\n",
    "# Convert the preprocessed date strings to datetime objects\n",
    "df_monitoring['first_call_date'] = pd.to_datetime(df_monitoring['first_call_date'], format=\"%d.%m.%Y\")\n",
    "\n",
    "date_columns = [\"ema_base_end\", \"ema_base_start\", \"ema_t20_start\", \"ema_t20_end\", \"first_call_date\"]\n",
    "df_monitoring = df_monitoring.copy()\n",
    "\n",
    "# Convert multiple columns to datetime'\n",
    "for col in date_columns:\n",
    "    df_monitoring[col] = pd.to_datetime(df_monitoring[col], errors='coerce', dayfirst=True).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46c1446a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>for_id</th>\n",
       "      <th>ema_id</th>\n",
       "      <th>customer</th>\n",
       "      <th>study_version</th>\n",
       "      <th>status</th>\n",
       "      <th>Besonderes</th>\n",
       "      <th>ema_base_start</th>\n",
       "      <th>ema_base_end</th>\n",
       "      <th>Terminpräferenz</th>\n",
       "      <th>first_call_date</th>\n",
       "      <th>Telefonat stattgefunden?</th>\n",
       "      <th>Baseline T20 Update verschickt?</th>\n",
       "      <th>ema_t20_start</th>\n",
       "      <th>ema_t20_end</th>\n",
       "      <th>ema_post_start</th>\n",
       "      <th>ema_post_end</th>\n",
       "      <th>Post T20 Update verschickt?</th>\n",
       "      <th>Studienende/ Dropout Mail verschickt?</th>\n",
       "      <th>t20_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOR11905</td>\n",
       "      <td>EMA1001</td>\n",
       "      <td>4MLe</td>\n",
       "      <td>Lang</td>\n",
       "      <td>Post_Erhebung_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>Montag , Dienstag, Mittwoch Nachmittag ab 14 Uhr</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>ja</td>\n",
       "      <td>05.09.2023</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOR11001</td>\n",
       "      <td>EMA1003</td>\n",
       "      <td>kVhY</td>\n",
       "      <td>Lang (Wechsel)</td>\n",
       "      <td>Post_Erhebung_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>flexibel</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>ja</td>\n",
       "      <td>04.09.2023</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOR11003</td>\n",
       "      <td>EMA1002</td>\n",
       "      <td>N3CY</td>\n",
       "      <td>Lang</td>\n",
       "      <td>Abgeschlossen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>flexibel</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>ja</td>\n",
       "      <td>29.09.2023</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOR11005</td>\n",
       "      <td>EMA1002</td>\n",
       "      <td>N3CY</td>\n",
       "      <td>Lang</td>\n",
       "      <td>Abgeschlossen</td>\n",
       "      <td>Non-Starter</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>Mo-Fr ab 17 Uhr</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>ja</td>\n",
       "      <td>26.09.2023</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOR14903</td>\n",
       "      <td>EMA4001</td>\n",
       "      <td>5qL5</td>\n",
       "      <td>Kurz</td>\n",
       "      <td>Abgeschlossen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>Mittwoch &amp; Donnerstag Nachmittag. (Aber Donner...</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>FOR13054</td>\n",
       "      <td>EMA3114</td>\n",
       "      <td>lcRv</td>\n",
       "      <td>Lang</td>\n",
       "      <td>Erhebung_1_aktiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>Mittwoch 03.07. vormittags oder Donnerstagvorm...</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>FOR12050</td>\n",
       "      <td>EMA2052</td>\n",
       "      <td>7nRn</td>\n",
       "      <td>Lang</td>\n",
       "      <td>Erhebung_1_aktiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>täglich 10:00 bis 14:00 Uhr</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>FOR11100</td>\n",
       "      <td>EMA1105</td>\n",
       "      <td>gpH8</td>\n",
       "      <td>Lang</td>\n",
       "      <td>Erhebung_1_aktiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>2024-07-17</td>\n",
       "      <td>täglich bis 12 Uhr</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>FOR14129</td>\n",
       "      <td>EMA4140</td>\n",
       "      <td>6lbm</td>\n",
       "      <td>Kurz</td>\n",
       "      <td>Erhebung_1_aktiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-05</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>Gut erreichbar taeglich ab 14.00</td>\n",
       "      <td>2024-07-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>FOR11101</td>\n",
       "      <td>EMA1102</td>\n",
       "      <td>gpv9</td>\n",
       "      <td>Kurz</td>\n",
       "      <td>Erhebung_1_aktiv</td>\n",
       "      <td>Tiki App hat zunächst nicht geöffnet; Verbindu...</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>täglich 9-14 Uhr\\nPat. muss zwei Mal direkt hi...</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       for_id   ema_id customer   study_version            status  \\\n",
       "0    FOR11905  EMA1001     4MLe            Lang   Post_Erhebung_2   \n",
       "1    FOR11001  EMA1003     kVhY  Lang (Wechsel)   Post_Erhebung_2   \n",
       "2    FOR11003  EMA1002     N3CY            Lang     Abgeschlossen   \n",
       "3    FOR11005  EMA1002     N3CY            Lang     Abgeschlossen   \n",
       "4    FOR14903  EMA4001     5qL5            Kurz     Abgeschlossen   \n",
       "..        ...      ...      ...             ...               ...   \n",
       "252  FOR13054  EMA3114     lcRv            Lang  Erhebung_1_aktiv   \n",
       "253  FOR12050  EMA2052     7nRn            Lang  Erhebung_1_aktiv   \n",
       "254  FOR11100  EMA1105     gpH8            Lang  Erhebung_1_aktiv   \n",
       "255  FOR14129  EMA4140     6lbm            Kurz  Erhebung_1_aktiv   \n",
       "256  FOR11101  EMA1102     gpv9            Kurz  Erhebung_1_aktiv   \n",
       "\n",
       "                                            Besonderes ema_base_start  \\\n",
       "0                                                  NaN     2023-05-17   \n",
       "1                                                  NaN     2023-05-26   \n",
       "2                                                  NaN     2023-05-31   \n",
       "3                                          Non-Starter     2023-06-06   \n",
       "4                                                  NaN     2023-06-12   \n",
       "..                                                 ...            ...   \n",
       "252                                                NaN     2024-07-01   \n",
       "253                                                NaN     2024-07-02   \n",
       "254                                                NaN     2024-07-03   \n",
       "255                                                NaN     2024-07-05   \n",
       "256  Tiki App hat zunächst nicht geöffnet; Verbindu...     2024-07-08   \n",
       "\n",
       "    ema_base_end                                    Terminpräferenz  \\\n",
       "0     2023-05-31   Montag , Dienstag, Mittwoch Nachmittag ab 14 Uhr   \n",
       "1     2023-06-09                                           flexibel   \n",
       "2     2023-06-14                                           flexibel   \n",
       "3     2023-06-20                                    Mo-Fr ab 17 Uhr   \n",
       "4     2023-06-26  Mittwoch & Donnerstag Nachmittag. (Aber Donner...   \n",
       "..           ...                                                ...   \n",
       "252   2024-07-15  Mittwoch 03.07. vormittags oder Donnerstagvorm...   \n",
       "253   2024-07-16                        täglich 10:00 bis 14:00 Uhr   \n",
       "254   2024-07-17                                 täglich bis 12 Uhr   \n",
       "255   2024-07-19                   Gut erreichbar taeglich ab 14.00   \n",
       "256   2024-07-22  täglich 9-14 Uhr\\nPat. muss zwei Mal direkt hi...   \n",
       "\n",
       "    first_call_date Telefonat stattgefunden? Baseline T20 Update verschickt?  \\\n",
       "0        2023-05-24                       ja                      05.09.2023   \n",
       "1        2023-05-31                       ja                      04.09.2023   \n",
       "2        2023-06-05                       ja                      29.09.2023   \n",
       "3        2023-06-13                       ja                      26.09.2023   \n",
       "4        2023-06-15                       ja                             NaN   \n",
       "..              ...                      ...                             ...   \n",
       "252      2024-07-03                       ja                             NaN   \n",
       "253      2024-07-08                      NaN                             NaN   \n",
       "254      2024-07-04                       ja                             NaN   \n",
       "255      2024-07-09                      NaN                             NaN   \n",
       "256      2024-07-10                      NaN                             NaN   \n",
       "\n",
       "    ema_t20_start ema_t20_end ema_post_start  ema_post_end  \\\n",
       "0      2023-10-26  2023-11-09            NaN           NaN   \n",
       "1             NaT         NaT            NaN           NaN   \n",
       "2             NaT         NaT            NaN           NaN   \n",
       "3      2024-01-10  2024-01-24            NaN           NaN   \n",
       "4             NaT         NaT            NaN           NaN   \n",
       "..            ...         ...            ...           ...   \n",
       "252           NaN         NaN            NaN           NaN   \n",
       "253           NaN         NaN            NaN           NaN   \n",
       "254           NaN         NaN            NaN           NaN   \n",
       "255           NaN         NaN            NaN           NaN   \n",
       "256           NaN         NaN            NaN           NaN   \n",
       "\n",
       "    Post T20 Update verschickt? Studienende/ Dropout Mail verschickt? t20_post  \n",
       "0                            ja                                   NaN      NaN  \n",
       "1                            ja                                   NaN      NaN  \n",
       "2                           NaN                                   NaN      NaN  \n",
       "3                           NaN                                   NaN       ja  \n",
       "4                           NaN                                    ja      NaN  \n",
       "..                          ...                                   ...      ...  \n",
       "252                         NaN                                   NaN      NaN  \n",
       "253                         NaN                                   NaN      NaN  \n",
       "254                         NaN                                   NaN      NaN  \n",
       "255                         NaN                                   NaN      NaN  \n",
       "256                         NaN                                   NaN      NaN  \n",
       "\n",
       "[257 rows x 19 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51b84e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monitoring.for_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcf9ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamp for today\n",
    "today = pd.Timestamp(\"today\")\n",
    "\n",
    "# Calculate the day of the week for today, where Monday is 0 and Sunday is 6\n",
    "today_day_of_week = today.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14abb09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday 08.07:  Onboarding Call: ['FOR12050']; Kurzversion end today, send mail: ['FOR14126 ']\n",
      "Tuesday 09.07:  Onboarding Call: ['FOR14129']; T20 Ende (Status ändern): ['FOR14022', 'FOR13018']; Kurzversion Ende, change status: ['FOR14126 ']\n",
      "Wednesday 10.07:  Onboarding Call: ['FOR14126 ', 'FOR11101']\n",
      "Thursday 11.07:  Baseline Ende Lang (Status ändern): ['FOR11095 ', 'FOR14123']\n",
      "Friday 12.07:  T20 Ende (Status ändern): ['FOR12022']; Kurzversion end today, send mail: ['FOR11096']; Person has finished Langversion, send reward, Redcap eCRF auf Complete setzen: ['FOR12022']\n",
      "Saturday 13.07:  T20 Ende (Status ändern): ['FOR14026']; Kurzversion Ende, change status: ['FOR11096']; Person has finished Langversion, send reward, Redcap eCRF auf Complete setzen: ['FOR14026']\n",
      "Sunday 14.07: No actions needed\n"
     ]
    }
   ],
   "source": [
    "# Use today's date, but focus only on the date part\n",
    "today = pd.Timestamp(\"today\").date()\n",
    "\n",
    "\n",
    "# Calculate the most recent Monday as the start of the week\n",
    "week_start_date = today - pd.Timedelta(days=today.weekday())\n",
    "\n",
    "# Loop through each day of the week from Monday to Friday\n",
    "for day in range(7):  # Monday to Friday\n",
    "    target_date = week_start_date + pd.Timedelta(days=day)\n",
    "\n",
    "    # Format the date to include the weekday name and day.month\n",
    "    formatted_date = target_date.strftime(\"%A %d.%m\")  # e.g., \"Monday 12.02\"\n",
    "\n",
    "    # Initialize message list\n",
    "    messages = []\n",
    "\n",
    "    # Assuming the filtering logic is already correctly implemented\n",
    "\n",
    "    # Debug prints to check if conditions are met (example messages for illustration)\n",
    "    \n",
    "    onboarding_ids = df_monitoring[df_monitoring['first_call_date'] == target_date]['for_id'].tolist()      \n",
    "    \n",
    "    baseline_ended_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date - pd.Timedelta(days=1)) &\n",
    "                                       (df_monitoring['study_version'].isin(['Lang', 'Lang(Wechsel)']))]['for_id'].tolist()\n",
    "    \n",
    "    study_short_finished_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date) &\n",
    "                                       (df_monitoring['study_version'].isin(['Kurz', 'Kurz (Wechsel/Abbruch)']))]['for_id'].tolist()\n",
    "    \n",
    "    study_finished_ids = df_monitoring[(df_monitoring['ema_base_end'] == target_date - pd.Timedelta(days=1)) &\n",
    "                                       (df_monitoring['study_version'].isin(['Kurz', 'Kurz (Wechsel/Abbruch)']))]['for_id'].tolist()\n",
    "\n",
    "    t20_ended_ids = df_monitoring[df_monitoring['ema_t20_end'] == (target_date - pd.Timedelta(days=1))]['for_id'].tolist()\n",
    "    \n",
    "    t20_start_ids = df_monitoring[df_monitoring['ema_t20_start'] == target_date]['for_id'].tolist()\n",
    "    \n",
    "    t20_post_ids = df_monitoring[(df_monitoring['ema_t20_end'] == (target_date - pd.Timedelta(days=1))) & (df_monitoring['t20_post'].str.contains('ja'))]['for_id'].tolist()\n",
    "\n",
    "    post_ended_ids = df_monitoring[df_monitoring['ema_post_end'] == (target_date - pd.Timedelta(days=1))]['for_id'].tolist()\n",
    "    \n",
    "    post_start_ids = df_monitoring[df_monitoring['ema_post_start'] == target_date]['for_id'].tolist()\n",
    "\n",
    "\n",
    "    if onboarding_ids:\n",
    "        messages.append(f\"Onboarding Call: {onboarding_ids}\")\n",
    "    if baseline_ended_ids:\n",
    "        messages.append(f\"Baseline Ende Lang (Status ändern): {baseline_ended_ids}\")\n",
    "    if t20_start_ids:\n",
    "        messages.append(f\"T20 Start (Status ändern): {t20_start_ids}\")\n",
    "    if t20_ended_ids:\n",
    "        messages.append(f\"T20 Ende (Status ändern): {t20_ended_ids}\")\n",
    "    if study_short_finished_ids:\n",
    "        messages.append(f\"Kurzversion end today, send mail: {study_short_finished_ids}\")\n",
    "    if study_finished_ids:\n",
    "        messages.append(f\"Kurzversion Ende, change status: {study_finished_ids}\")\n",
    "    if t20_post_ids:\n",
    "        messages.append(f\"Person has finished Langversion, send reward, Redcap eCRF auf Complete setzen: {t20_post_ids}\")\n",
    "    if post_start_ids:\n",
    "        messages.append(f\"TPost Start (Status ändern): {post_start_ids}\")\n",
    "    if post_ended_ids:\n",
    "        messages.append(f\"TPost Ende change status, send reward, finish Redcap): {post_ended_ids}\")\n",
    "\n",
    "    # Print the formatted date along with the actions\n",
    "    if messages:\n",
    "        print(f\"{formatted_date}: \", \"; \".join(messages))\n",
    "    else:\n",
    "        print(f\"{formatted_date}: No actions needed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8b93a",
   "metadata": {},
   "source": [
    "## 5. Export missing data to google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd9ca8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.applymap(str).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2dba8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a google sheet\n",
    "gs = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE\")\n",
    "# select a work sheet from its name\n",
    "worksheet1 = gs.worksheet('Datenqualität')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc3809d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/gx19nmhj6v30dlkkh5nfp5xh0000gn/T/ipykernel_12078/4283573234.py:8: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  worksheet1.update(start_range, missing_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE',\n",
       " 'updatedRange': \"'Datenqualität'!A1194:K1238\",\n",
       " 'updatedRows': 45,\n",
       " 'updatedColumns': 11,\n",
       " 'updatedCells': 495}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "next_row = len(worksheet1.col_values(1)) + 1  # Assuming column A has index 1\n",
    "\n",
    "# Construct the range string where you want to start appending data\n",
    "# For example, if starting from column A and the next available row is 10, the range would be 'A10'\n",
    "start_range = f'A{next_row}'\n",
    "\n",
    "# Use the update method to append data starting from the specified cell\n",
    "worksheet1.update(start_range, missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eea0a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1z8LZJBBMzzAmiXIS47X8SLk-zSMwDIXSKPit4IlmfuE/export?format=csv&gid=1512138040\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28951a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame\n",
    "df_long = df_missing.melt(id_vars=[\"Datum\"], value_vars=[\"no_pd\", \"no_gps\", \"no_gpspd\"], var_name=\"condition\", value_name=\"for_id\")\n",
    "\n",
    "# Drop rows where ID is NaN\n",
    "df_long = df_long.dropna(subset=[\"for_id\"])\n",
    "\n",
    "# Count occurrences of each ID per condition\n",
    "df_count = df_long.groupby(\"for_id\")[\"condition\"].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Optionally, rename columns back to original condition names for clarity\n",
    "df_count.columns = [\"no_pd_count\", \"no_gps_count\", \"no_gpspd_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ee80a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count[\"missing_sum\"] = df_count.no_pd_count + df_count.no_gps_count + df_count.no_gpspd_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "724f90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count[\"missing_relative\"] = df_count.missing_sum / df_long.Datum.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72a7fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pd.merge(df_active, df_count, on = \"for_id\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5b8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
