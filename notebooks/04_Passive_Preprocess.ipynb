{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ac61a",
   "metadata": {},
   "source": [
    "# 4 Detailed Preprocessing of Passive Data\n",
    "\n",
    "This notebook shows the analysis of situational context using EMA and passive sensing data\n",
    "\n",
    "1. **Load Data**: Load necessary data from pickle files.\n",
    "2. **Preprocess EMA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd56bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import regex as re\n",
    "# If your current working directory is the notebooks directory, use this:\n",
    "notebook_dir = os.getcwd()  # current working directory\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "import glob\n",
    "import pickle\n",
    "from IPython.display import Markdown\n",
    "from config import datapath, preprocessed_path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import statistics  # Make sure this is imported\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"axes.labelsize\": 14, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': True})\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696265f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backup_path = preprocessed_path + \"backup_data_passive_actual.feather\"\n",
    "df_backup = pd.read_feather(backup_path)\n",
    "\n",
    "with open(preprocessed_path + '/ema_data.pkl', 'rb') as file:\n",
    "    df_ema_framework = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path + '/ema_content.pkl', 'rb') as file:\n",
    "    df_ema_content = pickle.load(file)  \n",
    "\n",
    "with open(preprocessed_path + '/monitoring_data.pkl', 'rb') as file:\n",
    "    df_monitoring = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636f879f-cb41-4270-8e72-b1825102d7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>type</th>\n",
       "      <th>startTimestamp</th>\n",
       "      <th>endTimestamp</th>\n",
       "      <th>doubleValue</th>\n",
       "      <th>longValue</th>\n",
       "      <th>booleanValue</th>\n",
       "      <th>dateValue</th>\n",
       "      <th>stringValue</th>\n",
       "      <th>userReliability</th>\n",
       "      <th>...</th>\n",
       "      <th>Sleep_actual_days_with_data</th>\n",
       "      <th>Sleep_data_coverage_per</th>\n",
       "      <th>Heart_Rate_actual_days_with_data</th>\n",
       "      <th>Heart_Rate_data_coverage_per</th>\n",
       "      <th>ema_relative_start_phase0</th>\n",
       "      <th>ema_relative_end_phase0</th>\n",
       "      <th>ema_relative_start_phase1</th>\n",
       "      <th>ema_relative_end_phase1</th>\n",
       "      <th>ema_relative_start_phase2</th>\n",
       "      <th>ema_relative_end_phase2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4MLe</td>\n",
       "      <td>Steps</td>\n",
       "      <td>2023-05-17 18:44:00</td>\n",
       "      <td>2023-05-17 18:45:00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>71.366594</td>\n",
       "      <td>343.0</td>\n",
       "      <td>74.403471</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>2024-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4MLe</td>\n",
       "      <td>ActiveBurnedCalories</td>\n",
       "      <td>2023-05-17 18:44:00</td>\n",
       "      <td>2023-05-17 18:45:00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>71.366594</td>\n",
       "      <td>343.0</td>\n",
       "      <td>74.403471</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>2024-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4MLe</td>\n",
       "      <td>CoveredDistance</td>\n",
       "      <td>2023-05-17 18:44:00</td>\n",
       "      <td>2023-05-17 18:45:00</td>\n",
       "      <td>4.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>71.366594</td>\n",
       "      <td>343.0</td>\n",
       "      <td>74.403471</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>2024-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4MLe</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>2023-05-17 18:58:01</td>\n",
       "      <td>2023-05-17 18:58:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>71.366594</td>\n",
       "      <td>343.0</td>\n",
       "      <td>74.403471</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>2024-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4MLe</td>\n",
       "      <td>ActiveBurnedCalories</td>\n",
       "      <td>2023-05-17 19:04:00</td>\n",
       "      <td>2023-05-17 19:05:00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>71.366594</td>\n",
       "      <td>343.0</td>\n",
       "      <td>74.403471</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>2024-08-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer                  type      startTimestamp        endTimestamp  \\\n",
       "0     4MLe                 Steps 2023-05-17 18:44:00 2023-05-17 18:45:00   \n",
       "1     4MLe  ActiveBurnedCalories 2023-05-17 18:44:00 2023-05-17 18:45:00   \n",
       "2     4MLe       CoveredDistance 2023-05-17 18:44:00 2023-05-17 18:45:00   \n",
       "3     4MLe             HeartRate 2023-05-17 18:58:01 2023-05-17 18:58:38   \n",
       "4     4MLe  ActiveBurnedCalories 2023-05-17 19:04:00 2023-05-17 19:05:00   \n",
       "\n",
       "   doubleValue  longValue  booleanValue  dateValue stringValue  \\\n",
       "0         6.00        NaN         False        NaN         -99   \n",
       "1         0.14        NaN         False        NaN         -99   \n",
       "2         4.62        NaN         False        NaN         -99   \n",
       "3          NaN       74.0         False        NaN         -99   \n",
       "4         0.36        NaN         False        NaN         -99   \n",
       "\n",
       "   userReliability  ...  Sleep_actual_days_with_data  Sleep_data_coverage_per  \\\n",
       "0              NaN  ...                        329.0                71.366594   \n",
       "1              NaN  ...                        329.0                71.366594   \n",
       "2              NaN  ...                        329.0                71.366594   \n",
       "3              NaN  ...                        329.0                71.366594   \n",
       "4              NaN  ...                        329.0                71.366594   \n",
       "\n",
       "  Heart_Rate_actual_days_with_data Heart_Rate_data_coverage_per  \\\n",
       "0                            343.0                    74.403471   \n",
       "1                            343.0                    74.403471   \n",
       "2                            343.0                    74.403471   \n",
       "3                            343.0                    74.403471   \n",
       "4                            343.0                    74.403471   \n",
       "\n",
       "  ema_relative_start_phase0  ema_relative_end_phase0  \\\n",
       "0                2023-05-17               2023-06-01   \n",
       "1                2023-05-17               2023-06-01   \n",
       "2                2023-05-17               2023-06-01   \n",
       "3                2023-05-17               2023-06-01   \n",
       "4                2023-05-17               2023-06-01   \n",
       "\n",
       "   ema_relative_start_phase1 ema_relative_end_phase1  \\\n",
       "0                 2023-10-27              2023-11-11   \n",
       "1                 2023-10-27              2023-11-11   \n",
       "2                 2023-10-27              2023-11-11   \n",
       "3                 2023-10-27              2023-11-11   \n",
       "4                 2023-10-27              2023-11-11   \n",
       "\n",
       "  ema_relative_start_phase2 ema_relative_end_phase2  \n",
       "0                2024-08-15              2024-08-18  \n",
       "1                2024-08-15              2024-08-18  \n",
       "2                2024-08-15              2024-08-18  \n",
       "3                2024-08-15              2024-08-18  \n",
       "4                2024-08-15              2024-08-18  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_backup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba14b26f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "# Check min. amount of EMA data available to map to passive data\n",
    "\n",
    "timedelta_hours = 2\n",
    "assess = 0\n",
    "\n",
    "#GPS data\n",
    "speed_limit = 1.4\n",
    "max_distance = 150 \n",
    "kms_per_radian = 6371.0088\n",
    "epsilon = 0.05/kms_per_radian\n",
    "min_samples = 30\n",
    "min_nights_obs = 5\n",
    "min_f_home = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20265259",
   "metadata": {},
   "source": [
    "## 1. Prepare passive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973f3003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pass_act = df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc02478e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only keep data that were collected during the first assessment phase\n",
    "df_pass_act_base = df_pass_act[df_pass_act.startTimestamp <= df_pass_act.ema_base_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40577ed8-9cdf-4909-a565-847daca726dd",
   "metadata": {},
   "source": [
    "### 1.1 Calculate GPS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ead0d9e-b89c-44d1-ba1d-6e1f3b2e17ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pass_act_loc =df_pass_act_base[df_pass_act_base.type.isin([\"Latitude\", \"Longitude\"])][[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e8c7eb-9534-456c-900b-2b6aced14f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_loc = df_pass_act_loc.pivot_table(\n",
    "    index=[\"customer\", \"startTimestamp\"],\n",
    "    columns=\"type\",\n",
    "    values=[\"doubleValue\"],\n",
    "    aggfunc='first'  # Using 'first' since each type should theoretically have only one entry per customer and timestamp\n",
    ")\n",
    "\n",
    "# Flatten the MultiIndex in columns\n",
    "df_loc.columns = ['_'.join(col).strip() for col in df_loc.columns.values]\n",
    "\n",
    "df_loc = df_loc.rename_axis(None, axis=1).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df_loc = df_loc.rename(columns={\n",
    "    'doubleValue_Latitude': 'Latitude',\n",
    "    'doubleValue_Longitude': 'Longitude',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7740fa25-2cba-4dec-ab57-dae6d1588514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "class HomeClusterExtractor:\n",
    "    def __init__(self, df, speed_limit, max_distance, epsilon, min_samples, min_nights_obs, min_f_home):\n",
    "        self.df = df.copy()\n",
    "        self.speed_limit = speed_limit\n",
    "        self.max_distance = max_distance\n",
    "        self.epsilon = epsilon\n",
    "        self.min_samples = min_samples\n",
    "        self.min_nights_obs = min_nights_obs\n",
    "        self.min_f_home = min_f_home\n",
    "        \n",
    "        self.df['hour_gps'] = self.df['startTimestamp'].dt.hour\n",
    "        self.df['day_gps'] = self.df['startTimestamp'].dt.date\n",
    "\n",
    "    def calculate_distances_and_speeds(self):\n",
    "        \"\"\"Calculate distances and speeds for each customer.\"\"\"\n",
    "        self.df['distance'], self.df['time_diff'], self.df['speed'] = np.nan, np.nan, np.nan\n",
    "\n",
    "        for customer in self.df['customer'].unique():\n",
    "            mask = self.df['customer'] == customer\n",
    "            customer_data = self.df.loc[mask]\n",
    "\n",
    "            # Calculate distances between consecutive points\n",
    "            distances = self._calculate_distances(customer_data)\n",
    "            time_diffs = customer_data['startTimestamp'].diff().dt.total_seconds().fillna(0)\n",
    "            speeds = distances / time_diffs.replace(0, np.nan)\n",
    "\n",
    "            self.df.loc[mask, 'distance'] = distances\n",
    "            self.df.loc[mask, 'time_diff'] = time_diffs\n",
    "            self.df.loc[mask, 'speed'] = speeds\n",
    "\n",
    "    def calculate_transition(self):\n",
    "        \"\"\"Calculate transition (movement) status based on speed and distance.\"\"\"\n",
    "        self.df['transition'] = np.where(\n",
    "            (self.df['speed'] >= self.speed_limit) | (self.df['distance'] >= self.max_distance),\n",
    "            1,  # In transition\n",
    "            0   # Not in transition\n",
    "        )\n",
    "\n",
    "    def _calculate_distances(self, df):\n",
    "        \"\"\"Helper method to calculate distances using haversine formula.\"\"\"\n",
    "        coords = df[['Latitude', 'Longitude']].values\n",
    "        distances = np.array([\n",
    "            self._haversine(coords[i-1][1], coords[i-1][0], coords[i][1], coords[i][0])\n",
    "            for i in range(1, len(coords))\n",
    "        ])\n",
    "        return np.append(distances, 0)  # Append 0 for the last point\n",
    "\n",
    "    def _haversine(self, lon1, lat1, lon2, lat2):\n",
    "        \"\"\"Haversine formula to calculate distance between two lat/lon points in meters.\"\"\"\n",
    "        R = 6371000  # Radius of Earth in meters\n",
    "        phi_1 = np.radians(lat1)\n",
    "        phi_2 = np.radians(lat2)\n",
    "        delta_phi = np.radians(lat2 - lat1)\n",
    "        delta_lambda = np.radians(lon2 - lon1)\n",
    "        a = np.sin(delta_phi/2.0)**2 + np.cos(phi_1) * np.cos(phi_2) * np.sin(delta_lambda/2.0)**2\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "        meters = R * c  # Output distance in meters\n",
    "        return meters\n",
    "\n",
    "    def extract_stationary_points(self):\n",
    "        \"\"\"Filter stationary points based on speed and distance.\"\"\"\n",
    "        return self.df[(self.df['speed'] < self.speed_limit) & (self.df['distance'] < self.max_distance)]\n",
    "\n",
    "    def apply_clustering(self, df):\n",
    "        \"\"\"Apply DBSCAN clustering on stationary points.\"\"\"\n",
    "        return df.groupby('customer').apply(self._apply_dbscan).reset_index(drop=True)\n",
    "\n",
    "    def _apply_dbscan(self, df):\n",
    "        \"\"\"Helper method to apply DBSCAN clustering.\"\"\"\n",
    "        clustering_model = DBSCAN(eps=self.epsilon, min_samples=self.min_samples, metric=\"haversine\")\n",
    "        cluster_labels = clustering_model.fit_predict(df[['Longitude', 'Latitude']].apply(np.radians))\n",
    "        return pd.DataFrame({'cluster': cluster_labels}, index=df.index)\n",
    "\n",
    "    def find_home_cluster(self, geodata_clusters):\n",
    "        \"\"\"Identify the home cluster based on nighttime data.\"\"\"\n",
    "        # Filter for night hours\n",
    "        geodata_night = geodata_clusters.loc[\n",
    "            (geodata_clusters['hour_gps'] >= 20) | (geodata_clusters['hour_gps'] <= 7)\n",
    "        ].copy()\n",
    "\n",
    "        # Filter out any rows with a clusterID of -1\n",
    "        geodata_night = geodata_night[geodata_night['clusterID'] != 'None']\n",
    "\n",
    "        # Calculate the mode of clusterID per user during night hours\n",
    "        geodata_night['home'] = geodata_night.groupby('customer')['clusterID'].transform(\n",
    "            lambda x: statistics.mode(x)\n",
    "        )\n",
    "\n",
    "        # Calculate various metrics to validate the home cluster\n",
    "        geodata_night['nights_with_obs'] = geodata_night.groupby('customer')['day_gps'].transform('nunique')\n",
    "        geodata_night['night_obs'] = geodata_night.groupby('customer')['day_gps'].transform('size')\n",
    "        geodata_night['n_home'] = geodata_night.groupby('customer')['home'].transform(lambda x: x.value_counts().iloc[0])\n",
    "        geodata_night['f_home'] = geodata_night['n_home'] / geodata_night['night_obs']\n",
    "\n",
    "        # Update the 'home' label based on conditions\n",
    "        geodata_night['home'] = geodata_night.apply(\n",
    "            lambda x: x['home'] if x['nights_with_obs'] >= self.min_nights_obs and x['f_home'] > self.min_f_home else None, axis=1)\n",
    "\n",
    "        # Extract a mapping of userID to home cluster\n",
    "        user_home_mapping = geodata_night[['customer', 'home']].drop_duplicates()\n",
    "\n",
    "        # Merging back to the full dataset\n",
    "        return pd.merge(geodata_clusters, user_home_mapping, on='customer', how='left')\n",
    "    \n",
    "    def determine_if_at_home(self, df):\n",
    "        \"\"\"Determine if a person is at home.\"\"\"\n",
    "        df['at_home'] = df.apply(\n",
    "            lambda x: 1 if x['clusterID'] == x['home'] else (0 if pd.notna(x['home']) else -1), axis=1\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the full extraction process.\"\"\"\n",
    "        self.calculate_distances_and_speeds()\n",
    "        self.calculate_transition()\n",
    "\n",
    "        # Ensure transition is correctly added to geodata_clusters\n",
    "        geodata_clusters = self.df.copy()\n",
    "\n",
    "        stationary_df = self.extract_stationary_points()\n",
    "        geodata_cluster_df = self.apply_clustering(stationary_df)\n",
    "\n",
    "        geodata_clusters = pd.concat([geodata_clusters.reset_index(drop=True), geodata_cluster_df['cluster']], axis=1)\n",
    "        geodata_clusters = geodata_clusters[geodata_clusters['cluster'] != -1]\n",
    "        geodata_clusters['clusterID'] = geodata_clusters['customer'].astype(str) + '00' + geodata_clusters['cluster'].astype(str)\n",
    "\n",
    "        geodata_clusters = self.find_home_cluster(geodata_clusters)\n",
    "        geodata_clusters = self.determine_if_at_home(geodata_clusters)\n",
    "\n",
    "        return geodata_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3caf9eb-ade7-4215-b09b-031095780183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the class\n",
    "extractor = HomeClusterExtractor(\n",
    "    df=df_loc,\n",
    "    speed_limit=speed_limit,\n",
    "    max_distance=max_distance,\n",
    "    epsilon=epsilon,\n",
    "    min_samples=min_samples,\n",
    "    min_nights_obs=min_nights_obs,\n",
    "    min_f_home=min_f_home\n",
    ")\n",
    "\n",
    "# Run the extraction process\n",
    "home_clusters = extractor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb532753-e926-43aa-9985-262e22de4953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.013856e+06\n",
       "mean     6.309279e-01\n",
       "std      4.825538e-01\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      1.000000e+00\n",
       "max      1.000000e+00\n",
       "Name: transition, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_clusters.transition.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9895a55-a53d-4ab1-9b07-1159723e50e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home_clusters_red = home_clusters[[\"customer\", \"startTimestamp\", \"at_home\",\"transition\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d91a6f-6e1c-41e3-91f0-cc1bfd9ad6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>startTimestamp</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>hour_gps</th>\n",
       "      <th>day_gps</th>\n",
       "      <th>distance</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>speed</th>\n",
       "      <th>transition</th>\n",
       "      <th>cluster</th>\n",
       "      <th>clusterID</th>\n",
       "      <th>home</th>\n",
       "      <th>at_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05kz</td>\n",
       "      <td>2023-10-10 19:35:07</td>\n",
       "      <td>58.255878</td>\n",
       "      <td>-29.427252</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05kz</td>\n",
       "      <td>2023-10-10 19:35:11</td>\n",
       "      <td>58.255878</td>\n",
       "      <td>-29.427252</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05kz</td>\n",
       "      <td>2023-10-10 19:35:15</td>\n",
       "      <td>58.255878</td>\n",
       "      <td>-29.427252</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>16.842597</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.210649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05kz</td>\n",
       "      <td>2023-10-10 23:25:08</td>\n",
       "      <td>58.255878</td>\n",
       "      <td>-29.427252</td>\n",
       "      <td>23</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>3150.442913</td>\n",
       "      <td>13461.0</td>\n",
       "      <td>0.234042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05kz</td>\n",
       "      <td>2023-10-11 15:54:59</td>\n",
       "      <td>58.253108</td>\n",
       "      <td>-29.481662</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>443.166520</td>\n",
       "      <td>8528.0</td>\n",
       "      <td>0.051966</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>05kz000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013851</th>\n",
       "      <td>zgxc</td>\n",
       "      <td>2023-10-27 16:41:13</td>\n",
       "      <td>-51.442148</td>\n",
       "      <td>-91.319991</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>10.837161</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.292896</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zgxc00nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013852</th>\n",
       "      <td>zgxc</td>\n",
       "      <td>2023-10-27 16:41:38</td>\n",
       "      <td>-51.442058</td>\n",
       "      <td>-91.319931</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>3.612388</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.144496</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zgxc00nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013853</th>\n",
       "      <td>zgxc</td>\n",
       "      <td>2023-10-27 16:41:43</td>\n",
       "      <td>-51.442028</td>\n",
       "      <td>-91.319911</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>7.518023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.503605</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zgxc00nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013854</th>\n",
       "      <td>zgxc</td>\n",
       "      <td>2023-10-27 16:42:36</td>\n",
       "      <td>-51.442088</td>\n",
       "      <td>-91.319961</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>15.041611</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.283804</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zgxc00nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013855</th>\n",
       "      <td>zgxc</td>\n",
       "      <td>2023-10-27 16:42:55</td>\n",
       "      <td>-51.441958</td>\n",
       "      <td>-91.319901</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zgxc00nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013856 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer      startTimestamp   Latitude  Longitude  hour_gps  \\\n",
       "0           05kz 2023-10-10 19:35:07  58.255878 -29.427252        19   \n",
       "1           05kz 2023-10-10 19:35:11  58.255878 -29.427252        19   \n",
       "2           05kz 2023-10-10 19:35:15  58.255878 -29.427252        19   \n",
       "3           05kz 2023-10-10 23:25:08  58.255878 -29.427252        23   \n",
       "4           05kz 2023-10-11 15:54:59  58.253108 -29.481662        15   \n",
       "...          ...                 ...        ...        ...       ...   \n",
       "1013851     zgxc 2023-10-27 16:41:13 -51.442148 -91.319991        16   \n",
       "1013852     zgxc 2023-10-27 16:41:38 -51.442058 -91.319931        16   \n",
       "1013853     zgxc 2023-10-27 16:41:43 -51.442028 -91.319911        16   \n",
       "1013854     zgxc 2023-10-27 16:42:36 -51.442088 -91.319961        16   \n",
       "1013855     zgxc 2023-10-27 16:42:55 -51.441958 -91.319901        16   \n",
       "\n",
       "            day_gps     distance  time_diff     speed  transition  cluster  \\\n",
       "0        2023-10-10     0.000000        0.0       NaN           0      0.0   \n",
       "1        2023-10-10     0.000000        4.0  0.000000           0      0.0   \n",
       "2        2023-10-10    16.842597        4.0  4.210649           1      0.0   \n",
       "3        2023-10-10  3150.442913    13461.0  0.234042           1      0.0   \n",
       "4        2023-10-11   443.166520     8528.0  0.051966           1      0.0   \n",
       "...             ...          ...        ...       ...         ...      ...   \n",
       "1013851  2023-10-27    10.837161       37.0  0.292896           0      NaN   \n",
       "1013852  2023-10-27     3.612388       25.0  0.144496           0      NaN   \n",
       "1013853  2023-10-27     7.518023        5.0  1.503605           1      NaN   \n",
       "1013854  2023-10-27    15.041611       53.0  0.283804           0      NaN   \n",
       "1013855  2023-10-27     0.000000       19.0  0.000000           0      NaN   \n",
       "\n",
       "         clusterID       home  at_home  \n",
       "0        05kz000.0  05kz000.0        1  \n",
       "1        05kz000.0  05kz000.0        1  \n",
       "2        05kz000.0  05kz000.0        1  \n",
       "3        05kz000.0  05kz000.0        1  \n",
       "4        05kz000.0  05kz000.0        1  \n",
       "...            ...        ...      ...  \n",
       "1013851  zgxc00nan        NaN       -1  \n",
       "1013852  zgxc00nan        NaN       -1  \n",
       "1013853  zgxc00nan        NaN       -1  \n",
       "1013854  zgxc00nan        NaN       -1  \n",
       "1013855  zgxc00nan        NaN       -1  \n",
       "\n",
       "[1013856 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596a358",
   "metadata": {},
   "source": [
    "## 2. Prepare EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "133d9e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ema_udi = df_ema_content[[\"customer\", \"createdAt_day\", \"quest_create\", \"unique_day_id\", \"assess\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43dbd254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by customer and unique_day_id and calculate the minimum quest_create\n",
    "df_min_quest = df_ema_udi.groupby(['customer', 'unique_day_id'])['quest_create'].min().reset_index()\n",
    "\n",
    "# Rename the column to sensor_block_end\n",
    "df_min_quest.rename(columns={'quest_create': 'sensor_block_end'}, inplace=True)\n",
    "\n",
    "# Merge the minimum quest_create back to the original DataFrame\n",
    "df_ema_udi = pd.merge(df_ema_udi, df_min_quest, on=['customer', 'unique_day_id'], how='left')\n",
    "\n",
    "# Create the sensor_block_start column, which is 2 hours before quest_create\n",
    "df_ema_udi.drop(columns=['quest_create'], inplace=True)\n",
    "df_ema_udi = df_ema_udi.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79939ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ema_udi['sensor_block_start'] = df_ema_udi['sensor_block_end'] - pd.Timedelta(hours=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "041705f9-ae62-4345-a71d-afc2f06224d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only include first assessment phase\n",
    "df_ema_udi_base = df_ema_udi.loc[df_ema_udi.assess == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5c641-d497-4956-96a2-35a09594aa57",
   "metadata": {},
   "source": [
    "## 3. Merge EMA to passive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aba13b6-e4f7-4de9-89ac-71cb747f4e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class EMAMapper:\n",
    "    def __init__(self, df_ema, df_data, df_home_clusters=None):\n",
    "        self.df_ema = df_ema.copy()\n",
    "        self.df_data = df_data.copy()\n",
    "\n",
    "        if df_home_clusters is not None:\n",
    "            self.df_home_clusters = df_home_clusters.copy()\n",
    "            self.df_home_clusters['startTimestamp'] = pd.to_datetime(self.df_home_clusters['startTimestamp'])\n",
    "        else:\n",
    "            self.df_home_clusters = None\n",
    "\n",
    "        self.df_ema['sensor_block_start'] = pd.to_datetime(self.df_ema['sensor_block_start'])\n",
    "        self.df_ema['sensor_block_end'] = pd.to_datetime(self.df_ema['sensor_block_end'])\n",
    "        self.df_data['startTimestamp'] = pd.to_datetime(self.df_data['startTimestamp'])\n",
    "        if 'endTimestamp' in self.df_data.columns:\n",
    "            self.df_data['endTimestamp'] = pd.to_datetime(self.df_data['endTimestamp'])\n",
    "\n",
    "        self.outlier_distances = []  # To collect filtered outlier distances\n",
    "\n",
    "    def _haversine(self, lon1, lat1, lon2, lat2):\n",
    "        lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        r = 6371  # Radius of Earth in kilometers\n",
    "        distance = c * r\n",
    "\n",
    "        return distance\n",
    "\n",
    "    def count_gps_rows_within_blocks_and_calculate_distances(self, max_distance_km=50):\n",
    "        gps_counts = []\n",
    "        total_distances = []\n",
    "\n",
    "        df_gps = self.df_data[self.df_data['type'].isin(['Latitude', 'Longitude'])]\n",
    "        df_gps = df_gps.pivot_table(index=[\"customer\", \"startTimestamp\"], columns=\"type\", values=\"doubleValue\", aggfunc='first').reset_index()\n",
    "\n",
    "        for idx, ema_row in self.df_ema.iterrows():\n",
    "            sensor_block_start = ema_row['sensor_block_start']\n",
    "            sensor_block_end = ema_row['sensor_block_end']\n",
    "\n",
    "            df_filtered = df_gps[(df_gps['startTimestamp'] >= sensor_block_start) & \n",
    "                                 (df_gps['startTimestamp'] <= sensor_block_end)]\n",
    "\n",
    "            if df_filtered.empty:\n",
    "                gps_counts.append(0)\n",
    "                total_distances.append(0)\n",
    "            else:\n",
    "                df_filtered = df_filtered[(df_filtered['Latitude'] != 0) & (df_filtered['Longitude'] != 0)]\n",
    "                df_filtered = df_filtered.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "                gps_count = df_filtered.shape[0]\n",
    "                gps_counts.append(gps_count)\n",
    "\n",
    "                latitudes = df_filtered['Latitude'].values\n",
    "                longitudes = df_filtered['Longitude'].values\n",
    "\n",
    "                distances = []\n",
    "                for i in range(1, len(latitudes)):\n",
    "                    distance = self._haversine(longitudes[i-1], latitudes[i-1], longitudes[i], latitudes[i])\n",
    "\n",
    "                    # Apply max distance outlier detection\n",
    "                    if distance > max_distance_km:\n",
    "                        self.outlier_distances.append({\n",
    "                            'customer': df_filtered.iloc[i]['customer'],\n",
    "                            'unique_day_id': ema_row['unique_day_id'],\n",
    "                            'segment': i,\n",
    "                            'distance_km': distance,\n",
    "                            'reason': 'Exceeds max distance'\n",
    "                        })\n",
    "                        distances.append(0)  # Set outlier distances to 0\n",
    "                    else:\n",
    "                        distances.append(distance)\n",
    "\n",
    "                total_distance = np.sum(distances)\n",
    "                total_distances.append(total_distance)\n",
    "\n",
    "        self.df_ema['n_GPS'] = gps_counts\n",
    "        self.df_ema['total_distance_km'] = total_distances\n",
    "\n",
    "        return self.df_ema\n",
    "\n",
    "    def map_steps_to_ema(self):\n",
    "        n_steps_values = []\n",
    "\n",
    "        df_steps = self.df_data[self.df_data['type'] == 'Steps']\n",
    "\n",
    "        for idx, ema_row in self.df_ema.iterrows():\n",
    "            sensor_block_start = ema_row['sensor_block_start']\n",
    "            sensor_block_end = ema_row['sensor_block_end']\n",
    "\n",
    "            df_filtered = df_steps[(df_steps['startTimestamp'] < sensor_block_end) & \n",
    "                                   (df_steps['endTimestamp'] > sensor_block_start)]\n",
    "\n",
    "            if df_filtered.empty:\n",
    "                n_steps_values.append(0)\n",
    "            else:\n",
    "                overlap_start = df_filtered['startTimestamp'].combine(sensor_block_start, max)\n",
    "                overlap_end = df_filtered['endTimestamp'].combine(sensor_block_end, min)\n",
    "\n",
    "                overlap_duration = (overlap_end - overlap_start).dt.total_seconds()\n",
    "                step_duration = (df_filtered['endTimestamp'] - df_filtered['startTimestamp']).dt.total_seconds()\n",
    "\n",
    "                proportion = overlap_duration / step_duration\n",
    "                weighted_value = proportion * df_filtered['doubleValue']\n",
    "\n",
    "                n_steps = weighted_value.sum()\n",
    "                n_steps_values.append(round(n_steps))\n",
    "\n",
    "        self.df_ema['n_steps'] = n_steps_values\n",
    "\n",
    "        return self.df_ema\n",
    "\n",
    "    def map_at_home_to_ema(self):\n",
    "        \"\"\"\n",
    "        Maps the 'at_home' variable to EMA blocks based on whether the startTimestamp from the df_home_clusters falls within the blocks.\n",
    "\n",
    "        Returns:\n",
    "        - df_ema with an additional column 'at_home_percentage' containing the proportion of time spent at home within each block.\n",
    "        - df_ema with an additional column 'at_home_binary' indicating if the person was at home (1), not at home (0), or unknown (-1).\n",
    "        \"\"\"\n",
    "        if self.df_home_clusters is None:\n",
    "            raise ValueError(\"df_home_clusters is not provided during initialization.\")\n",
    "\n",
    "        at_home_percentage_values = []\n",
    "        at_home_binary_values = []\n",
    "\n",
    "        for idx, ema_row in self.df_ema.iterrows():\n",
    "            sensor_block_start = ema_row['sensor_block_start']\n",
    "            sensor_block_end = ema_row['sensor_block_end']\n",
    "            customer = ema_row['customer']\n",
    "\n",
    "            df_filtered = self.df_home_clusters[\n",
    "                (self.df_home_clusters['startTimestamp'] >= sensor_block_start) & \n",
    "                (self.df_home_clusters['startTimestamp'] <= sensor_block_end) & \n",
    "                (self.df_home_clusters['customer'] == customer)\n",
    "            ]\n",
    "\n",
    "            if df_filtered.empty:\n",
    "                at_home_percentage_values.append(0)\n",
    "                at_home_binary_values.append(-1)  # Unknown\n",
    "            else:\n",
    "                # Exclude unknown (-1) values from the calculation\n",
    "                valid_at_home = df_filtered[df_filtered['at_home'] != -1]\n",
    "\n",
    "                if valid_at_home.empty:\n",
    "                    at_home_percentage_values.append(0)\n",
    "                    at_home_binary_values.append(-1)  # Unknown\n",
    "                else:\n",
    "                    # Calculate the proportion of time spent at home within the block\n",
    "                    at_home_percentage = valid_at_home['at_home'].mean() * 100  # Convert proportion to percentage\n",
    "                    at_home_percentage_values.append(at_home_percentage)\n",
    "\n",
    "                    # Determine binary at_home status\n",
    "                    at_home_status = 1 if valid_at_home['at_home'].mean() > 0 else 0\n",
    "                    at_home_binary_values.append(at_home_status)\n",
    "\n",
    "        self.df_ema['at_home_percentage'] = at_home_percentage_values\n",
    "        self.df_ema['at_home_binary'] = at_home_binary_values\n",
    "\n",
    "        return self.df_ema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbecc8ab-0a6a-471a-abaf-111b726456be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming df_ema, df_data, and df_home_clusters_red are already defined DataFrames\n",
    "ema_mapper = EMAMapper(df_ema_udi_base, df_pass_act_base, df_home_clusters=home_clusters_red)\n",
    "\n",
    "# Mapping steps and GPS data\n",
    "df_ema_with_mapped_values = ema_mapper.map_steps_to_ema()\n",
    "df_ema_with_gps_counts_distances = ema_mapper.count_gps_rows_within_blocks_and_calculate_distances(max_distance_km=50)\n",
    "\n",
    "# Mapping the 'at_home' variable\n",
    "df_ema_with_at_home = ema_mapper.map_at_home_to_ema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6db176c1-44d8-4098-8ab2-39ee2b3047f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>createdAt_day</th>\n",
       "      <th>unique_day_id</th>\n",
       "      <th>assess</th>\n",
       "      <th>sensor_block_end</th>\n",
       "      <th>sensor_block_start</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_GPS</th>\n",
       "      <th>total_distance_km</th>\n",
       "      <th>at_home_percentage</th>\n",
       "      <th>at_home_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>20230919_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-19 07:31:20.352</td>\n",
       "      <td>2023-09-19 05:31:20.352</td>\n",
       "      <td>295</td>\n",
       "      <td>115</td>\n",
       "      <td>0.438162</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>20230919_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-19 17:14:33.463</td>\n",
       "      <td>2023-09-19 15:14:33.463</td>\n",
       "      <td>11126</td>\n",
       "      <td>720</td>\n",
       "      <td>49.047973</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>20230928_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-28 18:29:55.737</td>\n",
       "      <td>2023-09-28 16:29:55.737</td>\n",
       "      <td>15424</td>\n",
       "      <td>263</td>\n",
       "      <td>60.085323</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>20230925_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-25 17:08:34.592</td>\n",
       "      <td>2023-09-25 15:08:34.592</td>\n",
       "      <td>15565</td>\n",
       "      <td>439</td>\n",
       "      <td>42.653878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MYAi</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>20230922_6</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-22 17:06:14.166</td>\n",
       "      <td>2023-09-22 15:06:14.166</td>\n",
       "      <td>6507</td>\n",
       "      <td>233</td>\n",
       "      <td>20.542444</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712412</th>\n",
       "      <td>xwB7</td>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>20230721_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-21 08:11:31.637</td>\n",
       "      <td>2023-07-21 06:11:31.637</td>\n",
       "      <td>320</td>\n",
       "      <td>4</td>\n",
       "      <td>0.043616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712443</th>\n",
       "      <td>xwB7</td>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>20230721_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-21 11:40:30.657</td>\n",
       "      <td>2023-07-21 09:40:30.657</td>\n",
       "      <td>8228</td>\n",
       "      <td>72</td>\n",
       "      <td>1.023709</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712472</th>\n",
       "      <td>xwB7</td>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>20230720_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-20 13:46:15.775</td>\n",
       "      <td>2023-07-20 11:46:15.775</td>\n",
       "      <td>9443</td>\n",
       "      <td>256</td>\n",
       "      <td>22.752635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712502</th>\n",
       "      <td>xwB7</td>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>20230720_7</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-20 16:58:19.651</td>\n",
       "      <td>2023-07-20 14:58:19.651</td>\n",
       "      <td>7404</td>\n",
       "      <td>124</td>\n",
       "      <td>2.877848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712609</th>\n",
       "      <td>OzwS</td>\n",
       "      <td>2024-03-26</td>\n",
       "      <td>20240326_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-26 14:23:56.059</td>\n",
       "      <td>2024-03-26 12:23:56.059</td>\n",
       "      <td>14068</td>\n",
       "      <td>941</td>\n",
       "      <td>32.986776</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16693 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer createdAt_day unique_day_id  assess        sensor_block_end  \\\n",
       "0          MYAi    2023-09-19    20230919_1       0 2023-09-19 07:31:20.352   \n",
       "32         MYAi    2023-09-19    20230919_6       0 2023-09-19 17:14:33.463   \n",
       "33         MYAi    2023-09-28    20230928_6       0 2023-09-28 18:29:55.737   \n",
       "35         MYAi    2023-09-25    20230925_6       0 2023-09-25 17:08:34.592   \n",
       "39         MYAi    2023-09-22    20230922_6       0 2023-09-22 17:06:14.166   \n",
       "...         ...           ...           ...     ...                     ...   \n",
       "712412     xwB7    2023-07-21    20230721_2       0 2023-07-21 08:11:31.637   \n",
       "712443     xwB7    2023-07-21    20230721_4       0 2023-07-21 11:40:30.657   \n",
       "712472     xwB7    2023-07-20    20230720_5       0 2023-07-20 13:46:15.775   \n",
       "712502     xwB7    2023-07-20    20230720_7       0 2023-07-20 16:58:19.651   \n",
       "712609     OzwS    2024-03-26    20240326_5       0 2024-03-26 14:23:56.059   \n",
       "\n",
       "            sensor_block_start  n_steps  n_GPS  total_distance_km  \\\n",
       "0      2023-09-19 05:31:20.352      295    115           0.438162   \n",
       "32     2023-09-19 15:14:33.463    11126    720          49.047973   \n",
       "33     2023-09-28 16:29:55.737    15424    263          60.085323   \n",
       "35     2023-09-25 15:08:34.592    15565    439          42.653878   \n",
       "39     2023-09-22 15:06:14.166     6507    233          20.542444   \n",
       "...                        ...      ...    ...                ...   \n",
       "712412 2023-07-21 06:11:31.637      320      4           0.043616   \n",
       "712443 2023-07-21 09:40:30.657     8228     72           1.023709   \n",
       "712472 2023-07-20 11:46:15.775     9443    256          22.752635   \n",
       "712502 2023-07-20 14:58:19.651     7404    124           2.877848   \n",
       "712609 2024-03-26 12:23:56.059    14068    941          32.986776   \n",
       "\n",
       "        at_home_percentage  at_home_binary  \n",
       "0                    100.0               1  \n",
       "32                   100.0               1  \n",
       "33                   100.0               1  \n",
       "35                     0.0              -1  \n",
       "39                   100.0               1  \n",
       "...                    ...             ...  \n",
       "712412                 0.0              -1  \n",
       "712443               100.0               1  \n",
       "712472                 0.0              -1  \n",
       "712502                 0.0              -1  \n",
       "712609               100.0               1  \n",
       "\n",
       "[16693 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ema_with_at_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f62bfe-231c-4ad6-b02a-f55b0d6761f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16693.000000\n",
       "mean        40.620886\n",
       "std         48.818515\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%        100.000000\n",
       "max        100.000000\n",
       "Name: at_home_percentage, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ema_with_at_home.at_home_percentage.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad818d2-b04d-4cf6-b10e-f7ff7a33e800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(preprocessed_path + '/map_ema_passive.pkl', 'wb') as file:\n",
    "    pickle.dump(df_ema_with_at_home, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a26233-94bb-4e2b-9dd4-f2a6beb422bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
