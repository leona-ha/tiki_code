{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ac61a",
   "metadata": {},
   "source": [
    "# 4 Detailed Preprocessing of Passive Data\n",
    "\n",
    "This notebook shows the analysis of situational context using EMA and passive sensing data\n",
    "\n",
    "1. **Load Data**: Load necessary data from pickle files.\n",
    "2. **Preprocess EMA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd56bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'intervaltree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mregex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mintervaltree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntervalTree\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'intervaltree'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from intervaltree import IntervalTree\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# If your current working directory is the notebooks directory, use this:\n",
    "notebook_dir = os.getcwd()  # current working directory\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "import glob\n",
    "import pickle\n",
    "from IPython.display import Markdown\n",
    "from server_config import datapath, preprocessed_path_freezed, redcap_path, preprocessed_path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import EMA_Mapper\n",
    "import gps_features\n",
    "from missing_data import summarize_missing_data\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import statistics  # Make sure this is imported\n",
    "import hdbscan\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns \n",
    "import matplotlib.patches as mpatches\n",
    "# Ensure matplotlib displays plots inline (if using Jupyter Notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "# Suppress only SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696265f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backup_path = preprocessed_path_freezed + \"/backup_data_passive_actual.feather\"\n",
    "df_backup = pd.read_feather(backup_path)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_data.pkl', 'rb') as file:\n",
    "    df_ema_framework = pickle.load(file)\n",
    "\n",
    "with open(preprocessed_path_freezed + '/ema_content.pkl', 'rb') as file:\n",
    "    df_ema_content = pickle.load(file)  \n",
    "\n",
    "with open(preprocessed_path_freezed + '/monitoring_data.pkl', 'rb') as file:\n",
    "    df_monitoring = pickle.load(file)\n",
    "    \n",
    "with open(preprocessed_path_freezed + '/redcap_data.pkl', 'rb') as file:\n",
    "    df_redcap = pickle.load(file)\n",
    "\n",
    "sp1_path = redcap_path + \"/baseline_T5_data_incl_ns_freezed_241120.sav\"\n",
    "df_sp1 = pd.read_spss(sp1_path)\n",
    "freezed_ids = df_sp1.for_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28df9a-956c-4944-a93f-688159c7609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup_path = preprocessed_path+ \"/backup_data_passive_actual.feather\"\n",
    "#df_backup = pd.read_feather(backup_path)\n",
    "\n",
    "#with open(preprocessed_path + '/ema_data.pkl', 'rb') as file:\n",
    "#    df_ema_framework = pickle.load(file)\n",
    "\n",
    "#with open(preprocessed_path + '/ema_content.pkl', 'rb') as file:\n",
    "#    df_ema_content = pickle.load(file)  \n",
    "\n",
    "#with open(preprocessed_path + '/monitoring_data.pkl', 'rb') as file:\n",
    "#    df_monitoring = pickle.load(file)\n",
    "    \n",
    "#with open(preprocessed_path + '/redcap_data.pkl', 'rb') as file:\n",
    "#    df_redcap = pickle.load(file)\n",
    "\n",
    "#sp1_path = redcap_path + \"/baseline_T5_data_incl_ns_freezed_241120.sav\"\n",
    "#df_sp1 = pd.read_spss(sp1_path)\n",
    "#freezed_ids = df_sp1.for_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14b26f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "# Check min. amount of EMA data available to map to passive data\n",
    "\n",
    "#GPS data\n",
    "speed_limit = 1.4\n",
    "max_distance = 150 \n",
    "kms_per_radian = 6371000\n",
    "epsilon = 100/kms_per_radian\n",
    "min_samples = 10\n",
    "min_cluster_size = 20\n",
    "min_nights_obs = 4\n",
    "min_f_home = 0.5\n",
    "\n",
    "# EMA\n",
    "assessment_phase = [0] #1,2\n",
    "min_num_daily = 4\n",
    "min_days_data = 7\n",
    "\n",
    "\n",
    "#Passive to EMA matching\n",
    "timedelta_hours = 2\n",
    "assess = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb0b98-e053-4c56-8035-063d805fa1ee",
   "metadata": {},
   "source": [
    "## Filter for participants with sufficient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84307a-48e9-4237-a174-ca4aea690c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first assessment phase finished\n",
    "df_ema = df_ema_content.loc[df_ema_content.status.isin([\"Abgeschlossen\", \"Post_Erhebung_1\",\n",
    "                                                             \"Erhebung_2_aktiv\",\"Post_Erhebung_2\", \"Erhebung_3_aktiv\", \"Dropout\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31c439-6072-4c86-80a5-1531eaa1f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema[\"quest_create_day\"] = df_ema.quest_create.dt.normalize()\n",
    "df_ema[\"quest_create_hour\"] = df_ema.quest_create.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27524a-88f2-4a4e-bd84-cd2133071ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_cols = [\"assess\", \"study\", \"quest_create\", \"weekend\", \"quest_nr\", \"weekday\", \"season\", \"time_of_day\", \"quest_create_day\", \"quest_create_hour\"]\n",
    "\n",
    "aggregated_info = df_ema.groupby([\"customer\", \"unique_day_id\"])[extra_cols].first().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04638442-f380-4101-bb53-95f1dd8b7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_panas = df_ema.loc[df_ema.quest_title.isin(['panas_fear1', 'panas_fear2', 'panas_guilt1', \n",
    "            'panas_guilt2', 'panas_hostility1', 'panas_hostility2', \n",
    "             'panas_sadness1', 'panas_sadness2'])]\n",
    "\n",
    "# Pivot the table as specified\n",
    "df_piv = df_ema_panas.pivot_table(\n",
    "    index=[\"customer\", \"unique_day_id\", \"assess\"],\n",
    "    columns=\"quest_title\",\n",
    "    values=\"choice_text\",\n",
    "    aggfunc='first'  # Using 'first' since each entry should theoretically be unique per group\n",
    ")\n",
    "\n",
    "# The columns are now a single level Index with just the quest_title values since 'values' is not a list anymore\n",
    "df_piv.columns = [col for col in df_piv.columns.values]\n",
    "\n",
    "# Reset the index to turn the MultiIndex into columns\n",
    "df_piv = df_piv.reset_index()\n",
    "df_piv = df_piv.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ab7bf-1318-437e-bc7a-831917b1e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_TAI = df_ema.loc[df_ema.quest_title.isin(['ta_behavioral_2',\n",
    "       'ta_kognitiv', 'ta_kognitiv_2', 'ta_behavioral', 'panas_selfassurance', 'panas_joviality2', 'panas_fatigue',\n",
    "       'panas_joviality1', 'panas_fear1', 'panas_hostility2',\n",
    "       'panas_serenity2', 'panas_shyness', 'panas_hostility1',\n",
    "       'panas_guilt1', 'panas_fear2', 'panas_sadness1', 'panas_guilt2',\n",
    "       'panas_loneliness', 'panas_serenity1', 'panas_sadness2',\n",
    "       'panas_attentiveness', 'er_intensity', 'er_control',\n",
    "       'er_distraction', 'er_reappraisal', 'er_rumination',\n",
    "       'er_relaxation', 'er_suppression', 'er_acceptance'])]\n",
    "\n",
    "# Pivot the table as specified\n",
    "df_piv_tai = df_ema_TAI.pivot_table(\n",
    "    index=[\"customer\", \"unique_day_id\", \"assess\"],\n",
    "    columns=\"quest_title\",\n",
    "    values=\"choice_text\",\n",
    "    aggfunc='first'  # Using 'first' since each entry should theoretically be unique per group\n",
    ")\n",
    "\n",
    "# The columns are now a single level Index with just the quest_title values since 'values' is not a list anymore\n",
    "df_piv_tai.columns = [col for col in df_piv_tai.columns.values]\n",
    "\n",
    "# Reset the index to turn the MultiIndex into columns\n",
    "df_piv_tai = df_piv_tai.reset_index()\n",
    "df_piv_tai = df_piv_tai.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb339672-4426-4112-81a3-772a1aa3a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_piv_tai = pd.merge(aggregated_info, df_piv_tai, on=[\"customer\",\"assess\", \"unique_day_id\"])\n",
    "df_piv = pd.merge(aggregated_info, df_piv, on=[\"customer\",\"assess\", \"unique_day_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1404c0-9fe6-4378-9b88-3ee3c4e83aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_piv_tai_csv_path = preprocessed_path + '/ema_tai_benni.csv'\n",
    "df_piv_tai.to_csv(df_piv_tai_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f59bf-87c1-4e56-ae4e-a91c580e0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_piv = df_piv.loc[df_piv.study.isin([24,25])] # first assessment phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8aed5-4d32-46d6-ae46-0f53ee2e086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "na_scale = ['panas_fear1', 'panas_fear2', 'panas_guilt1', \n",
    "            'panas_guilt2', 'panas_hostility1', 'panas_hostility2', \n",
    "             'panas_sadness1', 'panas_sadness2']\n",
    "\n",
    "# Step 1: Ensure the columns in pa_scale and na_scale are numeric\n",
    "df_piv[na_scale] = df_piv[na_scale].apply(pd.to_numeric, errors='coerce')\n",
    "# Drop rows where any of the na_scale columns have NaN\n",
    "df_piv_clean = df_piv.dropna(subset=na_scale, how='any')\n",
    "\n",
    "# Step 2: Calculate the mean for PA and NA scales per unique_day_id\n",
    "df_piv['mean_na'] = df_piv.groupby(['customer', 'unique_day_id'])[na_scale].transform('mean').mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe03eb2-bba9-4193-8354-ea66b8d22d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of unique 'unique_day_id' per 'customer' and 'quest_complete_day'\n",
    "df_piv['n_quest'] = df_piv.groupby(['customer', 'quest_create_day'])['unique_day_id'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918981f-7f63-4c3c-bf76-ea4312810550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check condition\n",
    "df_piv = df_piv.loc[df_piv[\"n_quest\"] >= min_num_daily]\n",
    "df_piv[\"n_days_min\"] = df_piv.groupby(\"customer\")['quest_create_day'].transform(\"nunique\")\n",
    "df_piv = df_piv.loc[df_piv.n_days_min >= min_days_data]\n",
    "df_ema1_customers = df_piv.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20265259",
   "metadata": {},
   "source": [
    "## 1. Prepare passive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f3003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pass_act = df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86831ba8-eb56-441e-abfb-309935f0773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pass_act.startTimestamp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02478e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only keep data that were collected during the first assessment phase\n",
    "df_pass_act_base = df_pass_act[df_pass_act.startTimestamp <= (df_pass_act.ema_base_end + pd.Timedelta(days=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cab1c-c515-4365-a3c1-6efbfd465284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pass_act_base = df_pass_act_base.loc[df_pass_act_base.customer.isin(df_ema1_customers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8a105-1433-4a86-b475-b3e666184ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pass_act_base.customer.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40577ed8-9cdf-4909-a565-847daca726dd",
   "metadata": {},
   "source": [
    "### 1.1 Calculate GPS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead0d9e-b89c-44d1-ba1d-6e1f3b2e17ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pass_act_loc =df_pass_act_base[df_pass_act_base.type.isin([\"Latitude\", \"Longitude\"])][[\"customer\", \"startTimestamp\", \"type\", \"doubleValue\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8c7eb-9534-456c-900b-2b6aced14f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_loc = df_pass_act_loc.pivot_table(\n",
    "    index=[\"customer\", \"startTimestamp\"],\n",
    "    columns=\"type\",\n",
    "    values=[\"doubleValue\"],\n",
    "    aggfunc='first'  # Using 'first' since each type should theoretically have only one entry per customer and timestamp\n",
    ")\n",
    "\n",
    "# Flatten the MultiIndex in columns\n",
    "df_loc.columns = ['_'.join(col).strip() for col in df_loc.columns.values]\n",
    "\n",
    "df_loc = df_loc.rename_axis(None, axis=1).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df_loc = df_loc.rename(columns={\n",
    "    'doubleValue_Latitude': 'Latitude',\n",
    "    'doubleValue_Longitude': 'Longitude',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3d176-fd67-49df-8ce9-9d9b32784d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc.customer.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f71a0a-7ede-4ad2-8009-07b37be30343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows per customer\n",
    "customer_counts = df_loc['customer'].value_counts()\n",
    "\n",
    "# Get a description of the distribution\n",
    "distribution_description = customer_counts.describe()\n",
    "print(\"Description of the distribution of number of rows per customer:\")\n",
    "print(distribution_description)\n",
    "\n",
    "# Display percentiles\n",
    "percentiles = customer_counts.quantile([i / 20 for i in range(1, 21)])\n",
    "print(\"\\nPercentiles:\")\n",
    "print(percentiles)\n",
    "\n",
    "# Find minimum threshold for data inclusion with a floor of 0\n",
    "threshold = max(0, customer_counts.mean() - customer_counts.std())\n",
    "print(f\"\\nMinimum threshold for inclusion: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d652d9d-063d-4a6e-a7d4-11843777c840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage with HDBSCAN and normalized min_samples:\n",
    "extractor = gps_features.HomeClusterExtractor(df_loc, speed_limit=speed_limit, max_distance=max_distance, epsilon=epsilon, min_samples=min_samples, \n",
    "                                 min_nights_obs = min_nights_obs, min_f_home=min_f_home, clustering_method='dbscan', \n",
    "                                 normalize_min_samples=False, min_data_points=50)\n",
    "result = extractor.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834db62-be07-4fc3-882e-dfb100d78605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 customers not enough GPS data (i.e. less than 50 data points, so that no home cluster could be computed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9895a55-a53d-4ab1-9b07-1159723e50e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home_clusters_red = result[[\"customer\", \"startTimestamp\", \"at_home\",\"transition\", \"distance\", \"stationary\",\"time_diff\", \"speed\", \"clusterID\", \"homeID\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21bb74-7c7b-4972-93e4-2b19de543a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_customer_list = home_clusters_red.customer.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596a358",
   "metadata": {},
   "source": [
    "## 2. Prepare EMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75454ad6-61e3-483b-a824-032cfc2d8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_udi = df_piv[[\"customer\", \"quest_create_day\",\"quest_create\", \"unique_day_id\", \"assess\",  \"quest_create_hour\", \"weekday\", \n",
    "                     \"weekend\",\"season\", \"time_of_day\",\"n_quest\",\"mean_na\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff90ae-e728-4485-9aed-400da4d35455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_udi = df_ema_udi.loc[df_ema_udi.customer.isin(gps_customer_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbd254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by customer and unique_day_id and calculate the minimum quest_create\n",
    "df_min_quest = df_ema_udi.groupby(['customer', 'unique_day_id'])['quest_create'].min().reset_index()\n",
    "\n",
    "# Rename the column to sensor_block_end\n",
    "df_min_quest.rename(columns={'quest_create': 'sensor_block_end'}, inplace=True)\n",
    "\n",
    "# Merge the minimum quest_create back to the original DataFrame\n",
    "df_ema_udi = pd.merge(df_ema_udi, df_min_quest, on=['customer', 'unique_day_id'], how='left')\n",
    "\n",
    "# Create the sensor_block_start column, which is 2 hours before quest_create\n",
    "df_ema_udi.drop(columns=['quest_create'], inplace=True)\n",
    "df_ema_udi = df_ema_udi.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79939ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare mapping of passing data by creating blocks\n",
    "\n",
    "df_ema_udi['sensor_block_start'] = df_ema_udi['sensor_block_end'] - pd.Timedelta(hours=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041705f9-ae62-4345-a71d-afc2f06224d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only include first assessment phase\n",
    "\n",
    "df_ema_udi_base = df_ema_udi.loc[df_ema_udi.assess == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09797e-588f-411c-949b-f70acb554ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_udi_base = df_ema_udi_base.copy()\n",
    "df_ema_udi_base[\"unique_blocks\"] = df_ema_udi_base.customer + df_ema_udi_base.unique_day_id\n",
    "df_ema_udi_base = df_ema_udi_base.drop_duplicates(subset = [\"customer\", \"unique_blocks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d54df1-cca4-4821-bcbe-12a935de8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_udi_merged = pd.merge(df_ema_udi_base, df_redcap, on=\"customer\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6adf57d-f203-4120-a1a7-7fc051220210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_udi_merged = df_ema_udi_merged.drop_duplicates(subset = [\"customer\", \"unique_blocks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5c641-d497-4956-96a2-35a09594aa57",
   "metadata": {},
   "source": [
    "## 3. Merge EMA to passive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b8668-24ae-49e8-add1-e714e167dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'customer' columns are strings and stripped of whitespace\n",
    "df_ema_udi_merged['customer'] = df_ema_udi_merged['customer'].astype(str).str.strip()\n",
    "df_pass_act_base['customer'] = df_pass_act_base['customer'].astype(str).str.strip()\n",
    "home_clusters_red['customer'] = home_clusters_red['customer'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecc8ab-0a6a-471a-abaf-111b726456be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Initialize the EMAMapper\n",
    "ema_mapper = EMA_Mapper.EMAMapper(df_ema_udi_merged, df_pass_act_base, home_clusters_red)\n",
    "\n",
    "# Step 2: Run the mappings\n",
    "ema_mapper.run_mappings()\n",
    "\n",
    "# Step 3: Retrieve the enriched EMA DataFrame\n",
    "df_ema_enriched = ema_mapper.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98933117-258d-4edf-9e9a-bacc78cb1ed0",
   "metadata": {},
   "source": [
    "### Include weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10865e-7835-418b-b8a6-730aaacde41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "\t\"latitude\": 52.5244,\n",
    "\t\"longitude\": 13.4105,\n",
    "\t\"start_date\": \"2023-05-01\",\n",
    "\t\"end_date\": \"2024-12-31\",\n",
    "\t\"daily\": [\"temperature_2m_max\", \"temperature_2m_min\", \"temperature_2m_mean\", \"apparent_temperature_max\", \"apparent_temperature_min\", \"apparent_temperature_mean\", \"sunshine_duration\", \"precipitation_sum\", \"precipitation_hours\"],\n",
    "\t\"timezone\": \"Europe/Berlin\"\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "# Process daily data. The order of variables needs to be the same as requested.\n",
    "daily = response.Daily()\n",
    "daily_temperature_2m_max = daily.Variables(0).ValuesAsNumpy()\n",
    "daily_temperature_2m_min = daily.Variables(1).ValuesAsNumpy()\n",
    "daily_temperature_2m_mean = daily.Variables(2).ValuesAsNumpy()\n",
    "daily_apparent_temperature_max = daily.Variables(3).ValuesAsNumpy()\n",
    "daily_apparent_temperature_min = daily.Variables(4).ValuesAsNumpy()\n",
    "daily_apparent_temperature_mean = daily.Variables(5).ValuesAsNumpy()\n",
    "daily_sunshine_duration = daily.Variables(6).ValuesAsNumpy()\n",
    "daily_precipitation_sum = daily.Variables(7).ValuesAsNumpy()\n",
    "daily_precipitation_hours = daily.Variables(8).ValuesAsNumpy()\n",
    "\n",
    "daily_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = daily.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "\n",
    "daily_data[\"apparent_temperature_mean\"] = daily_apparent_temperature_mean\n",
    "daily_data[\"sunshine_duration\"] = daily_sunshine_duration/3600\n",
    "daily_data[\"precipitation_hours\"] = daily_precipitation_hours\n",
    "\n",
    "daily_dataframe = pd.DataFrame(data = daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90716d-eedc-4552-99ce-8965c72d133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dataframe['date'] = pd.to_datetime(daily_dataframe['date'], utc=True)\n",
    "daily_dataframe['assessment_day'] = daily_dataframe['date'].dt.date\n",
    "df_ema_enriched[\"quest_create_day\"] = pd.to_datetime(df_ema_enriched[\"quest_create_day\"]).dt.date\n",
    "\n",
    "df_ema_weather = pd.merge(\n",
    "    df_ema_enriched,\n",
    "    daily_dataframe,\n",
    "    left_on=\"quest_create_day\",\n",
    "    right_on='assessment_day',\n",
    "    how='left'  # Use 'left' to keep all records from df_ema_enriched\n",
    ")\n",
    "\n",
    "# Drop redundant columns if necessary\n",
    "df_ema_weather.drop(['date', 'assessment_day'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965003ab-539c-47a7-a751-6dd9b08cfcf8",
   "metadata": {},
   "source": [
    "### Analyze missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f8a709-0d9c-4941-84ce-ee24814685ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove customers with missing person-static information\n",
    "\n",
    "missing_static = df_ema_weather[df_ema_weather.age.isna()][[\"customer\",\"for_id\",\"age\"]].customer.unique().tolist()\n",
    "df_ema_weather = df_ema_weather[~df_ema_weather.customer.isin(missing_static)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d51ec-9e8a-49f4-a6af-33f1bbf6a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae6da0-fd2e-4fe0-acff-adf0ea0a37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group_pa = [\n",
    "    'activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes'\n",
    "]\n",
    "feature_group_hr = ['hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hr_median', 'range_heartrate',\n",
    "       'iqr_heartrate', 'hr_zone_resting', 'hr_zone_moderate',\n",
    "       'hr_zone_vigorous']\n",
    "\n",
    "feature_group_gps = [ 'n_GPS', 'total_distance_km', 'at_home_minute',\n",
    "       'time_in_transition_minutes', 'time_stationary_minutes']\n",
    "\n",
    "feature_group_weather = [\"apparent_temperature_mean\", \"sunshine_duration\", \"precipitation_hours\"]\n",
    "\n",
    "feature_group_person_static = [\n",
    "    'age',\n",
    "    'somatic_description',\n",
    "    'psychotropic_description',\n",
    "    'employability_description_simple',\n",
    "    'prior_treatment_description_simple',\n",
    "    'ema_smartphone_description'\n",
    "]\n",
    "\n",
    "columns_to_check = ['activity_102_minutes',\n",
    "       'activity_103_minutes', 'activity_104_minutes', 'activity_105_minutes',\n",
    "       'activity_106_minutes', 'activity_107_minutes', 'hr_mean', 'hr_min', 'hr_max', 'hr_std', 'hr_median', 'range_heartrate',\n",
    "       'iqr_heartrate', 'skewness_heartrate', 'kurtosis_heartrate','hr_peak_counts', 'hr_zone_resting', 'hr_zone_moderate','hr_zone_vigorous', \n",
    "                    'n_GPS', 'total_distance_km', 'at_home_minute','time_in_transition_minutes', 'time_stationary_minutes', \"apparent_temperature_mean\", \n",
    "                    \"sunshine_duration\", \"precipitation_hours\",'n_steps', 'calories_burned', 'age','somatic_description','psychotropic_description',\n",
    "                    'employability_description_simple', 'prior_treatment_description_simple', 'ema_smartphone_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f36927-f5ae-407a-aa81-d9b736abb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_missing_df = summarize_missing_data(\n",
    "    df=df_ema_weather,\n",
    "    feature_group_pa=feature_group_pa,\n",
    "    feature_group_gps=feature_group_gps,\n",
    "    feature_group_hr=feature_group_hr,\n",
    "    feature_group_weather = feature_group_weather,\n",
    "    feature_group_person_static = feature_group_person_static,\n",
    "    columns_to_check=columns_to_check,\n",
    "    customer_id_col = \"customer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2e24a-c962-4feb-9405-927872047c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total beeps and condition beeps per participant\n",
    "beep_counts = df_ema_weather.groupby('customer').agg(\n",
    "    total_beeps=('sensor_block_end', 'count'),\n",
    "    condition_beeps=('at_home_minute', lambda x: ((x == -1) & (df_ema_enriched.loc[x.index, 'n_steps'] > 625)).sum())\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the ratio of condition beeps to total beeps\n",
    "beep_counts['condition_beeps_ratio'] = beep_counts['condition_beeps'] / beep_counts['total_beeps']\n",
    "\n",
    "# Identify participants where condition beeps >50% of total beeps\n",
    "high_condition_participants = beep_counts[beep_counts['condition_beeps_ratio'] > 0.50]['customer']\n",
    "\n",
    "# Remove those participants \n",
    "df_ema_enriched_filtered = df_ema_weather[~df_ema_weather['customer'].isin(high_condition_participants)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3962ee2-4e93-45a6-859b-5fb7a7af5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "beep_counts.condition_beeps.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512003c-60ad-46f8-9f96-93d1ef5ce91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_missing_df = summarize_missing_data(\n",
    "    df=df_ema_enriched_filtered,\n",
    "    feature_group_pa=feature_group_pa,\n",
    "    feature_group_gps=feature_group_gps,\n",
    "    feature_group_hr=feature_group_hr,\n",
    "    feature_group_weather = feature_group_weather,\n",
    "    feature_group_person_static = feature_group_person_static,\n",
    "    columns_to_check=columns_to_check,\n",
    "    customer_id_col = \"customer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96e9a7-98ef-4124-a035-9e267c426b71",
   "metadata": {},
   "source": [
    "### GPS condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15e5a8-83d8-4965-90d5-0e05b80b68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions\n",
    "conditions_home = [\n",
    "    (df_ema_enriched_filtered['at_home_minute'] == -1) & (df_ema_enriched_filtered['n_steps'] > 625),\n",
    "    (df_ema_enriched_filtered['at_home_minute'] == -1) & (df_ema_enriched_filtered['n_steps'] <= 625),\n",
    "    (df_ema_enriched_filtered['at_home_minute'] != -1)\n",
    "]\n",
    "\n",
    "conditions = [\n",
    "    (df_ema_enriched_filtered['n_GPS'] == -1) & (df_ema_enriched_filtered['n_steps'] > 625),\n",
    "    (df_ema_enriched_filtered['n_GPS'] == -1) & (df_ema_enriched_filtered['n_steps'] <= 625),\n",
    "    (df_ema_enriched_filtered['n_GPS'] != -1)\n",
    "]\n",
    "# Define the corresponding choices\n",
    "choices = [\n",
    "    'Steps>625',\n",
    "    'Steps<=625',\n",
    "    'GPS_present'\n",
    "]\n",
    "\n",
    "# Create the categorical column\n",
    "df_ema_enriched_filtered['missing_GPS_home'] = np.select(conditions_home, choices, default='Unknown')\n",
    "df_ema_enriched_filtered['missing_GPS'] = np.select(conditions, choices, default='Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56bf4ff-7149-473c-b875-d1970e64818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_enriched_filtered.loc[df_ema_enriched_filtered['missing_GPS_home']=='Steps>625']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e902da3-6c77-491f-9306-718d73e6237e",
   "metadata": {},
   "source": [
    "### Steps condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b7415-7340-4be1-aded-b351ae30fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for all specified columns being -1\n",
    "cols_to_check = [\n",
    "    'hr_mean', \n",
    "    'activity_102_minutes', \n",
    "    'activity_103_minutes', \n",
    "    'activity_104_minutes', \n",
    "    'activity_105_minutes', \n",
    "    'activity_106_minutes', \n",
    "    'activity_107_minutes'\n",
    "]\n",
    "\n",
    "all_negative = (df_ema_enriched_filtered[cols_to_check] == -1).all(axis=1)\n",
    "\n",
    "# Define the conditions for the new \"missing_steps\" column\n",
    "conditions_steps = [\n",
    "    # Condition: n_steps is -1 and all other specified columns are -1\n",
    "    (df_ema_enriched_filtered['n_steps'] == -1) & all_negative,\n",
    "    # Condition: n_steps is -1 but at least one of the specified columns is not -1\n",
    "    (df_ema_enriched_filtered['n_steps'] == -1) & (~all_negative),\n",
    "    # Condition: n_steps is not -1\n",
    "    (df_ema_enriched_filtered['n_steps'] != -1)\n",
    "]\n",
    "\n",
    "# Define the corresponding choices\n",
    "choices_steps = ['step_missing', 'step_zero', 'not_missing']\n",
    "\n",
    "# Create the \"missing_steps\" column\n",
    "df_ema_enriched_filtered['missing_steps'] = np.select(conditions_steps, choices_steps, default='Unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f983d6-7784-4bc5-9bc9-e8d53a839b37",
   "metadata": {},
   "source": [
    "### PA condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf8983-90fb-4b81-b792-5b37ee21f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions for the new \"missing_pa\" column\n",
    "\n",
    "conditions_pa = [\n",
    "    # 1. If 'activity_102_minutes' is NOT -1, mark as \"not_missing\"\n",
    "    (df_ema_enriched_filtered['activity_102_minutes'] != -1),\n",
    "    \n",
    "    # 2. If 'activity_102_minutes' is -1 and both 'n_steps' and 'hr_mean' are -1, mark as \"pa_missing\"\n",
    "    (df_ema_enriched_filtered['activity_102_minutes'] == -1) &\n",
    "    ((df_ema_enriched_filtered['n_steps'] == -1) & (df_ema_enriched_filtered['hr_mean'] == -1)),\n",
    "    \n",
    "    # 3. If 'activity_102_minutes' is -1 and at least one of 'n_steps' or 'hr_mean' is not -1, mark as \"pa_zero\"\n",
    "    (df_ema_enriched_filtered['activity_102_minutes'] == -1) &\n",
    "    (((df_ema_enriched_filtered['n_steps'] != -1) | (df_ema_enriched_filtered['hr_mean'] != -1)))\n",
    "]\n",
    "\n",
    "# Define the corresponding choices for each condition\n",
    "choices_pa = ['not_missing', 'pa_missing', 'pa_zero']\n",
    "\n",
    "# Create the \"missing_pa\" column using np.select\n",
    "df_ema_enriched_filtered['missing_pa'] = np.select(conditions_pa, choices_pa, default='Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35294b2-a8a0-4a3e-a873-c13e992b7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ema_enriched_filtered.unique_blocks.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08e105-0342-4091-8737-c2c95d8bc834",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preprocessed_path_freezed + f'/map_ema_passive.pkl', 'wb') as file:\n",
    "    pickle.dump(df_ema_enriched_filtered, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5392dc5-f496-4fa0-8adb-c1a37355c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preprocessed_path + f'/map_ema_passive.pkl', 'wb') as file:\n",
    "    pickle.dump(df_ema_enriched_filtered, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2d644-266c-4e59-b67f-31d85f6e558c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tiki]",
   "language": "python",
   "name": "conda-env-.conda-tiki-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
